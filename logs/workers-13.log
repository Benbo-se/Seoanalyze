âœ… Using Prisma singleton for database connection
Queue worker using Chrome at: /usr/bin/chromium
PM2 Instance: 0, Running Lighthouse: true
ğŸ•·ï¸ Creating Crawl worker (enabled=true, isMainInstance=true)
ğŸ”’ Memory guard started for queue-workers-0 (limit: 1100MB)
[STORAGE] Local artifact storage initialized at /home/reda/seo-analyzer-nextjs/artifacts
âœ… Connected to Redis
IMPORTANT! Eviction policy is allkeys-lru. It should be "noeviction"
IMPORTANT! Eviction policy is allkeys-lru. It should be "noeviction"
IMPORTANT! Eviction policy is allkeys-lru. It should be "noeviction"
IMPORTANT! Eviction policy is allkeys-lru. It should be "noeviction"
IMPORTANT! Eviction policy is allkeys-lru. It should be "noeviction"
IMPORTANT! Eviction policy is allkeys-lru. It should be "noeviction"
IMPORTANT! Eviction policy is allkeys-lru. It should be "noeviction"
IMPORTANT! Eviction policy is allkeys-lru. It should be "noeviction"
IMPORTANT! Eviction policy is allkeys-lru. It should be "noeviction"
IMPORTANT! Eviction policy is allkeys-lru. It should be "noeviction"
IMPORTANT! Eviction policy is allkeys-lru. It should be "noeviction"
IMPORTANT! Eviction policy is allkeys-lru. It should be "noeviction"
Processing Crawl job 1022 for https://chatgpt.com
ğŸ”„ STATE TRANSITION [Crawl 1022]: waiting â†’ active (worker picked up job)
ğŸ“Š PROGRESS UPDATE [Crawl 1022]: 10 pages crawled
Loaded robots.txt
Could not parse sitemap: https://chatgpt.com/sitemap.xml
Could not parse sitemap: https://chatgpt.com/sitemap_index.xml
Could not parse sitemap: https://chatgpt.com/sitemap.txt
Could not parse sitemap: https://chatgpt.com/sitemaps.xml
Could not parse sitemap: https://chatgpt.com/sitemap-index.xml
Could not parse sitemap: https://chatgpt.com/wp-sitemap.xml
Could not parse sitemap: https://chatgpt.com/page-sitemap.xml
No sitemap found - will discover pages by following links
Crawling (1/100): https://chatgpt.com
ğŸ“Š PROGRESS UPDATE [Crawl 1022]: 1 pages crawled
[CRAWL DEBUG] Puppeteer check: ENABLE=true, links=0, threshold=10
ğŸ”„ CRAWL: Only 0 links found with Axios, trying Puppeteer fallback for https://chatgpt.com...
Creating new browser instance...
Browser instance created
Browser acquired from pool (1 in pool, 0 available)
âœ… CRAWL: Puppeteer HTML retrieved for https://chatgpt.com
Browser operation completed in 6561ms
Browser released to pool
âœ… CRAWL: Puppeteer found 6 links vs 0, using Puppeteer result
Crawling (2/100): https://chatgpt.com/
ğŸ“Š PROGRESS UPDATE [Crawl 1022]: 2 pages crawled
[CRAWL DEBUG] Puppeteer check: ENABLE=true, links=0, threshold=10
ğŸ”„ CRAWL: Only 0 links found with Axios, trying Puppeteer fallback for https://chatgpt.com/...
Browser acquired from pool (1 in pool, 0 available)
âœ… CRAWL: Puppeteer HTML retrieved for https://chatgpt.com/
Browser operation completed in 6488ms
Browser released to pool
âœ… CRAWL: Puppeteer found 6 links vs 0, using Puppeteer result
ğŸ§  Running Rule Engine for crawl analysis 01K74SWAAFWWV6ANDFQAZ8E3WQ
âœ… Added 0 rule-based recommendations
ğŸ“Š Added RUM data with 0 samples
ğŸ” Running Change Detection for crawl https://chatgpt.com
ğŸ“¸ Created snapshot 553006ac-8e90-481b-88f8-2e2f33e682ad for https://chatgpt.com
ğŸ“Š PROGRESS UPDATE [Crawl 1022]: 100 pages crawled
Crawl job 1022 completed in 14718ms
ğŸ’¾ Updating Crawl analysis 01K74SWAAFWWV6ANDFQAZ8E3WQ in database
ğŸ’¾ DB results uppdaterade fÃ¶r crawl 01K74SWAAFWWV6ANDFQAZ8E3WQ
ğŸ“ Updated analysis 01K74SWAAFWWV6ANDFQAZ8E3WQ status to completed
[SAVE] Saved artifact locally: analyses/2025-10-09/01K74SWAAFWWV6ANDFQAZ8E3WQ/crawl-results.json
âœ… Crawl analysis 01K74SWAAFWWV6ANDFQAZ8E3WQ updated in database and artifacts
ğŸ“Š METRICS [Crawl]: domain=chatgpt.com, score=72, issuesCount=14, durationMs=14929, pagesCount=2
ğŸ”„ STATE TRANSITION [Crawl 1022]: active â†’ completed (resultId: 01K74SWAAFWWV6ANDFQAZ8E3WQ)
ğŸ“Š Memory [queue-workers-0]: RSS 148MB, Heap 40MB
Destroying browser instance...
Browser instance destroyed
ğŸ“Š Memory [queue-workers-0]: RSS 110MB, Heap 30MB
ğŸ“Š Memory [queue-workers-0]: RSS 111MB, Heap 31MB

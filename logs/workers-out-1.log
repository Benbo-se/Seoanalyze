ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 30MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 31MB
ðŸ“Š Memory [queue-workers-0]: RSS 114MB, Heap 30MB
ðŸ“Š Memory [queue-workers-0]: RSS 114MB, Heap 30MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 31MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 30MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 31MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 31MB
ðŸ“Š Memory [queue-workers-0]: RSS 114MB, Heap 31MB
ðŸ“Š Memory [queue-workers-0]: RSS 114MB, Heap 31MB
ðŸ“Š Memory [queue-workers-0]: RSS 114MB, Heap 31MB
ðŸ“Š Memory [queue-workers-0]: RSS 114MB, Heap 31MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 32MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 32MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 32MB
ðŸ“Š Memory [queue-workers-0]: RSS 114MB, Heap 31MB
ðŸ“Š Memory [queue-workers-0]: RSS 114MB, Heap 32MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 32MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 33MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 32MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 33MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 32MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 32MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 32MB
ðŸ“Š Memory [queue-workers-0]: RSS 114MB, Heap 32MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 33MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 33MB
ðŸ“Š Memory [queue-workers-0]: RSS 114MB, Heap 33MB
ðŸ“Š Memory [queue-workers-0]: RSS 114MB, Heap 33MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 33MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 33MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 33MB
ðŸ“Š Memory [queue-workers-0]: RSS 114MB, Heap 33MB
ðŸ“Š Memory [queue-workers-0]: RSS 114MB, Heap 33MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 34MB
ðŸ“Š Memory [queue-workers-0]: RSS 114MB, Heap 33MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 34MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 34MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 34MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 35MB
ðŸ“Š Memory [queue-workers-0]: RSS 114MB, Heap 34MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 35MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 35MB
ðŸ“Š Memory [queue-workers-0]: RSS 114MB, Heap 34MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 35MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 35MB
ðŸ“Š Memory [queue-workers-0]: RSS 114MB, Heap 35MB
ðŸ“Š Memory [queue-workers-0]: RSS 114MB, Heap 35MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 35MB
ðŸ“Š Memory [queue-workers-0]: RSS 114MB, Heap 35MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 35MB
ðŸ“Š Memory [queue-workers-0]: RSS 114MB, Heap 35MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 35MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 36MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 36MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 36MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 36MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 36MB
ðŸ“Š Memory [queue-workers-0]: RSS 114MB, Heap 36MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 36MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 36MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 29MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 29MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 29MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 29MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 29MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 29MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 30MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 30MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 30MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 31MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 30MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 30MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 31MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 31MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 31MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 31MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 31MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 31MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 31MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 31MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 31MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 31MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 32MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 31MB
ðŸ“Š Memory [queue-workers-0]: RSS 114MB, Heap 31MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 32MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 32MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 32MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 32MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 32MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 32MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 32MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 33MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 33MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 33MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 33MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 33MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 33MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 33MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 33MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 33MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 33MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 34MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 34MB
ðŸ“Š Memory [queue-workers-0]: RSS 114MB, Heap 33MB
ðŸ“Š Memory [queue-workers-0]: RSS 114MB, Heap 33MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 34MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 34MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 34MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 34MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 34MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 34MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 34MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 34MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 35MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 35MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 35MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 35MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 35MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 35MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 35MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 35MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 36MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 36MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 36MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 35MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 36MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 36MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 29MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 29MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 29MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 29MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 30MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 30MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 30MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 30MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 30MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 30MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 30MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 30MB
ðŸ“Š Memory [queue-workers-0]: RSS 114MB, Heap 30MB
ðŸ“Š Memory [queue-workers-0]: RSS 114MB, Heap 30MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 31MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 31MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 31MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 31MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 31MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 32MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 31MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 32MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 31MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 31MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 32MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 32MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 32MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 32MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 32MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 32MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 32MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 32MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 33MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 32MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 32MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 33MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 33MB
ðŸ“Š Memory [queue-workers-0]: RSS 116MB, Heap 33MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 33MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 34MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 33MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 33MB
ðŸ“Š Memory [queue-workers-0]: RSS 116MB, Heap 33MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 34MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 34MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 34MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 34MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 34MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 34MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 34MB
ðŸ“Š Memory [queue-workers-0]: RSS 114MB, Heap 34MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 35MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 34MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 34MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 35MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 35MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 34MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 35MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 35MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 35MB
ðŸ“Š Memory [queue-workers-0]: RSS 114MB, Heap 35MB
ðŸ“Š Memory [queue-workers-0]: RSS 114MB, Heap 35MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 35MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 35MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 36MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 36MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 36MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 36MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 29MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 29MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 30MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 30MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 30MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 29MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 30MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 30MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 30MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 30MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 30MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 30MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 30MB
ðŸ“Š Memory [queue-workers-0]: RSS 114MB, Heap 30MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 30MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 30MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 31MB
ðŸ“Š Memory [queue-workers-0]: RSS 114MB, Heap 31MB
ðŸ“Š Memory [queue-workers-0]: RSS 114MB, Heap 31MB
ðŸ“Š Memory [queue-workers-0]: RSS 114MB, Heap 31MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 32MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 32MB
ðŸ“Š Memory [queue-workers-0]: RSS 114MB, Heap 32MB
ðŸ“Š Memory [queue-workers-0]: RSS 114MB, Heap 32MB
ðŸ“Š Memory [queue-workers-0]: RSS 114MB, Heap 31MB
ðŸ“Š Memory [queue-workers-0]: RSS 114MB, Heap 31MB
ðŸ“Š Memory [queue-workers-0]: RSS 114MB, Heap 32MB
ðŸ“Š Memory [queue-workers-0]: RSS 114MB, Heap 32MB
ðŸ“Š Memory [queue-workers-0]: RSS 114MB, Heap 32MB
ðŸ“Š Memory [queue-workers-0]: RSS 114MB, Heap 32MB
ðŸ“Š Memory [queue-workers-0]: RSS 114MB, Heap 32MB
ðŸ“Š Memory [queue-workers-0]: RSS 114MB, Heap 32MB
ðŸ“Š Memory [queue-workers-0]: RSS 114MB, Heap 32MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 32MB
ðŸ“Š Memory [queue-workers-0]: RSS 114MB, Heap 32MB
ðŸ“Š Memory [queue-workers-0]: RSS 114MB, Heap 32MB
ðŸ“Š Memory [queue-workers-0]: RSS 114MB, Heap 33MB
ðŸ“Š Memory [queue-workers-0]: RSS 114MB, Heap 33MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 33MB
ðŸ“Š Memory [queue-workers-0]: RSS 114MB, Heap 33MB
ðŸ“Š Memory [queue-workers-0]: RSS 114MB, Heap 33MB
ðŸ“Š Memory [queue-workers-0]: RSS 114MB, Heap 33MB
ðŸ“Š Memory [queue-workers-0]: RSS 114MB, Heap 34MB
ðŸ“Š Memory [queue-workers-0]: RSS 114MB, Heap 34MB
ðŸ“Š Memory [queue-workers-0]: RSS 114MB, Heap 34MB
ðŸ“Š Memory [queue-workers-0]: RSS 114MB, Heap 34MB
ðŸ“Š Memory [queue-workers-0]: RSS 114MB, Heap 34MB
ðŸ“Š Memory [queue-workers-0]: RSS 114MB, Heap 34MB
ðŸ“Š Memory [queue-workers-0]: RSS 114MB, Heap 34MB
ðŸ“Š Memory [queue-workers-0]: RSS 114MB, Heap 34MB
ðŸ“Š Memory [queue-workers-0]: RSS 114MB, Heap 34MB
ðŸ“Š Memory [queue-workers-0]: RSS 114MB, Heap 34MB
ðŸ“Š Memory [queue-workers-0]: RSS 114MB, Heap 34MB
ðŸ“Š Memory [queue-workers-0]: RSS 114MB, Heap 35MB
ðŸ“Š Memory [queue-workers-0]: RSS 114MB, Heap 35MB
ðŸ“Š Memory [queue-workers-0]: RSS 114MB, Heap 34MB
ðŸ“Š Memory [queue-workers-0]: RSS 115MB, Heap 34MB
ðŸ“Š Memory [queue-workers-0]: RSS 114MB, Heap 35MB
ðŸ“Š Memory [queue-workers-0]: RSS 114MB, Heap 35MB
ðŸ“Š Memory [queue-workers-0]: RSS 114MB, Heap 35MB
ðŸ“Š Memory [queue-workers-0]: RSS 114MB, Heap 35MB
ðŸ“Š Memory [queue-workers-0]: RSS 114MB, Heap 35MB
Processing Lighthouse job 420 for https://stackr.se
ðŸ”„ STATE TRANSITION [Lighthouse 420]: waiting â†’ active (worker picked up job)
ðŸ“Š PROGRESS UPDATE [Lighthouse 420]: 10%
Loading ES modules...
Using Chrome path: /usr/bin/chromium
Chrome flags: 14 flags configured
Lighthouse categories: performance, accessibility, seo, best-practices
Processing SEO job 5224 for https://stackr.se
ðŸ”„ STATE TRANSITION [SEO 5224]: waiting â†’ active (worker picked up job)
ðŸ“Š PROGRESS UPDATE [SEO 5224]: 10%
ðŸ“Š PROGRESS UPDATE [SEO 5224]: 30%
DEBUG: HTML retrieved for https://stackr.se, HTML sample=<!DOCTYPE html><html lang="sv" class="__variable_f367f3 __variable_13fb82"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="stylesheet" href
DEBUG: performSeoAnalysis creating new Cheerio instance for https://stackr.se
DEBUG: Cheerio version: 1.1.2
DEBUG: URL=https://stackr.se, Cheerio found 0 scripts, 0 JSON-LD
Schema detection: found 0 scripts, hasSchema: false, types: 
robots.txt check: true
No sitemap.xml found
ðŸ“Š PROGRESS UPDATE [SEO 5224]: 90%
[SCREENSHOT] start id=01K6Y6W7Q2V7VDM4QKMR4Z6ZNY url=https://stackr.se
Creating new browser instance...
Browser instance created
Browser acquired from pool (1 in pool, 0 available)
[SAVE] Saved artifact locally: analyses/2025-10-07/01K6Y6W7Q2V7VDM4QKMR4Z6ZNY/screenshots/desktop.png
[SCREENSHOT] desktop OK key=analyses/2025-10-07/01K6Y6W7Q2V7VDM4QKMR4Z6ZNY/screenshots/desktop.png
[SAVE] Saved artifact locally: analyses/2025-10-07/01K6Y6W7Q2V7VDM4QKMR4Z6ZNY/screenshots/mobile.png
[SCREENSHOT] mobile OK key=analyses/2025-10-07/01K6Y6W7Q2V7VDM4QKMR4Z6ZNY/screenshots/mobile.png
Browser operation completed in 5905ms
Browser released to pool
[SAVE] Saved artifact locally: analyses/2025-10-07/01K6Y6W7Q2V7VDM4QKMR4Z6ZNY/seo-results.json
ðŸ“ Updated analysis 01K6Y6W7Q2V7VDM4QKMR4Z6ZNY status to completed
ðŸ’¾ Saved SEO analysis 01K6Y6W7Q2V7VDM4QKMR4Z6ZNY to database and artifacts
ðŸ“¸ Created snapshot 8df994a8-5e79-4213-8c14-a12f0b835f9a for https://stackr.se
ðŸ“Š PROGRESS UPDATE [SEO 5224]: 100%
SEO job 5224 completed in 7068ms
ðŸ“Š METRICS [SEO]: domain=stackr.se, score=80, issuesCount=0, durationMs=7068
ðŸ”„ STATE TRANSITION [SEO 5224]: active â†’ completed (resultId: 01K6Y6W7Q2V7VDM4QKMR4Z6ZNY)
Chrome process 397229 killed successfully
Cleaned up temp directory: /tmp/lighthouse-1759802951009-g1eir47s-387422
ðŸ“Š PROGRESS UPDATE [Lighthouse 420]: 90%
ðŸ§  Running Rule Engine for analysis 01K6Y6VZVPA9CZKC22J1JANJRC
âœ… Added 0 rule-based recommendations
ðŸ“Š Added RUM data with 0 samples
ðŸ” Running Change Detection for https://stackr.se
ðŸ“¸ Created snapshot 323aed0c-3b4d-483f-b79b-947a718f37e8 for https://stackr.se
ðŸ“Š PROGRESS UPDATE [Lighthouse 420]: 100%
Lighthouse job 420 completed in 19844ms
ðŸ’¾ Updating Lighthouse analysis 01K6Y6VZVPA9CZKC22J1JANJRC in database
ðŸ’¾ DB results uppdaterade fÃ¶r 01K6Y6VZVPA9CZKC22J1JANJRC
ðŸ“ Updated analysis 01K6Y6VZVPA9CZKC22J1JANJRC status to completed
[SAVE] Saved artifact locally: analyses/2025-10-07/01K6Y6VZVPA9CZKC22J1JANJRC/lighthouse-results.json
âœ… Lighthouse analysis 01K6Y6VZVPA9CZKC22J1JANJRC updated in database and artifacts
ðŸ“Š METRICS [Lighthouse]: domain=stackr.se, score=89, issuesCount=2, durationMs=19856
ðŸ”„ STATE TRANSITION [Lighthouse 420]: active â†’ completed (resultId: 01K6Y6VZVPA9CZKC22J1JANJRC)
Processing Crawl job 847 for https://stackr.se
ðŸ”„ STATE TRANSITION [Crawl 847]: waiting â†’ active (worker picked up job)
ðŸ“Š PROGRESS UPDATE [Crawl 847]: 10 pages crawled
Loaded robots.txt
Could not parse sitemap: https://stackr.se/sitemap.xml
Could not parse sitemap: https://stackr.se/sitemap_index.xml
Could not parse sitemap: https://stackr.se/sitemap.txt
Could not parse sitemap: https://stackr.se/sitemaps.xml
Could not parse sitemap: https://stackr.se/sitemap-index.xml
Could not parse sitemap: https://stackr.se/wp-sitemap.xml
Could not parse sitemap: https://stackr.se/page-sitemap.xml
Crawling (1/100): https://stackr.se
ðŸ“Š PROGRESS UPDATE [Crawl 847]: 1 pages crawled
Crawling (2/100): https://stackr.se/
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 847]: 2 pages crawled
Crawling (3/100): https://stackr.se/foretag
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 847]: 3 pages crawled
Crawling (4/100): https://stackr.se/karta
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 847]: 4 pages crawled
Crawling (5/100): https://stackr.se/jamfor
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 847]: 5 pages crawled
Crawling (6/100): https://stackr.se/?q=React
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 847]: 6 pages crawled
ðŸ“Š Memory [queue-workers-0]: RSS 314MB, Heap 161MB
Crawling (7/100): https://stackr.se/?q=Python
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 847]: 7 pages crawled
Crawling (8/100): https://stackr.se/?q=AWS
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 847]: 8 pages crawled
Destroying browser instance...
Browser instance destroyed
ðŸ“Š Memory [queue-workers-0]: RSS 209MB, Heap 85MB
Crawling (9/100): https://stackr.se/?q=TypeScript
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 847]: 9 pages crawled
Crawling (10/100): https://stackr.se/?q=Node.js
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 847]: 10 pages crawled
Crawling (11/100): https://stackr.se/?q=Docker
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 847]: 11 pages crawled
Crawling (12/100): https://stackr.se/?q=Kubernetes
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 847]: 12 pages crawled
Crawling (13/100): https://stackr.se/?q=PostgreSQL
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 847]: 13 pages crawled
Crawling (14/100): https://stackr.se/?q=Java
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 847]: 14 pages crawled
Crawling (15/100): https://stackr.se/?q=C
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 847]: 15 pages crawled
Crawling (16/100): https://stackr.se/jobb/a2e35cde3025778f
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 847]: 16 pages crawled
Crawling (17/100): https://stackr.se/foretag/techbuddy-ab-visby-
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 847]: 17 pages crawled
Page has noindex directive, skipping: https://stackr.se/foretag/techbuddy-ab-visby-
Crawling (18/100): https://stackr.se/jobb/cb77d24975dd45b0
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 847]: 18 pages crawled
Crawling (19/100): https://stackr.se/jobb/a24ab2e62698df51
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 847]: 19 pages crawled
Crawling (20/100): https://stackr.se/foretag/jobbs-on-sweden
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 847]: 20 pages crawled
Crawling (21/100): https://stackr.se/jobb/a1579ab55d7db5a0
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 847]: 21 pages crawled
Crawling (22/100): https://stackr.se/foretag/hirely-ab-jobylon-
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 847]: 22 pages crawled
Page has noindex directive, skipping: https://stackr.se/foretag/hirely-ab-jobylon-
Crawling (23/100): https://stackr.se/jobb/8f28491156a5bab8
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 847]: 23 pages crawled
Crawling (24/100): https://stackr.se/foretag/izadata-tech-consultancy
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 847]: 24 pages crawled
Page has noindex directive, skipping: https://stackr.se/foretag/izadata-tech-consultancy
Crawling (25/100): https://stackr.se/jobb/2ee88ee2b2d96c4f
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 847]: 25 pages crawled
ðŸ“Š Memory [queue-workers-0]: RSS 249MB, Heap 105MB
Crawling (26/100): https://stackr.se/foretag/kaching-cashback-ab-kaching-
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 847]: 26 pages crawled
Page has noindex directive, skipping: https://stackr.se/foretag/kaching-cashback-ab-kaching-
Crawling (27/100): https://stackr.se/jobb/cd180d0d09bbe0fb
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 847]: 27 pages crawled
Crawling (28/100): https://stackr.se/foretag/svab-hydraulik-ab-svab-
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 847]: 28 pages crawled
Page has noindex directive, skipping: https://stackr.se/foretag/svab-hydraulik-ab-svab-
Crawling (29/100): https://stackr.se/jobb/bb94c8e1aa1ecb0b
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 847]: 29 pages crawled
Crawling (30/100): https://stackr.se/foretag/incluso-ab-incluso-
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 847]: 30 pages crawled
Crawling (31/100): https://stackr.se/jobb/b24ca1be42473ac1
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 847]: 31 pages crawled
Crawling (32/100): https://stackr.se/foretag/globedesk-sverige-ab-100-remote-
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 847]: 32 pages crawled
Crawling (33/100): https://stackr.se/jobb/4b4108dae0746879
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 847]: 33 pages crawled
Crawling (34/100): https://stackr.se/foretag/kvalident-dental-group
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 847]: 34 pages crawled
Page has noindex directive, skipping: https://stackr.se/foretag/kvalident-dental-group
Crawling (35/100): https://stackr.se/jobb/149ada78b9f51c46
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 847]: 35 pages crawled
ðŸ“Š Memory [queue-workers-0]: RSS 246MB, Heap 85MB
Crawling (36/100): https://stackr.se/foretag/come-on-stockholm
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 847]: 36 pages crawled
Page has noindex directive, skipping: https://stackr.se/foretag/come-on-stockholm
Crawling (37/100): https://stackr.se/jobb/fa49e799350eed11
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 847]: 37 pages crawled
Crawling (38/100): https://stackr.se/foretag/ea-digital-illusions-ce-ab-ea-digital-illusions-ce-ab-
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 847]: 38 pages crawled
Crawling (39/100): https://stackr.se/jobb/41b9c374e880e80d
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 847]: 39 pages crawled
Crawling (40/100): https://stackr.se/foretag/xlnt-search-ab-xlnt-recruitment-group-
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 847]: 40 pages crawled
Page has noindex directive, skipping: https://stackr.se/foretag/xlnt-search-ab-xlnt-recruitment-group-
Crawling (41/100): https://stackr.se/jobb/8ed843a861db1a19
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 847]: 41 pages crawled
Crawling (42/100): https://stackr.se/foretag/io-interactive-ab-ioi-
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 847]: 42 pages crawled
Page has noindex directive, skipping: https://stackr.se/foretag/io-interactive-ab-ioi-
Crawling (43/100): https://stackr.se/jobb/844bdeb65f245163
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 847]: 43 pages crawled
Page has noindex directive, skipping: https://stackr.se/jobb/844bdeb65f245163
Crawling (44/100): https://stackr.se/foretag/sebratec-ab-sebratec-gothenburg-
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 847]: 44 pages crawled
Crawling (45/100): https://stackr.se/jobb/a9c0206fec2ee550
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 847]: 45 pages crawled
Page has noindex directive, skipping: https://stackr.se/jobb/a9c0206fec2ee550
Crawling (46/100): https://stackr.se/foretag/kambi-sweden
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 847]: 46 pages crawled
Crawling (47/100): https://stackr.se/jobb/13133bd30ec0fbea
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 847]: 47 pages crawled
Crawling (48/100): https://stackr.se/foretag/netonyx-ab-remote-from-eu-
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 847]: 48 pages crawled
Page has noindex directive, skipping: https://stackr.se/foretag/netonyx-ab-remote-from-eu-
Crawling (49/100): https://stackr.se/jobb/6c0914f0f632e174
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 847]: 49 pages crawled
Crawling (50/100): https://stackr.se/foretag/ants-akademiskt-n-tverk-av-tekniska-studenter-ab-ants-
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 847]: 50 pages crawled
Crawling (51/100): https://stackr.se/jobb/b3717937d62c8f24
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 847]: 51 pages crawled
Page has noindex directive, skipping: https://stackr.se/jobb/b3717937d62c8f24
Crawling (52/100): https://stackr.se/foretag/columbus-sweden-ab-columbus-sweden-poland-germany-czech-republic-
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 847]: 52 pages crawled
Crawling (53/100): https://stackr.se/jobb/e74423e392c32e4a
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 847]: 53 pages crawled
ðŸ“Š Memory [queue-workers-0]: RSS 248MB, Heap 93MB
Crawling (54/100): https://stackr.se/foretag/vx-service-delivery
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 847]: 54 pages crawled
Page has noindex directive, skipping: https://stackr.se/foretag/vx-service-delivery
Crawling (55/100): https://stackr.se/jobb/4c16ade28f3f0aa3
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 847]: 55 pages crawled
Crawling (56/100): https://stackr.se/foretag/techstack-global
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 847]: 56 pages crawled
Crawling (57/100): https://stackr.se/jobb/f1b2ef57428637b6
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 847]: 57 pages crawled
Page has noindex directive, skipping: https://stackr.se/jobb/f1b2ef57428637b6
Crawling (58/100): https://stackr.se/foretag/comsol
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 847]: 58 pages crawled
Crawling (59/100): https://stackr.se/jobb/f0617ce7925e78e7
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 847]: 59 pages crawled
Crawling (60/100): https://stackr.se/foretag/doktorse-nordic-ab-doktor-se-
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 847]: 60 pages crawled
Crawling (61/100): https://stackr.se/jobb/2a1d17e3b4dcdbb1
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 847]: 61 pages crawled
Crawling (62/100): https://stackr.se/foretag/hirely-ab-instabee-
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 847]: 62 pages crawled
Page has noindex directive, skipping: https://stackr.se/foretag/hirely-ab-instabee-
Crawling (63/100): https://stackr.se/jobb/8924f2e4871d0c8a
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 847]: 63 pages crawled
Page has noindex directive, skipping: https://stackr.se/jobb/8924f2e4871d0c8a
Crawling (64/100): https://stackr.se/foretag/wrknest-ab-wrknest-
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 847]: 64 pages crawled
Page has noindex directive, skipping: https://stackr.se/foretag/wrknest-ab-wrknest-
Crawling (65/100): https://stackr.se/jobb/e4c97e478edadcc1
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 847]: 65 pages crawled
Crawling (66/100): https://stackr.se/foretag/jobs-europe-ab-telus-digital-ai-inc-
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 847]: 66 pages crawled
Crawling (67/100): https://stackr.se/jobb/37e9f0f00fa8afd7
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 847]: 67 pages crawled
ðŸ“Š Memory [queue-workers-0]: RSS 249MB, Heap 94MB
Crawling (68/100): https://stackr.se/foretag/knowit-ab-publ-knowit-sweden-
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 847]: 68 pages crawled
Crawling (69/100): https://stackr.se/jobb/2b402a3ddc679d0a
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 847]: 69 pages crawled
Crawling (70/100): https://stackr.se/foretag/consultingit-stockholm-ab-consulting-it-
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 847]: 70 pages crawled
Crawling (71/100): https://stackr.se/jobb/c18abab392c763e3
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 847]: 71 pages crawled
Page has noindex directive, skipping: https://stackr.se/jobb/c18abab392c763e3
Crawling (72/100): https://stackr.se/jobb/4a86d516331a3bb1
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 847]: 72 pages crawled
Crawling (73/100): https://stackr.se/jobb/896688bed3771869
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 847]: 73 pages crawled
Crawling (74/100): https://stackr.se/foretag/v-g-milj-i-karlstad-ab-v-g-milj-ab-
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 847]: 74 pages crawled
Page has noindex directive, skipping: https://stackr.se/foretag/v-g-milj-i-karlstad-ab-v-g-milj-ab-
Crawling (75/100): https://stackr.se/jobb/1da32d4a04abf564
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 847]: 75 pages crawled
Crawling (76/100): https://stackr.se/foretag/nexer-telescope-ab-telescope-services-ab-
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 847]: 76 pages crawled
Crawling (77/100): https://stackr.se/jobb/e32f22e180ea6696
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 847]: 77 pages crawled
Crawling (78/100): https://stackr.se/jobb/5b80d753b41cc40d
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 847]: 78 pages crawled
Crawling (79/100): https://stackr.se/jobb/ba93dee7475dd2d2
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 847]: 79 pages crawled
Page has noindex directive, skipping: https://stackr.se/jobb/ba93dee7475dd2d2
Crawling (80/100): https://stackr.se/foretag/ubiquiti-sweden
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 847]: 80 pages crawled
Crawling (81/100): https://stackr.se/jobb/603696d975544b48
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 847]: 81 pages crawled
Page has noindex directive, skipping: https://stackr.se/jobb/603696d975544b48
Crawling (82/100): https://stackr.se/jobb/29fbf7d66e47ae75
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 847]: 82 pages crawled
Crawling (83/100): https://stackr.se/jobb/2f7d0b343b553e5d
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 847]: 83 pages crawled
ðŸ“Š Memory [queue-workers-0]: RSS 242MB, Heap 99MB
Page has noindex directive, skipping: https://stackr.se/jobb/2f7d0b343b553e5d
Crawling (84/100): https://stackr.se/jobb/6bc8ea767ad18fb3
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 847]: 84 pages crawled
Crawling (85/100): https://stackr.se/jobb/138c5c3eccff9e23
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 847]: 85 pages crawled
Crawling (86/100): https://stackr.se/foretag/tata-technologies-nordics
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 847]: 86 pages crawled
Page has noindex directive, skipping: https://stackr.se/foretag/tata-technologies-nordics
Crawling (87/100): https://stackr.se/jobb/873bdbaf49fab8df
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 847]: 87 pages crawled
Crawling (88/100): https://stackr.se/foretag/norla
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 847]: 88 pages crawled
Page has noindex directive, skipping: https://stackr.se/foretag/norla
Crawling (89/100): https://stackr.se/jobb/320839c98020352c
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 847]: 89 pages crawled
Crawling (90/100): https://stackr.se/foretag/veritaz-ab-lund-
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 847]: 90 pages crawled
Crawling (91/100): https://stackr.se/jobb/405207df5fb62e4a
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 847]: 91 pages crawled
Crawling (92/100): https://stackr.se/foretag/rasulson-consulting
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 847]: 92 pages crawled
Crawling (93/100): https://stackr.se/jobb/9bef914ff2caa989
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 847]: 93 pages crawled
Page has noindex directive, skipping: https://stackr.se/jobb/9bef914ff2caa989
Crawling (94/100): https://stackr.se/foretag/atqta-ab-atqta-
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 847]: 94 pages crawled
Page has noindex directive, skipping: https://stackr.se/foretag/atqta-ab-atqta-
Crawling (95/100): https://stackr.se/jobb/c542dbf3f572caa6
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 847]: 95 pages crawled
Crawling (96/100): https://stackr.se/foretag/veritaz-ab-gothenburg-
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 847]: 96 pages crawled
Crawling (97/100): https://stackr.se/jobb/287c4a0fd12c6f8a
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 847]: 97 pages crawled
ðŸ“Š Memory [queue-workers-0]: RSS 243MB, Heap 90MB
Crawling (98/100): https://stackr.se/foretag/leoware-sverige-ab-g-teborg-
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 847]: 98 pages crawled
Page has noindex directive, skipping: https://stackr.se/foretag/leoware-sverige-ab-g-teborg-
Crawling (99/100): https://stackr.se/jobb/99b2d975b2368da0
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 847]: 99 pages crawled
Crawling (100/100): https://stackr.se/foretag/veritaz-ab-stockholm-
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 847]: 100 pages crawled
ðŸ§  Running Rule Engine for crawl analysis 01K6Y6WKFH36CG020RWMYT1K9N
âœ… Added 0 rule-based recommendations
ðŸ“Š Added RUM data with 0 samples
ðŸ” Running Change Detection for crawl https://stackr.se
ðŸ“¸ Created snapshot 78f1999f-6136-4bea-ae38-f9b98086b526 for https://stackr.se
ðŸ“Š PROGRESS UPDATE [Crawl 847]: 100 pages crawled
Crawl job 847 completed in 231797ms
ðŸ’¾ Updating Crawl analysis 01K6Y6WKFH36CG020RWMYT1K9N in database
ðŸ’¾ DB results uppdaterade fÃ¶r crawl 01K6Y6WKFH36CG020RWMYT1K9N
ðŸ“ Updated analysis 01K6Y6WKFH36CG020RWMYT1K9N status to completed
[SAVE] Saved artifact locally: analyses/2025-10-07/01K6Y6WKFH36CG020RWMYT1K9N/crawl-results.json
âœ… Crawl analysis 01K6Y6WKFH36CG020RWMYT1K9N updated in database and artifacts
ðŸ“Š METRICS [Crawl]: domain=stackr.se, score=0, issuesCount=142, durationMs=232650, pagesCount=72
ðŸ”„ STATE TRANSITION [Crawl 847]: active â†’ completed (resultId: 01K6Y6WKFH36CG020RWMYT1K9N)
ðŸ“Š Memory [queue-workers-0]: RSS 326MB, Heap 101MB
ðŸ“Š Memory [queue-workers-0]: RSS 295MB, Heap 83MB
ðŸ“Š Memory [queue-workers-0]: RSS 295MB, Heap 82MB
ðŸ“Š Memory [queue-workers-0]: RSS 295MB, Heap 83MB
ðŸ“Š Memory [queue-workers-0]: RSS 295MB, Heap 83MB
ðŸ“Š Memory [queue-workers-0]: RSS 295MB, Heap 83MB
ðŸ“Š Memory [queue-workers-0]: RSS 295MB, Heap 83MB
ðŸ“Š Memory [queue-workers-0]: RSS 295MB, Heap 83MB
ðŸ“Š Memory [queue-workers-0]: RSS 295MB, Heap 83MB
ðŸ“Š Memory [queue-workers-0]: RSS 295MB, Heap 84MB
ðŸ“Š Memory [queue-workers-0]: RSS 296MB, Heap 84MB
ðŸ“Š Memory [queue-workers-0]: RSS 295MB, Heap 84MB
ðŸ“Š Memory [queue-workers-0]: RSS 295MB, Heap 84MB
ðŸ“Š Memory [queue-workers-0]: RSS 295MB, Heap 84MB
ðŸ“Š Memory [queue-workers-0]: RSS 295MB, Heap 84MB
ðŸ“Š Memory [queue-workers-0]: RSS 296MB, Heap 85MB
ðŸ“Š Memory [queue-workers-0]: RSS 296MB, Heap 85MB
ðŸ“Š Memory [queue-workers-0]: RSS 296MB, Heap 85MB
ðŸ“Š Memory [queue-workers-0]: RSS 297MB, Heap 85MB
ðŸ“Š Memory [queue-workers-0]: RSS 296MB, Heap 85MB
ðŸ“Š Memory [queue-workers-0]: RSS 296MB, Heap 85MB
ðŸ“Š Memory [queue-workers-0]: RSS 296MB, Heap 85MB
ðŸ“Š Memory [queue-workers-0]: RSS 297MB, Heap 85MB
ðŸ“Š Memory [queue-workers-0]: RSS 297MB, Heap 86MB
ðŸ“Š Memory [queue-workers-0]: RSS 297MB, Heap 86MB
ðŸ“Š Memory [queue-workers-0]: RSS 297MB, Heap 86MB
ðŸ“Š Memory [queue-workers-0]: RSS 297MB, Heap 86MB
ðŸ“Š Memory [queue-workers-0]: RSS 297MB, Heap 86MB
ðŸ“Š Memory [queue-workers-0]: RSS 297MB, Heap 86MB
ðŸ“Š Memory [queue-workers-0]: RSS 297MB, Heap 86MB
ðŸ“Š Memory [queue-workers-0]: RSS 298MB, Heap 86MB
ðŸ“Š Memory [queue-workers-0]: RSS 298MB, Heap 87MB
ðŸ“Š Memory [queue-workers-0]: RSS 298MB, Heap 87MB
ðŸ“Š Memory [queue-workers-0]: RSS 298MB, Heap 87MB
ðŸ“Š Memory [queue-workers-0]: RSS 298MB, Heap 87MB
ðŸ“Š Memory [queue-workers-0]: RSS 298MB, Heap 87MB
ðŸ“Š Memory [queue-workers-0]: RSS 298MB, Heap 87MB
ðŸ“Š Memory [queue-workers-0]: RSS 298MB, Heap 87MB
ðŸ“Š Memory [queue-workers-0]: RSS 299MB, Heap 88MB
ðŸ“Š Memory [queue-workers-0]: RSS 299MB, Heap 88MB
Processing SEO job 5225 for https://jessica-h.vercel.app/
ðŸ”„ STATE TRANSITION [SEO 5225]: waiting â†’ active (worker picked up job)
ðŸ“Š PROGRESS UPDATE [SEO 5225]: 10%
ðŸ“Š PROGRESS UPDATE [SEO 5225]: 30%
DEBUG: HTML retrieved for https://jessica-h.vercel.app/, HTML sample=<!doctype html> <html lang="en"> <head> <meta charset="UTF-8" /> <link rel="icon" type="image/svg+xml" href="/assets/favicon-BzVJVk0b.ico" /> <meta name="viewport" content="width=device-
DEBUG: performSeoAnalysis creating new Cheerio instance for https://jessica-h.vercel.app/
DEBUG: Cheerio version: 1.1.2
DEBUG: URL=https://jessica-h.vercel.app/, Cheerio found 0 scripts, 0 JSON-LD
Schema detection: found 0 scripts, hasSchema: false, types: 
robots.txt check: true
sitemap.xml check: false
ðŸ“Š PROGRESS UPDATE [SEO 5225]: 90%
[SCREENSHOT] start id=01K6Y883S2V6PGKK0PMQFFQRDG url=https://jessica-h.vercel.app/
Creating new browser instance...
Browser instance created
Browser acquired from pool (1 in pool, 0 available)
[SAVE] Saved artifact locally: analyses/2025-10-07/01K6Y883S2V6PGKK0PMQFFQRDG/screenshots/desktop.png
[SCREENSHOT] desktop OK key=analyses/2025-10-07/01K6Y883S2V6PGKK0PMQFFQRDG/screenshots/desktop.png
[SAVE] Saved artifact locally: analyses/2025-10-07/01K6Y883S2V6PGKK0PMQFFQRDG/screenshots/mobile.png
[SCREENSHOT] mobile OK key=analyses/2025-10-07/01K6Y883S2V6PGKK0PMQFFQRDG/screenshots/mobile.png
Browser operation completed in 4359ms
Browser released to pool
[SAVE] Saved artifact locally: analyses/2025-10-07/01K6Y883S2V6PGKK0PMQFFQRDG/seo-results.json
ðŸ“ Updated analysis 01K6Y883S2V6PGKK0PMQFFQRDG status to completed
ðŸ’¾ Saved SEO analysis 01K6Y883S2V6PGKK0PMQFFQRDG to database and artifacts
ðŸ“¸ Created snapshot 6c8912bf-aea0-4c5d-9f64-03dbce81564d for https://jessica-h.vercel.app/
ðŸ“Š First snapshot created for https://jessica-h.vercel.app/ - no changes to detect
ðŸ“¸ First snapshot created for change monitoring: https://jessica-h.vercel.app/
ðŸ“Š PROGRESS UPDATE [SEO 5225]: 100%
SEO job 5225 completed in 5532ms
ðŸ“Š METRICS [SEO]: domain=jessica-h.vercel.app, score=21, issuesCount=0, durationMs=5532
ðŸ”„ STATE TRANSITION [SEO 5225]: active â†’ completed (resultId: 01K6Y883S2V6PGKK0PMQFFQRDG)
Processing Crawl job 848 for https://jessica-h.vercel.app/
ðŸ”„ STATE TRANSITION [Crawl 848]: waiting â†’ active (worker picked up job)
ðŸ“Š PROGRESS UPDATE [Crawl 848]: 10 pages crawled
Loaded robots.txt
Crawling (1/100): https://jessica-h.vercel.app/
ðŸ“Š PROGRESS UPDATE [Crawl 848]: 1 pages crawled
ðŸ§  Running Rule Engine for crawl analysis 01K6Y889N67VCXNRJ31QNX9J9W
âœ… Added 0 rule-based recommendations
ðŸ“Š Added RUM data with 0 samples
ðŸ” Running Change Detection for crawl https://jessica-h.vercel.app/
ðŸ“¸ Created snapshot c9506d17-d0ba-431a-84ef-888d643e6d8b for https://jessica-h.vercel.app/
ðŸ“Š PROGRESS UPDATE [Crawl 848]: 100 pages crawled
Crawl job 848 completed in 301ms
ðŸ’¾ Updating Crawl analysis 01K6Y889N67VCXNRJ31QNX9J9W in database
ðŸ’¾ DB results uppdaterade fÃ¶r crawl 01K6Y889N67VCXNRJ31QNX9J9W
ðŸ“ Updated analysis 01K6Y889N67VCXNRJ31QNX9J9W status to completed
[SAVE] Saved artifact locally: analyses/2025-10-07/01K6Y889N67VCXNRJ31QNX9J9W/crawl-results.json
âœ… Crawl analysis 01K6Y889N67VCXNRJ31QNX9J9W updated in database and artifacts
ðŸ“Š METRICS [Crawl]: domain=jessica-h.vercel.app, score=94, issuesCount=3, durationMs=319, pagesCount=1
ðŸ”„ STATE TRANSITION [Crawl 848]: active â†’ completed (resultId: 01K6Y889N67VCXNRJ31QNX9J9W)
Processing Lighthouse job 421 for https://jessica-h.vercel.app/
ðŸ”„ STATE TRANSITION [Lighthouse 421]: waiting â†’ active (worker picked up job)
ðŸ“Š PROGRESS UPDATE [Lighthouse 421]: 10%
Loading ES modules...
Using Chrome path: /usr/bin/chromium
Chrome flags: 14 flags configured
Lighthouse categories: performance, accessibility, seo, best-practices
Chrome process 398322 killed successfully
Cleaned up temp directory: /tmp/lighthouse-1759804406553-nuw86bft-387422
ðŸ“Š PROGRESS UPDATE [Lighthouse 421]: 90%
ðŸ§  Running Rule Engine for analysis 01K6Y88ERJ66GF206VXJZ06KSV
âœ… Added 0 rule-based recommendations
ðŸ“Š Added RUM data with 0 samples
ðŸ” Running Change Detection for https://jessica-h.vercel.app/
ðŸ“¸ Created snapshot d3b76359-4922-4778-a7e2-5d4525afcbbb for https://jessica-h.vercel.app/
ðŸ“Š PROGRESS UPDATE [Lighthouse 421]: 100%
Lighthouse job 421 completed in 10066ms
ðŸ’¾ Updating Lighthouse analysis 01K6Y88ERJ66GF206VXJZ06KSV in database
ðŸ’¾ DB results uppdaterade fÃ¶r 01K6Y88ERJ66GF206VXJZ06KSV
ðŸ“ Updated analysis 01K6Y88ERJ66GF206VXJZ06KSV status to completed
[SAVE] Saved artifact locally: analyses/2025-10-07/01K6Y88ERJ66GF206VXJZ06KSV/lighthouse-results.json
âœ… Lighthouse analysis 01K6Y88ERJ66GF206VXJZ06KSV updated in database and artifacts
ðŸ“Š METRICS [Lighthouse]: domain=jessica-h.vercel.app, score=0, issuesCount=0, durationMs=10078
ðŸ”„ STATE TRANSITION [Lighthouse 421]: active â†’ completed (resultId: 01K6Y88ERJ66GF206VXJZ06KSV)
ðŸ“Š Memory [queue-workers-0]: RSS 370MB, Heap 131MB
Destroying browser instance...
Browser instance destroyed
ðŸ“Š Memory [queue-workers-0]: RSS 340MB, Heap 130MB
ðŸ“Š Memory [queue-workers-0]: RSS 300MB, Heap 91MB
ðŸ“Š Memory [queue-workers-0]: RSS 299MB, Heap 91MB
ðŸ“Š Memory [queue-workers-0]: RSS 299MB, Heap 91MB
ðŸ“Š Memory [queue-workers-0]: RSS 300MB, Heap 91MB
ðŸ“Š Memory [queue-workers-0]: RSS 300MB, Heap 92MB
ðŸ“Š Memory [queue-workers-0]: RSS 301MB, Heap 92MB
ðŸ“Š Memory [queue-workers-0]: RSS 300MB, Heap 92MB
ðŸ“Š Memory [queue-workers-0]: RSS 301MB, Heap 92MB
ðŸ“Š Memory [queue-workers-0]: RSS 300MB, Heap 92MB
ðŸ“Š Memory [queue-workers-0]: RSS 300MB, Heap 92MB
ðŸ“Š Memory [queue-workers-0]: RSS 301MB, Heap 92MB
ðŸ“Š Memory [queue-workers-0]: RSS 301MB, Heap 92MB
ðŸ“Š Memory [queue-workers-0]: RSS 301MB, Heap 93MB
ðŸ“Š Memory [queue-workers-0]: RSS 301MB, Heap 93MB
ðŸ“Š Memory [queue-workers-0]: RSS 301MB, Heap 93MB
ðŸ“Š Memory [queue-workers-0]: RSS 302MB, Heap 93MB
ðŸ“Š Memory [queue-workers-0]: RSS 301MB, Heap 93MB
ðŸ“Š Memory [queue-workers-0]: RSS 302MB, Heap 93MB
ðŸ“Š Memory [queue-workers-0]: RSS 302MB, Heap 94MB
ðŸ“Š Memory [queue-workers-0]: RSS 302MB, Heap 94MB
ðŸ“Š Memory [queue-workers-0]: RSS 302MB, Heap 94MB
ðŸ“Š Memory [queue-workers-0]: RSS 302MB, Heap 94MB
ðŸ“Š Memory [queue-workers-0]: RSS 302MB, Heap 94MB
ðŸ“Š Memory [queue-workers-0]: RSS 302MB, Heap 94MB
ðŸ“Š Memory [queue-workers-0]: RSS 302MB, Heap 94MB
ðŸ“Š Memory [queue-workers-0]: RSS 303MB, Heap 94MB
ðŸ“Š Memory [queue-workers-0]: RSS 303MB, Heap 95MB
ðŸ“Š Memory [queue-workers-0]: RSS 304MB, Heap 95MB
ðŸ“Š Memory [queue-workers-0]: RSS 303MB, Heap 95MB
ðŸ“Š Memory [queue-workers-0]: RSS 303MB, Heap 95MB
ðŸ“Š Memory [queue-workers-0]: RSS 304MB, Heap 95MB
ðŸ“Š Memory [queue-workers-0]: RSS 304MB, Heap 95MB
ðŸ“Š Memory [queue-workers-0]: RSS 304MB, Heap 96MB
ðŸ“Š Memory [queue-workers-0]: RSS 304MB, Heap 96MB
ðŸ“Š Memory [queue-workers-0]: RSS 304MB, Heap 96MB
ðŸ“Š Memory [queue-workers-0]: RSS 304MB, Heap 96MB
ðŸ“Š Memory [queue-workers-0]: RSS 304MB, Heap 96MB
ðŸ“Š Memory [queue-workers-0]: RSS 305MB, Heap 96MB
ðŸ“Š Memory [queue-workers-0]: RSS 304MB, Heap 96MB
ðŸ“Š Memory [queue-workers-0]: RSS 304MB, Heap 96MB
ðŸ“Š Memory [queue-workers-0]: RSS 305MB, Heap 97MB
ðŸ“Š Memory [queue-workers-0]: RSS 305MB, Heap 97MB
ðŸ“Š Memory [queue-workers-0]: RSS 305MB, Heap 97MB
ðŸ“Š Memory [queue-workers-0]: RSS 305MB, Heap 97MB
ðŸ“Š Memory [queue-workers-0]: RSS 305MB, Heap 97MB
ðŸ“Š Memory [queue-workers-0]: RSS 306MB, Heap 97MB
ðŸ“Š Memory [queue-workers-0]: RSS 305MB, Heap 97MB
ðŸ“Š Memory [queue-workers-0]: RSS 305MB, Heap 97MB
ðŸ“Š Memory [queue-workers-0]: RSS 306MB, Heap 97MB
ðŸ“Š Memory [queue-workers-0]: RSS 306MB, Heap 97MB
ðŸ“Š Memory [queue-workers-0]: RSS 306MB, Heap 98MB
ðŸ“Š Memory [queue-workers-0]: RSS 306MB, Heap 98MB
ðŸ“Š Memory [queue-workers-0]: RSS 306MB, Heap 98MB
ðŸ“Š Memory [queue-workers-0]: RSS 307MB, Heap 98MB
ðŸ“Š Memory [queue-workers-0]: RSS 307MB, Heap 98MB
ðŸ“Š Memory [queue-workers-0]: RSS 306MB, Heap 98MB
ðŸ“Š Memory [queue-workers-0]: RSS 306MB, Heap 98MB
ðŸ“Š Memory [queue-workers-0]: RSS 307MB, Heap 99MB
ðŸ“Š Memory [queue-workers-0]: RSS 307MB, Heap 98MB
ðŸ“Š Memory [queue-workers-0]: RSS 307MB, Heap 98MB
ðŸ“Š Memory [queue-workers-0]: RSS 307MB, Heap 99MB
ðŸ“Š Memory [queue-workers-0]: RSS 307MB, Heap 99MB
ðŸ“Š Memory [queue-workers-0]: RSS 308MB, Heap 91MB
ðŸ“Š Memory [queue-workers-0]: RSS 307MB, Heap 91MB
ðŸ“Š Memory [queue-workers-0]: RSS 307MB, Heap 91MB
ðŸ“Š Memory [queue-workers-0]: RSS 307MB, Heap 91MB
ðŸ“Š Memory [queue-workers-0]: RSS 307MB, Heap 91MB
ðŸ“Š Memory [queue-workers-0]: RSS 308MB, Heap 92MB
ðŸ“Š Memory [queue-workers-0]: RSS 307MB, Heap 91MB
ðŸ“Š Memory [queue-workers-0]: RSS 307MB, Heap 91MB
ðŸ“Š Memory [queue-workers-0]: RSS 307MB, Heap 92MB
ðŸ“Š Memory [queue-workers-0]: RSS 307MB, Heap 92MB
ðŸ“Š Memory [queue-workers-0]: RSS 307MB, Heap 92MB
ðŸ“Š Memory [queue-workers-0]: RSS 307MB, Heap 92MB
ðŸ“Š Memory [queue-workers-0]: RSS 307MB, Heap 92MB
ðŸ“Š Memory [queue-workers-0]: RSS 307MB, Heap 92MB
ðŸ“Š Memory [queue-workers-0]: RSS 307MB, Heap 92MB
ðŸ“Š Memory [queue-workers-0]: RSS 307MB, Heap 92MB
ðŸ“Š Memory [queue-workers-0]: RSS 307MB, Heap 93MB
ðŸ“Š Memory [queue-workers-0]: RSS 308MB, Heap 93MB
ðŸ“Š Memory [queue-workers-0]: RSS 307MB, Heap 93MB
ðŸ“Š Memory [queue-workers-0]: RSS 308MB, Heap 93MB
ðŸ“Š Memory [queue-workers-0]: RSS 307MB, Heap 93MB
ðŸ“Š Memory [queue-workers-0]: RSS 308MB, Heap 93MB
ðŸ“Š Memory [queue-workers-0]: RSS 307MB, Heap 93MB
ðŸ“Š Memory [queue-workers-0]: RSS 307MB, Heap 93MB
ðŸ“Š Memory [queue-workers-0]: RSS 307MB, Heap 93MB
ðŸ“Š Memory [queue-workers-0]: RSS 307MB, Heap 93MB
ðŸ“Š Memory [queue-workers-0]: RSS 308MB, Heap 94MB
ðŸ“Š Memory [queue-workers-0]: RSS 308MB, Heap 94MB
ðŸ“Š Memory [queue-workers-0]: RSS 308MB, Heap 94MB
ðŸ“Š Memory [queue-workers-0]: RSS 308MB, Heap 94MB
ðŸ“Š Memory [queue-workers-0]: RSS 307MB, Heap 94MB
ðŸ“Š Memory [queue-workers-0]: RSS 308MB, Heap 94MB
ðŸ“Š Memory [queue-workers-0]: RSS 307MB, Heap 94MB
ðŸ“Š Memory [queue-workers-0]: RSS 308MB, Heap 94MB
ðŸ“Š Memory [queue-workers-0]: RSS 307MB, Heap 95MB
ðŸ“Š Memory [queue-workers-0]: RSS 307MB, Heap 95MB
ðŸ“Š Memory [queue-workers-0]: RSS 307MB, Heap 95MB
ðŸ“Š Memory [queue-workers-0]: RSS 307MB, Heap 94MB
ðŸ“Š Memory [queue-workers-0]: RSS 307MB, Heap 95MB
ðŸ“Š Memory [queue-workers-0]: RSS 307MB, Heap 95MB
ðŸ“Š Memory [queue-workers-0]: RSS 307MB, Heap 95MB
ðŸ“Š Memory [queue-workers-0]: RSS 307MB, Heap 95MB
ðŸ“Š Memory [queue-workers-0]: RSS 307MB, Heap 95MB
ðŸ“Š Memory [queue-workers-0]: RSS 307MB, Heap 95MB
ðŸ“Š Memory [queue-workers-0]: RSS 308MB, Heap 96MB
âœ… Using Prisma singleton for database connection
Queue worker using Chrome at: /usr/bin/chromium
PM2 Instance: 0, Running Lighthouse: true
ðŸ•·ï¸ Creating Crawl worker (enabled=true, isMainInstance=true)
ðŸ”’ Memory guard started for queue-workers-0 (limit: 1100MB)
[STORAGE] Local artifact storage initialized at /home/reda/seo-analyzer-nextjs/artifacts
ðŸ“Š Memory [queue-workers-0]: RSS 117MB, Heap 29MB
ðŸ“Š Memory [queue-workers-0]: RSS 88MB, Heap 27MB
ðŸ“Š Memory [queue-workers-0]: RSS 88MB, Heap 28MB
ðŸ“Š Memory [queue-workers-0]: RSS 88MB, Heap 28MB
ðŸ“Š Memory [queue-workers-0]: RSS 88MB, Heap 27MB
ðŸ“Š Memory [queue-workers-0]: RSS 88MB, Heap 28MB
ðŸ“Š Memory [queue-workers-0]: RSS 88MB, Heap 28MB
ðŸ“Š Memory [queue-workers-0]: RSS 87MB, Heap 27MB
ðŸ“Š Memory [queue-workers-0]: RSS 87MB, Heap 27MB
âœ… Using Prisma singleton for database connection
Queue worker using Chrome at: /usr/bin/chromium
PM2 Instance: 0, Running Lighthouse: true
ðŸ•·ï¸ Creating Crawl worker (enabled=true, isMainInstance=true)
ðŸ”’ Memory guard started for queue-workers-0 (limit: 1100MB)
[STORAGE] Local artifact storage initialized at /home/reda/seo-analyzer-nextjs/artifacts
ðŸ¤– Processing AI Analysis job 1 for https://example.com
ðŸ”„ STATE TRANSITION [AI Analysis 1]: waiting â†’ active (worker picked up job)
ðŸ¤– AI Analysis job 1 completed in 182ms
ðŸ”„ STATE TRANSITION [AI Analysis 1]: waiting â†’ completed
ðŸ“Š Memory [queue-workers-0]: RSS 98MB, Heap 27MB
ðŸ“Š Memory [queue-workers-0]: RSS 98MB, Heap 27MB
ðŸ“Š Memory [queue-workers-0]: RSS 97MB, Heap 27MB
ðŸ“Š Memory [queue-workers-0]: RSS 97MB, Heap 27MB
ðŸ“Š Memory [queue-workers-0]: RSS 98MB, Heap 27MB
ðŸ“Š Memory [queue-workers-0]: RSS 98MB, Heap 27MB
ðŸ“Š Memory [queue-workers-0]: RSS 97MB, Heap 27MB
ðŸ“Š Memory [queue-workers-0]: RSS 98MB, Heap 28MB
ðŸ“Š Memory [queue-workers-0]: RSS 98MB, Heap 28MB
ðŸ“Š Memory [queue-workers-0]: RSS 98MB, Heap 27MB
âœ… Using Prisma singleton for database connection
Queue worker using Chrome at: /usr/bin/chromium
PM2 Instance: 0, Running Lighthouse: true
ðŸ•·ï¸ Creating Crawl worker (enabled=true, isMainInstance=true)
ðŸ”’ Memory guard started for queue-workers-0 (limit: 1100MB)
[STORAGE] Local artifact storage initialized at /home/reda/seo-analyzer-nextjs/artifacts
âœ… Connected to Redis
ðŸ“Š Memory [queue-workers-0]: RSS 89MB, Heap 28MB
ðŸ“Š Memory [queue-workers-0]: RSS 89MB, Heap 27MB
ðŸ“Š Memory [queue-workers-0]: RSS 89MB, Heap 28MB
ðŸ“Š Memory [queue-workers-0]: RSS 88MB, Heap 27MB
ðŸ“Š Memory [queue-workers-0]: RSS 89MB, Heap 27MB
ðŸ“Š Memory [queue-workers-0]: RSS 89MB, Heap 28MB
ðŸ“Š Memory [queue-workers-0]: RSS 89MB, Heap 27MB
ðŸ¤– Processing AI Analysis job 2 for https://google.com
ðŸ¤– Step 1: Crawling user's website https://google.com
ðŸ”„ STATE TRANSITION [AI Analysis 2]: waiting â†’ active (worker picked up job)
Added Crawl job 849 for https://google.com
Processing Crawl job 849 for https://google.com
ðŸ”„ STATE TRANSITION [Crawl 849]: waiting â†’ active (worker picked up job)
Added Lighthouse job 422 for https://google.com
Processing Lighthouse job 422 for https://google.com
ðŸ¤– Waiting for user crawl (849) and lighthouse (422)
ðŸ“Š PROGRESS UPDATE [Crawl 849]: 10 pages crawled
ðŸ”„ STATE TRANSITION [Lighthouse 422]: waiting â†’ active (worker picked up job)
ðŸ“Š PROGRESS UPDATE [Lighthouse 422]: 10%
Loading ES modules...
Loaded robots.txt
Using Chrome path: /usr/bin/chromium
Chrome flags: 14 flags configured
Could not parse sitemap: https://www.google.com/slides/sitemaps.xml
Could not parse sitemap: https://www.google.com/sheets/sitemaps.xml
Lighthouse categories: performance, accessibility, seo, best-practices
Could not parse sitemap: https://www.google.com/search/about/sitemap.xml
Could not parse sitemap: https://www.google.com/calendar/about/sitemap.xml
Could not parse sitemap: https://www.google.com/slides/sitemaps.xml
Could not parse sitemap: https://www.google.com/sheets/sitemaps.xml
Could not parse sitemap: https://www.google.com/search/about/sitemap.xml
Could not parse sitemap: https://www.google.com/calendar/about/sitemap.xml
Could not parse sitemap: https://google.com/sitemap_index.xml
Could not parse sitemap: https://google.com/sitemap.txt
Could not parse sitemap: https://google.com/sitemaps.xml
Could not parse sitemap: https://google.com/sitemap-index.xml
Could not parse sitemap: https://google.com/wp-sitemap.xml
Could not parse sitemap: https://google.com/page-sitemap.xml
Found 44255 URLs in sitemap
Crawling (1/10): https://google.com
ðŸ“Š PROGRESS UPDATE [Crawl 849]: 1 pages crawled
Robots.txt blocks: https://www.google.com/intl/am/gmail/about/
Robots.txt blocks: https://www.google.com/intl/am/gmail/about/for-work/
Robots.txt blocks: https://www.google.com/intl/am/gmail/about/policy/
Robots.txt blocks: https://www.google.com/intl/ar/gmail/about/
Robots.txt blocks: https://www.google.com/intl/ar/gmail/about/for-work/
Robots.txt blocks: https://www.google.com/intl/ar/gmail/about/policy/
Robots.txt blocks: https://www.google.com/intl/bg/gmail/about/
Robots.txt blocks: https://www.google.com/intl/bg/gmail/about/for-work/
Robots.txt blocks: https://www.google.com/intl/bg/gmail/about/policy/
Crawling (2/10): https://google.com/preferences?hl=sv
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 849]: 2 pages crawled
Crawling (3/10): https://google.com/advanced_search?hl=sv-NL&authuser=0
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 849]: 3 pages crawled
Crawling (4/10): https://google.com/intl/sv/ads/
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 849]: 4 pages crawled
Chrome process 401638 killed successfully
Cleaned up temp directory: /tmp/lighthouse-1759808474014-anfj3itr-401510
ðŸ“Š PROGRESS UPDATE [Lighthouse 422]: 90%
ðŸ§  Running Rule Engine for analysis null
âœ… Added 0 rule-based recommendations
ðŸ“Š Added RUM data with 0 samples
ðŸ” Running Change Detection for https://google.com
ðŸ“¸ Created snapshot cccc51dd-b05e-47b4-9504-40ed36d4609f for https://google.com
ðŸ“Š PROGRESS UPDATE [Lighthouse 422]: 100%
Lighthouse job 422 completed in 15877ms
ðŸ”„ STATE TRANSITION [Lighthouse 422]: active â†’ completed (resultId: lighthouse_422_1759808488264)
Crawling (5/10): https://google.com/intl/sv/about.html
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 849]: 5 pages crawled
Crawling (6/10): https://google.com/intl/sv/policies/privacy/
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 849]: 6 pages crawled
Crawling (7/10): https://google.com/intl/sv/policies/terms/
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 849]: 7 pages crawled
Crawling (8/10): https://google.com/url?q=https://myactivity.google.com/product/search/controls%3Futm_source%3Dgoogle%26utm_medium%3Dpref-page%26hl%3Dsv-NL%26authuser%3D0&opi=89978449&sa=U&ved=0ahUKEwjezae8lZGQAxUZhf0HHT-LHw8Q7JsICAE&usg=AOvVaw1q-QnsWg6dNj3-M4BUHK1V
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 849]: 8 pages crawled
Crawling (9/10): https://google.com/url?q=/setting/search/privateresults%3Fhl%3Dsv-NL%26authuser%3D0&opi=89978449&sa=U&ved=0ahUKEwjezae8lZGQAxUZhf0HHT-LHw8Q-vUJCAI&usg=AOvVaw1cSSqfz2oWE6Cpb6b5LnsR
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 849]: 9 pages crawled
Crawling (10/10): https://google.com/url?q=/safesearch%3Fhl%3Dsv-NL%26prev%3Dhttps://www.google.com/preferences%3Fhl%253Dsv&opi=89978449&sa=U&ved=0ahUKEwjezae8lZGQAxUZhf0HHT-LHw8Q1fMKCAM&usg=AOvVaw3GZO2CKNFIvnKFb98-Z78G
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 849]: 10 pages crawled
ðŸ“Š Memory [queue-workers-0]: RSS 361MB, Heap 159MB
ðŸ§  Running Rule Engine for crawl analysis null
âœ… Added 0 rule-based recommendations
ðŸ“Š Added RUM data with 0 samples
ðŸ” Running Change Detection for crawl https://google.com
ðŸ“¸ Created snapshot 7e6be8a6-69b4-4c3f-ae81-c8d156d2b1bf for https://google.com
ðŸ“Š PROGRESS UPDATE [Crawl 849]: 100 pages crawled
Crawl job 849 completed in 21513ms
ðŸ”„ STATE TRANSITION [Crawl 849]: active â†’ completed (resultId: crawl_849_1759808493884)
ðŸ¤– Step 2: Finding competitors for https://google.com
ðŸ¤– Mock competitors for google.com: [
  'https://competitor1-google.com',
  'https://competitor2-google.com',
  'https://competitor3-google.com'
]
ðŸ¤– Found 3 competitors: [
  'https://competitor1-google.com',
  'https://competitor2-google.com',
  'https://competitor3-google.com'
]
ðŸ¤– Step 3: Crawling 3 competitors
ðŸ¤– Crawling competitor 1/3: https://competitor1-google.com
Added Crawl job 850 for https://competitor1-google.com
Processing Crawl job 850 for https://competitor1-google.com
ðŸ”„ STATE TRANSITION [Crawl 850]: waiting â†’ active (worker picked up job)
ðŸ“Š PROGRESS UPDATE [Crawl 850]: 10 pages crawled
No robots.txt found
Could not parse sitemap: https://competitor1-google.com/sitemap.xml
Could not parse sitemap: https://competitor1-google.com/sitemap_index.xml
Could not parse sitemap: https://competitor1-google.com/sitemap.txt
Could not parse sitemap: https://competitor1-google.com/sitemaps.xml
Could not parse sitemap: https://competitor1-google.com/sitemap-index.xml
Could not parse sitemap: https://competitor1-google.com/wp-sitemap.xml
Could not parse sitemap: https://competitor1-google.com/page-sitemap.xml
Crawling (1/10): https://competitor1-google.com
ðŸ“Š PROGRESS UPDATE [Crawl 850]: 1 pages crawled
ðŸ§  Running Rule Engine for crawl analysis null
âœ… Added 0 rule-based recommendations
ðŸ“Š Added RUM data with 0 samples
ðŸ” Running Change Detection for crawl https://competitor1-google.com
ðŸ“¸ Created snapshot 698b4987-882e-4734-be61-a0969a49f702 for https://competitor1-google.com
ðŸ“Š First snapshot created for https://competitor1-google.com - no changes to detect
ðŸ“Š PROGRESS UPDATE [Crawl 850]: 100 pages crawled
Crawl job 850 completed in 168ms
ðŸ”„ STATE TRANSITION [Crawl 850]: active â†’ completed (resultId: crawl_850_1759808494144)
ðŸ¤– Crawling competitor 2/3: https://competitor2-google.com
Added Crawl job 851 for https://competitor2-google.com
Processing Crawl job 851 for https://competitor2-google.com
ðŸ”„ STATE TRANSITION [Crawl 851]: waiting â†’ active (worker picked up job)
ðŸ“Š PROGRESS UPDATE [Crawl 851]: 10 pages crawled
No robots.txt found
Could not parse sitemap: https://competitor2-google.com/sitemap.xml
Could not parse sitemap: https://competitor2-google.com/sitemap_index.xml
Could not parse sitemap: https://competitor2-google.com/sitemap.txt
Could not parse sitemap: https://competitor2-google.com/sitemaps.xml
Could not parse sitemap: https://competitor2-google.com/sitemap-index.xml
Could not parse sitemap: https://competitor2-google.com/wp-sitemap.xml
Could not parse sitemap: https://competitor2-google.com/page-sitemap.xml
Crawling (1/10): https://competitor2-google.com
ðŸ“Š PROGRESS UPDATE [Crawl 851]: 1 pages crawled
ðŸ§  Running Rule Engine for crawl analysis null
âœ… Added 0 rule-based recommendations
ðŸ“Š Added RUM data with 0 samples
ðŸ” Running Change Detection for crawl https://competitor2-google.com
ðŸ“¸ Created snapshot 65464dbd-53c7-41d2-9197-49066f513bb9 for https://competitor2-google.com
ðŸ“Š First snapshot created for https://competitor2-google.com - no changes to detect
ðŸ“Š PROGRESS UPDATE [Crawl 851]: 100 pages crawled
Crawl job 851 completed in 169ms
ðŸ”„ STATE TRANSITION [Crawl 851]: active â†’ completed (resultId: crawl_851_1759808496154)
ðŸ¤– Crawling competitor 3/3: https://competitor3-google.com
Added Crawl job 852 for https://competitor3-google.com
Processing Crawl job 852 for https://competitor3-google.com
ðŸ”„ STATE TRANSITION [Crawl 852]: waiting â†’ active (worker picked up job)
ðŸ“Š PROGRESS UPDATE [Crawl 852]: 10 pages crawled
No robots.txt found
Could not parse sitemap: https://competitor3-google.com/sitemap.xml
Could not parse sitemap: https://competitor3-google.com/sitemap_index.xml
Could not parse sitemap: https://competitor3-google.com/sitemap.txt
Could not parse sitemap: https://competitor3-google.com/sitemaps.xml
Could not parse sitemap: https://competitor3-google.com/sitemap-index.xml
Could not parse sitemap: https://competitor3-google.com/wp-sitemap.xml
Could not parse sitemap: https://competitor3-google.com/page-sitemap.xml
Crawling (1/10): https://competitor3-google.com
ðŸ“Š PROGRESS UPDATE [Crawl 852]: 1 pages crawled
ðŸ§  Running Rule Engine for crawl analysis null
âœ… Added 0 rule-based recommendations
ðŸ“Š Added RUM data with 0 samples
ðŸ” Running Change Detection for crawl https://competitor3-google.com
ðŸ“¸ Created snapshot a43c55c0-18e5-42bf-af53-c1d708374096 for https://competitor3-google.com
ðŸ“Š First snapshot created for https://competitor3-google.com - no changes to detect
ðŸ“Š PROGRESS UPDATE [Crawl 852]: 100 pages crawled
Crawl job 852 completed in 169ms
ðŸ”„ STATE TRANSITION [Crawl 852]: active â†’ completed (resultId: crawl_852_1759808498164)
ðŸ¤– Step 4: Generating AI report with DeepSeek
ðŸ¤– Step 5: Saving AI report
ðŸ¤– AI Analysis job 2 completed in 27864ms
ðŸ”„ STATE TRANSITION [AI Analysis 2]: waiting â†’ completed
ðŸ“Š Memory [queue-workers-0]: RSS 230MB, Heap 81MB
ðŸ“Š Memory [queue-workers-0]: RSS 216MB, Heap 81MB
âœ… Using Prisma singleton for database connection
Queue worker using Chrome at: /usr/bin/chromium
PM2 Instance: 0, Running Lighthouse: true
ðŸ•·ï¸ Creating Crawl worker (enabled=true, isMainInstance=true)
ðŸ”’ Memory guard started for queue-workers-0 (limit: 1100MB)
[STORAGE] Local artifact storage initialized at /home/reda/seo-analyzer-nextjs/artifacts
âœ… Connected to Redis
ðŸ“Š Memory [queue-workers-0]: RSS 89MB, Heap 28MB
ðŸ¤– Processing AI Analysis job 3 for https://wikipedia.org
ðŸ¤– Step 1: Crawling user's website https://wikipedia.org
ðŸ”„ STATE TRANSITION [AI Analysis 3]: waiting â†’ active (worker picked up job)
Added Crawl job 853 for https://wikipedia.org
Processing Crawl job 853 for https://wikipedia.org
ðŸ”„ STATE TRANSITION [Crawl 853]: waiting â†’ active (worker picked up job)
Added Lighthouse job 423 for https://wikipedia.org
ðŸ“Š PROGRESS UPDATE [Crawl 853]: 10 pages crawled
Processing Lighthouse job 423 for https://wikipedia.org
ðŸ”„ STATE TRANSITION [Lighthouse 423]: waiting â†’ active (worker picked up job)
ðŸ¤– Waiting for user crawl (853) and lighthouse (423)
ðŸ“Š PROGRESS UPDATE [Lighthouse 423]: 10%
Loading ES modules...
Loaded robots.txt
Using Chrome path: /usr/bin/chromium
Chrome flags: 14 flags configured
Could not parse sitemap: https://wikipedia.org/sitemap.xml
Could not parse sitemap: https://wikipedia.org/sitemap_index.xml
Lighthouse categories: performance, accessibility, seo, best-practices
Could not parse sitemap: https://wikipedia.org/sitemap.txt
Could not parse sitemap: https://wikipedia.org/sitemaps.xml
Could not parse sitemap: https://wikipedia.org/sitemap-index.xml
Could not parse sitemap: https://wikipedia.org/wp-sitemap.xml
Could not parse sitemap: https://wikipedia.org/page-sitemap.xml
Crawling (1/10): https://wikipedia.org
ðŸ“Š PROGRESS UPDATE [Crawl 853]: 1 pages crawled
Crawling (2/10): https://wikipedia.org/
Respecting crawl-delay of 0.5s
ðŸ“Š PROGRESS UPDATE [Crawl 853]: 2 pages crawled
ðŸ§  Running Rule Engine for crawl analysis null
âœ… Added 0 rule-based recommendations
ðŸ“Š Added RUM data with 0 samples
ðŸ” Running Change Detection for crawl https://wikipedia.org
ðŸ“¸ Created snapshot ba031a6a-70ab-46fc-a904-93629ac8f7f0 for https://wikipedia.org
ðŸ“Š First snapshot created for https://wikipedia.org - no changes to detect
ðŸ“Š PROGRESS UPDATE [Crawl 853]: 100 pages crawled
Crawl job 853 completed in 5632ms
ðŸ”„ STATE TRANSITION [Crawl 853]: active â†’ completed (resultId: crawl_853_1759808617853)
ðŸ“Š Memory [queue-workers-0]: RSS 251MB, Heap 132MB
Chrome process 402077 killed successfully
Cleaned up temp directory: /tmp/lighthouse-1759808613789-ox1mhuce-402015
ðŸ“Š PROGRESS UPDATE [Lighthouse 423]: 90%
ðŸ§  Running Rule Engine for analysis null
âœ… Added 0 rule-based recommendations
ðŸ“Š Added RUM data with 0 samples
ðŸ” Running Change Detection for https://wikipedia.org
ðŸ“¸ Created snapshot f1695497-ccfb-4138-a688-6b399a52206f for https://wikipedia.org
ðŸ“Š PROGRESS UPDATE [Lighthouse 423]: 100%
Lighthouse job 423 completed in 18160ms
ðŸ”„ STATE TRANSITION [Lighthouse 423]: active â†’ completed (resultId: lighthouse_423_1759808630474)
ðŸ¤– Step 2: Finding competitors for https://wikipedia.org
ðŸ¤– Mock competitors for wikipedia.org: [
  'https://competitor1-wikipedia.com',
  'https://competitor2-wikipedia.com',
  'https://competitor3-wikipedia.com'
]
ðŸ¤– Found 3 competitors: [
  'https://competitor1-wikipedia.com',
  'https://competitor2-wikipedia.com',
  'https://competitor3-wikipedia.com'
]
ðŸ¤– Step 3: Crawling 3 competitors
ðŸ¤– Crawling competitor 1/3: https://competitor1-wikipedia.com
Added Crawl job 854 for https://competitor1-wikipedia.com
Processing Crawl job 854 for https://competitor1-wikipedia.com
ðŸ”„ STATE TRANSITION [Crawl 854]: waiting â†’ active (worker picked up job)
ðŸ“Š PROGRESS UPDATE [Crawl 854]: 10 pages crawled
No robots.txt found
Could not parse sitemap: https://competitor1-wikipedia.com/sitemap.xml
Could not parse sitemap: https://competitor1-wikipedia.com/sitemap_index.xml
Could not parse sitemap: https://competitor1-wikipedia.com/sitemap.txt
Could not parse sitemap: https://competitor1-wikipedia.com/sitemaps.xml
Could not parse sitemap: https://competitor1-wikipedia.com/sitemap-index.xml
Could not parse sitemap: https://competitor1-wikipedia.com/wp-sitemap.xml
Could not parse sitemap: https://competitor1-wikipedia.com/page-sitemap.xml
Crawling (1/10): https://competitor1-wikipedia.com
ðŸ“Š PROGRESS UPDATE [Crawl 854]: 1 pages crawled
ðŸ§  Running Rule Engine for crawl analysis null
âœ… Added 0 rule-based recommendations
ðŸ“Š Added RUM data with 0 samples
ðŸ” Running Change Detection for crawl https://competitor1-wikipedia.com
ðŸ“¸ Created snapshot e3ebf523-d0b2-4324-8d84-10bbcb02e34c for https://competitor1-wikipedia.com
ðŸ“Š First snapshot created for https://competitor1-wikipedia.com - no changes to detect
ðŸ“Š PROGRESS UPDATE [Crawl 854]: 100 pages crawled
Crawl job 854 completed in 174ms
ðŸ”„ STATE TRANSITION [Crawl 854]: active â†’ completed (resultId: crawl_854_1759808632609)
ðŸ¤– Crawling competitor 2/3: https://competitor2-wikipedia.com
Added Crawl job 855 for https://competitor2-wikipedia.com
Processing Crawl job 855 for https://competitor2-wikipedia.com
ðŸ”„ STATE TRANSITION [Crawl 855]: waiting â†’ active (worker picked up job)
ðŸ“Š PROGRESS UPDATE [Crawl 855]: 10 pages crawled
No robots.txt found
Could not parse sitemap: https://competitor2-wikipedia.com/sitemap.xml
Could not parse sitemap: https://competitor2-wikipedia.com/sitemap_index.xml
Could not parse sitemap: https://competitor2-wikipedia.com/sitemap.txt
Could not parse sitemap: https://competitor2-wikipedia.com/sitemaps.xml
Could not parse sitemap: https://competitor2-wikipedia.com/sitemap-index.xml
Could not parse sitemap: https://competitor2-wikipedia.com/wp-sitemap.xml
Could not parse sitemap: https://competitor2-wikipedia.com/page-sitemap.xml
Crawling (1/10): https://competitor2-wikipedia.com
ðŸ“Š PROGRESS UPDATE [Crawl 855]: 1 pages crawled
ðŸ§  Running Rule Engine for crawl analysis null
âœ… Added 0 rule-based recommendations
ðŸ“Š Added RUM data with 0 samples
ðŸ” Running Change Detection for crawl https://competitor2-wikipedia.com
ðŸ“¸ Created snapshot 4d68158d-c8ba-493e-8cf9-e6f0be7f86f4 for https://competitor2-wikipedia.com
ðŸ“Š First snapshot created for https://competitor2-wikipedia.com - no changes to detect
ðŸ“Š PROGRESS UPDATE [Crawl 855]: 100 pages crawled
Crawl job 855 completed in 167ms
ðŸ”„ STATE TRANSITION [Crawl 855]: active â†’ completed (resultId: crawl_855_1759808634612)
ðŸ¤– Crawling competitor 3/3: https://competitor3-wikipedia.com
Added Crawl job 856 for https://competitor3-wikipedia.com
Processing Crawl job 856 for https://competitor3-wikipedia.com
ðŸ”„ STATE TRANSITION [Crawl 856]: waiting â†’ active (worker picked up job)
ðŸ“Š PROGRESS UPDATE [Crawl 856]: 10 pages crawled
No robots.txt found
Could not parse sitemap: https://competitor3-wikipedia.com/sitemap.xml
Could not parse sitemap: https://competitor3-wikipedia.com/sitemap_index.xml
Could not parse sitemap: https://competitor3-wikipedia.com/sitemap.txt
Could not parse sitemap: https://competitor3-wikipedia.com/sitemaps.xml
Could not parse sitemap: https://competitor3-wikipedia.com/sitemap-index.xml
Could not parse sitemap: https://competitor3-wikipedia.com/wp-sitemap.xml
Could not parse sitemap: https://competitor3-wikipedia.com/page-sitemap.xml
Crawling (1/10): https://competitor3-wikipedia.com
ðŸ“Š PROGRESS UPDATE [Crawl 856]: 1 pages crawled
ðŸ§  Running Rule Engine for crawl analysis null
âœ… Added 0 rule-based recommendations
ðŸ“Š Added RUM data with 0 samples
ðŸ” Running Change Detection for crawl https://competitor3-wikipedia.com
ðŸ“¸ Created snapshot a88706bb-159b-4e16-996f-5345f46dc16e for https://competitor3-wikipedia.com
ðŸ“Š First snapshot created for https://competitor3-wikipedia.com - no changes to detect
ðŸ“Š PROGRESS UPDATE [Crawl 856]: 100 pages crawled
Crawl job 856 completed in 165ms
ðŸ”„ STATE TRANSITION [Crawl 856]: active â†’ completed (resultId: crawl_856_1759808636622)
ðŸ¤– Step 4: Generating AI report with DeepSeek
ðŸ¤– Step 5: Saving AI report
ðŸ¤– AI Analysis job 3 completed in 26452ms
ðŸ”„ STATE TRANSITION [AI Analysis 3]: waiting â†’ completed
ðŸ“Š Memory [queue-workers-0]: RSS 339MB, Heap 129MB
ðŸ“Š Memory [queue-workers-0]: RSS 192MB, Heap 78MB
ðŸ“Š Memory [queue-workers-0]: RSS 190MB, Heap 78MB
ðŸ“Š Memory [queue-workers-0]: RSS 191MB, Heap 78MB
ðŸ“Š Memory [queue-workers-0]: RSS 190MB, Heap 78MB
ðŸ“Š Memory [queue-workers-0]: RSS 190MB, Heap 78MB
ðŸ“Š Memory [queue-workers-0]: RSS 190MB, Heap 78MB
ðŸ“Š Memory [queue-workers-0]: RSS 191MB, Heap 79MB
ðŸ“Š Memory [queue-workers-0]: RSS 191MB, Heap 79MB
ðŸ“Š Memory [queue-workers-0]: RSS 192MB, Heap 79MB
ðŸ“Š Memory [queue-workers-0]: RSS 191MB, Heap 79MB
ðŸ“Š Memory [queue-workers-0]: RSS 190MB, Heap 79MB
ðŸ“Š Memory [queue-workers-0]: RSS 191MB, Heap 79MB
ðŸ“Š Memory [queue-workers-0]: RSS 191MB, Heap 79MB
âœ… Using Prisma singleton for database connection
Queue worker using Chrome at: /usr/bin/chromium
PM2 Instance: 0, Running Lighthouse: true
ðŸ•·ï¸ Creating Crawl worker (enabled=true, isMainInstance=true)
ðŸ”’ Memory guard started for queue-workers-0 (limit: 1100MB)
[STORAGE] Local artifact storage initialized at /home/reda/seo-analyzer-nextjs/artifacts
âœ… Connected to Redis
ðŸ“Š Memory [queue-workers-0]: RSS 116MB, Heap 31MB
ðŸ“Š Memory [queue-workers-0]: RSS 88MB, Heap 27MB
ðŸ“Š Memory [queue-workers-0]: RSS 89MB, Heap 28MB
ðŸ“Š Memory [queue-workers-0]: RSS 87MB, Heap 27MB
ðŸ¤– Processing AI Analysis job 74 for https://seoanalyze.se/
ðŸ¤– Step 1: Analyzing user's website https://seoanalyze.se/
ðŸ”„ STATE TRANSITION [AI Analysis 74]: waiting â†’ active (worker picked up job)
ðŸ¤– Created SEO analysis: cmglg5k3e0000r20otjj7ruu2, Crawl analysis: cmglg5k3r0001r20oah3p3hkc, Lighthouse analysis: cmglg5k3u0002r20oz5d23qii
Added SEO job 5314 for https://seoanalyze.se/
Processing SEO job 5314 for https://seoanalyze.se/
ðŸ”„ STATE TRANSITION [SEO 5314]: waiting â†’ active (worker picked up job)
Added Crawl job 1027 for https://seoanalyze.se/
Processing Crawl job 1027 for https://seoanalyze.se/
ðŸ“Š PROGRESS UPDATE [SEO 5314]: 10%
ðŸ”„ STATE TRANSITION [Crawl 1027]: waiting â†’ active (worker picked up job)
Added Lighthouse job 504 for https://seoanalyze.se/
Processing Lighthouse job 504 for https://seoanalyze.se/
ðŸ¤– Waiting for user SEO (5314), Crawl (1027), and Lighthouse (504)
ðŸ“Š PROGRESS UPDATE [Crawl 1027]: 10 pages crawled
ðŸ”„ STATE TRANSITION [Lighthouse 504]: waiting â†’ active (worker picked up job)
ðŸ“Š PROGRESS UPDATE [Lighthouse 504]: 10%
Loading ES modules...
Loaded robots.txt
Could not parse sitemap: https://seoanalyzer.se/sitemap.xml
ðŸ“Š PROGRESS UPDATE [SEO 5314]: 30%
DEBUG: HTML retrieved for https://seoanalyze.se/, HTML sample=<!DOCTYPE html><!--9cgQzoniMRb1BVtM0dP4u--><html lang="sv"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" as="image" imageSrcSet=
DEBUG: performSeoAnalysis creating new Cheerio instance for https://seoanalyze.se/
DEBUG: Cheerio version: 1.1.2
DEBUG: URL=https://seoanalyze.se/, Cheerio found 0 scripts, 0 JSON-LD
DEBUG: Using regex fallback for JSON-LD extraction
Found JSON-LD via regex: {"@context":"https://schema.org","@graph":[{"@type":"Organization","@id":"https://seoanalyze.se/#org...
Schema detection: found 1 scripts, hasSchema: true, types: Organization,WebSite,SoftwareApplication,BreadcrumbList
robots.txt check: true
Could not parse sitemap: https://seoanalyze.se/sitemap_index.xml
sitemap.xml check: true
Could not parse sitemap: https://seoanalyze.se/sitemap.txt
ðŸ“Š PROGRESS UPDATE [SEO 5314]: 90%
[SCREENSHOT] start id=cmglg5k3e0000r20otjj7ruu2 url=https://seoanalyze.se/
Creating new browser instance...
Could not parse sitemap: https://seoanalyze.se/sitemaps.xml
Could not parse sitemap: https://seoanalyze.se/sitemap-index.xml
Could not parse sitemap: https://seoanalyze.se/wp-sitemap.xml
Could not parse sitemap: https://seoanalyze.se/page-sitemap.xml
Found 6 URLs in sitemap - using sitemap-first strategy
Crawling (1/100): https://seoanalyze.se/
Robots.txt blocks: https://seoanalyzer.se/
Robots.txt blocks: https://seoanalyzer.se/seo-analys
Robots.txt blocks: https://seoanalyzer.se/lighthouse-analys
Robots.txt blocks: https://seoanalyzer.se/crawl-analys
Robots.txt blocks: https://seoanalyzer.se/integritetspolicy
Robots.txt blocks: https://seoanalyzer.se/anvandarvillkor
Using Chrome path: /usr/bin/chromium
Chrome flags: 14 flags configured
ðŸ“Š PROGRESS UPDATE [Crawl 1027]: 1 pages crawled
Browser instance created
Browser acquired from pool (1 in pool, 0 available)
Lighthouse categories: performance, accessibility, seo, best-practices
Crawling (2/100): https://seoanalyze.se/ai-analys
ðŸ“Š PROGRESS UPDATE [Crawl 1027]: 2 pages crawled
Crawling (3/100): https://seoanalyze.se/integritetspolicy
ðŸ“Š PROGRESS UPDATE [Crawl 1027]: 3 pages crawled
ðŸ§  Running Rule Engine for crawl analysis cmglg5k3r0001r20oah3p3hkc
âœ… Added 0 rule-based recommendations
ðŸ“Š Added RUM data with 128 samples
ðŸ” Running Change Detection for crawl https://seoanalyze.se/
ðŸ“¸ Created snapshot fdc522fc-bf47-4747-aaf3-3bbe7955121c for https://seoanalyze.se/
ðŸ“Š PROGRESS UPDATE [Crawl 1027]: 100 pages crawled
Crawl job 1027 completed in 5237ms
ðŸ’¾ Updating Crawl analysis cmglg5k3r0001r20oah3p3hkc in database
ðŸ’¾ DB results uppdaterade fÃ¶r crawl cmglg5k3r0001r20oah3p3hkc
ðŸ“ Updated analysis cmglg5k3r0001r20oah3p3hkc status to completed
[SAVE] Saved artifact locally: analyses/2025-10-10/cmglg5k3r0001r20oah3p3hkc/crawl-results.json
âœ… Crawl analysis cmglg5k3r0001r20oah3p3hkc updated in database and artifacts
ðŸ“Š METRICS [Crawl]: domain=seoanalyze.se, score=100, issuesCount=0, durationMs=5452, pagesCount=3
ðŸ”„ STATE TRANSITION [Crawl 1027]: active â†’ completed (resultId: cmglg5k3r0001r20oah3p3hkc)
Processing SEO job 5315 for https://seoanalyze.se/
ðŸ”„ STATE TRANSITION [SEO 5315]: waiting â†’ active (worker picked up job)
ðŸ“Š PROGRESS UPDATE [SEO 5315]: 10%
ðŸ“Š PROGRESS UPDATE [SEO 5315]: 30%
DEBUG: HTML retrieved for https://seoanalyze.se/, HTML sample=<!DOCTYPE html><!--9cgQzoniMRb1BVtM0dP4u--><html lang="sv"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" as="image" imageSrcSet=
DEBUG: performSeoAnalysis creating new Cheerio instance for https://seoanalyze.se/
DEBUG: Cheerio version: 1.1.2
DEBUG: URL=https://seoanalyze.se/, Cheerio found 0 scripts, 0 JSON-LD
DEBUG: Using regex fallback for JSON-LD extraction
Found JSON-LD via regex: {"@context":"https://schema.org","@graph":[{"@type":"Organization","@id":"https://seoanalyze.se/#org...
Schema detection: found 1 scripts, hasSchema: true, types: Organization,WebSite,SoftwareApplication,BreadcrumbList
ðŸ“Š Memory [queue-workers-0]: RSS 218MB, Heap 91MB
robots.txt check: true
sitemap.xml check: true
ðŸ“Š PROGRESS UPDATE [SEO 5315]: 90%
[SCREENSHOT] start id=01K785G3MDX96J19JC3BYDPXV2 url=https://seoanalyze.se/
Creating new browser instance...
Browser instance created
Browser acquired from pool (2 in pool, 0 available)
[SAVE] Saved artifact locally: analyses/2025-10-10/cmglg5k3e0000r20otjj7ruu2/screenshots/desktop.png
[SCREENSHOT] desktop OK key=analyses/2025-10-10/cmglg5k3e0000r20otjj7ruu2/screenshots/desktop.png
[SAVE] Saved artifact locally: analyses/2025-10-10/01K785G3MDX96J19JC3BYDPXV2/screenshots/desktop.png
[SCREENSHOT] desktop OK key=analyses/2025-10-10/01K785G3MDX96J19JC3BYDPXV2/screenshots/desktop.png
[SAVE] Saved artifact locally: analyses/2025-10-10/cmglg5k3e0000r20otjj7ruu2/screenshots/mobile.png
[SCREENSHOT] mobile OK key=analyses/2025-10-10/cmglg5k3e0000r20otjj7ruu2/screenshots/mobile.png
Browser operation completed in 7495ms
Browser released to pool
[SAVE] Saved artifact locally: analyses/2025-10-10/cmglg5k3e0000r20otjj7ruu2/seo-results.json
ðŸ“ Updated analysis cmglg5k3e0000r20otjj7ruu2 status to completed
ðŸ’¾ Saved SEO analysis cmglg5k3e0000r20otjj7ruu2 to database and artifacts
ðŸ“¸ Created snapshot 82c8566c-90aa-48aa-b4e1-578ce63c0308 for https://seoanalyze.se/
ðŸ“Š PROGRESS UPDATE [SEO 5314]: 100%
SEO job 5314 completed in 10396ms
ðŸ“Š METRICS [SEO]: domain=seoanalyze.se, score=98, issuesCount=0, durationMs=10396
ðŸ”„ STATE TRANSITION [SEO 5314]: active â†’ completed (resultId: cmglg5k3e0000r20otjj7ruu2)
Processing Crawl job 1028 for https://seoanalyze.se/
ðŸ”„ STATE TRANSITION [Crawl 1028]: completed â†’ active (worker picked up job)
ðŸ“Š PROGRESS UPDATE [Crawl 1028]: 10 pages crawled
Loaded robots.txt
Could not parse sitemap: https://seoanalyzer.se/sitemap.xml
Could not parse sitemap: https://seoanalyze.se/sitemap_index.xml
Could not parse sitemap: https://seoanalyze.se/sitemap.txt
Could not parse sitemap: https://seoanalyze.se/sitemaps.xml
Could not parse sitemap: https://seoanalyze.se/sitemap-index.xml
Could not parse sitemap: https://seoanalyze.se/wp-sitemap.xml
Could not parse sitemap: https://seoanalyze.se/page-sitemap.xml
Found 6 URLs in sitemap - using sitemap-first strategy
Crawling (1/10): https://seoanalyze.se/
Robots.txt blocks: https://seoanalyzer.se/
Robots.txt blocks: https://seoanalyzer.se/seo-analys
Robots.txt blocks: https://seoanalyzer.se/lighthouse-analys
Robots.txt blocks: https://seoanalyzer.se/crawl-analys
Robots.txt blocks: https://seoanalyzer.se/integritetspolicy
Robots.txt blocks: https://seoanalyzer.se/anvandarvillkor
ðŸ“Š PROGRESS UPDATE [Crawl 1028]: 1 pages crawled
Crawling (2/10): https://seoanalyze.se/ai-analys
ðŸ“Š PROGRESS UPDATE [Crawl 1028]: 2 pages crawled
[SAVE] Saved artifact locally: analyses/2025-10-10/01K785G3MDX96J19JC3BYDPXV2/screenshots/mobile.png
[SCREENSHOT] mobile OK key=analyses/2025-10-10/01K785G3MDX96J19JC3BYDPXV2/screenshots/mobile.png
Browser operation completed in 6247ms
Browser released to pool
[SAVE] Saved artifact locally: analyses/2025-10-10/01K785G3MDX96J19JC3BYDPXV2/seo-results.json
ðŸ“ Updated analysis 01K785G3MDX96J19JC3BYDPXV2 status to completed
ðŸ’¾ Saved SEO analysis 01K785G3MDX96J19JC3BYDPXV2 to database and artifacts
Crawling (3/10): https://seoanalyze.se/integritetspolicy
ðŸ“¸ Created snapshot 617213f9-9982-4ab2-b3a1-e039ad517963 for https://seoanalyze.se/
ðŸ“Š PROGRESS UPDATE [Crawl 1028]: 3 pages crawled
ðŸ“Š PROGRESS UPDATE [SEO 5315]: 100%
SEO job 5315 completed in 7331ms
ðŸ“Š METRICS [SEO]: domain=seoanalyze.se, score=98, issuesCount=0, durationMs=7332
ðŸ”„ STATE TRANSITION [SEO 5315]: active â†’ completed (resultId: 01K785G3MDX96J19JC3BYDPXV2)
ðŸ§  Running Rule Engine for crawl analysis 01K785G8F63D4GFJKMTSF5W0QB
âœ… Added 0 rule-based recommendations
ðŸ“Š Added RUM data with 128 samples
ðŸ” Running Change Detection for crawl https://seoanalyze.se/
ðŸ“¸ Created snapshot d5eb32e8-041d-40d3-8187-e519c10045d4 for https://seoanalyze.se/
ðŸ“Š PROGRESS UPDATE [Crawl 1028]: 100 pages crawled
Crawl job 1028 completed in 2499ms
ðŸ’¾ Updating Crawl analysis 01K785G8F63D4GFJKMTSF5W0QB in database
ðŸ’¾ DB results uppdaterade fÃ¶r crawl 01K785G8F63D4GFJKMTSF5W0QB
ðŸ“ Updated analysis 01K785G8F63D4GFJKMTSF5W0QB status to completed
[SAVE] Saved artifact locally: analyses/2025-10-10/01K785G8F63D4GFJKMTSF5W0QB/crawl-results.json
âœ… Crawl analysis 01K785G8F63D4GFJKMTSF5W0QB updated in database and artifacts
ðŸ“Š METRICS [Crawl]: domain=seoanalyze.se, score=100, issuesCount=0, durationMs=3193, pagesCount=3
ðŸ”„ STATE TRANSITION [Crawl 1028]: waiting â†’ completed (resultId: 01K785G8F63D4GFJKMTSF5W0QB)
Chrome process 4684 killed successfully
Cleaned up temp directory: /tmp/lighthouse-1760137052734-1lbfv6d3-1320
ðŸ“Š PROGRESS UPDATE [Lighthouse 504]: 90%
ðŸ§  Running Rule Engine for analysis cmglg5k3u0002r20oz5d23qii
âœ… Added 0 rule-based recommendations
ðŸ“Š Added RUM data with 128 samples
ðŸ” Running Change Detection for https://seoanalyze.se/
ðŸ“¸ Created snapshot ca30c54c-1fc4-4460-b2b3-56a67f4f8469 for https://seoanalyze.se/
ðŸ“Š PROGRESS UPDATE [Lighthouse 504]: 100%
Lighthouse job 504 completed in 19564ms
ðŸ’¾ Updating Lighthouse analysis cmglg5k3u0002r20oz5d23qii in database
ðŸ’¾ DB results uppdaterade fÃ¶r cmglg5k3u0002r20oz5d23qii
ðŸ“ Updated analysis cmglg5k3u0002r20oz5d23qii status to completed
[SAVE] Saved artifact locally: analyses/2025-10-10/cmglg5k3u0002r20oz5d23qii/lighthouse-results.json
âœ… Lighthouse analysis cmglg5k3u0002r20oz5d23qii updated in database and artifacts
ðŸ“Š METRICS [Lighthouse]: domain=seoanalyze.se, score=80, issuesCount=2, durationMs=19576
Processing Lighthouse job 505 for https://seoanalyze.se/
ðŸ”„ STATE TRANSITION [Lighthouse 505]: waiting â†’ active (worker picked up job)
ðŸ”„ STATE TRANSITION [Lighthouse 504]: active â†’ completed (resultId: cmglg5k3u0002r20oz5d23qii)
ðŸ“Š PROGRESS UPDATE [Lighthouse 505]: 10%
Loading ES modules...
Using Chrome path: /usr/bin/chromium
Chrome flags: 14 flags configured
Lighthouse categories: performance, accessibility, seo, best-practices
ðŸ¤– SEO, Crawl, and Lighthouse jobs completed successfully
ðŸ¤– Fetched full data from DB - SEO has summary: true, Crawl has summary: true, Lighthouse has summary: true
ðŸ¤– Step 2: Using 0 user-provided competitors: []
ðŸ¤– Step 3: Crawling 0 competitors
ðŸ¤– Step 4: Generating AI report with DeepSeek
ðŸ¤– Step 5: Saving AI report
ðŸ¤– AI Analysis job 74 completed in 21948ms
ðŸ”„ STATE TRANSITION [AI Analysis 74]: waiting â†’ completed
Chrome process 5225 killed successfully
Cleaned up temp directory: /tmp/lighthouse-1760137070097-eiz72wxn-1320
ðŸ“Š PROGRESS UPDATE [Lighthouse 505]: 90%
ðŸ§  Running Rule Engine for analysis 01K785GCF77Q14RSKKNF74Z1ET
âœ… Added 0 rule-based recommendations
ðŸ“Š Added RUM data with 128 samples
ðŸ” Running Change Detection for https://seoanalyze.se/
ðŸ“¸ Created snapshot 0079db02-3a42-4e6c-ad8c-eed689d44343 for https://seoanalyze.se/
ðŸ“Š PROGRESS UPDATE [Lighthouse 505]: 100%
Lighthouse job 505 completed in 13703ms
ðŸ’¾ Updating Lighthouse analysis 01K785GCF77Q14RSKKNF74Z1ET in database
ðŸ’¾ DB results uppdaterade fÃ¶r 01K785GCF77Q14RSKKNF74Z1ET
ðŸ“ Updated analysis 01K785GCF77Q14RSKKNF74Z1ET status to completed
[SAVE] Saved artifact locally: analyses/2025-10-10/01K785GCF77Q14RSKKNF74Z1ET/lighthouse-results.json
âœ… Lighthouse analysis 01K785GCF77Q14RSKKNF74Z1ET updated in database and artifacts
ðŸ“Š METRICS [Lighthouse]: domain=seoanalyze.se, score=90, issuesCount=4, durationMs=13717
ðŸ”„ STATE TRANSITION [Lighthouse 505]: active â†’ completed (resultId: 01K785GCF77Q14RSKKNF74Z1ET)
ðŸ“Š Memory [queue-workers-0]: RSS 347MB, Heap 188MB
Destroying browser instance...
Destroying browser instance...
Browser instance destroyed
Browser instance destroyed
ðŸ“Š Memory [queue-workers-0]: RSS 241MB, Heap 107MB
ðŸ“Š Memory [queue-workers-0]: RSS 241MB, Heap 107MB
ðŸ“Š Memory [queue-workers-0]: RSS 241MB, Heap 107MB
ðŸ“Š Memory [queue-workers-0]: RSS 241MB, Heap 107MB
ðŸ¤– Processing AI Analysis job 75 for https://seoanalyze.se
ðŸ¤– Step 1: Analyzing user's website https://seoanalyze.se
ðŸ”„ STATE TRANSITION [AI Analysis 75]: waiting â†’ active (worker picked up job)
ðŸ¤– Created SEO analysis: cmglg94y20003r20o0vbttckq, Crawl analysis: cmglg94yu0004r20omxt318c0, Lighthouse analysis: cmglg94z70005r20ojs781nvm
Added SEO job 5316 for https://seoanalyze.se
Processing SEO job 5316 for https://seoanalyze.se
Added Crawl job 1029 for https://seoanalyze.se
ðŸ”„ STATE TRANSITION [SEO 5316]: waiting â†’ active (worker picked up job)
Processing Crawl job 1029 for https://seoanalyze.se
ðŸ”„ STATE TRANSITION [Crawl 1029]: waiting â†’ active (worker picked up job)
ðŸ“Š PROGRESS UPDATE [SEO 5316]: 10%
Added Lighthouse job 506 for https://seoanalyze.se
Processing Lighthouse job 506 for https://seoanalyze.se
ðŸ¤– Waiting for user SEO (5316), Crawl (1029), and Lighthouse (506)
ðŸ“Š PROGRESS UPDATE [Crawl 1029]: 10 pages crawled
ðŸ”„ STATE TRANSITION [Lighthouse 506]: waiting â†’ active (worker picked up job)
ðŸ“Š PROGRESS UPDATE [Lighthouse 506]: 10%
Loading ES modules...
Using Chrome path: /usr/bin/chromium
Chrome flags: 14 flags configured
Loaded robots.txt
Could not parse sitemap: https://seoanalyzer.se/sitemap.xml
ðŸ“Š PROGRESS UPDATE [SEO 5316]: 30%
DEBUG: HTML retrieved for https://seoanalyze.se, HTML sample=<!DOCTYPE html><!--9cgQzoniMRb1BVtM0dP4u--><html lang="sv"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" as="image" imageSrcSet=
DEBUG: performSeoAnalysis creating new Cheerio instance for https://seoanalyze.se
DEBUG: Cheerio version: 1.1.2
DEBUG: URL=https://seoanalyze.se, Cheerio found 0 scripts, 0 JSON-LD
DEBUG: Using regex fallback for JSON-LD extraction
Found JSON-LD via regex: {"@context":"https://schema.org","@graph":[{"@type":"Organization","@id":"https://seoanalyze.se/#org...
Schema detection: found 1 scripts, hasSchema: true, types: Organization,WebSite,SoftwareApplication,BreadcrumbList
robots.txt check: true
sitemap.xml check: true
Could not parse sitemap: https://seoanalyze.se/sitemap_index.xml
ðŸ“Š PROGRESS UPDATE [SEO 5316]: 90%
[SCREENSHOT] start id=cmglg94y20003r20o0vbttckq url=https://seoanalyze.se
Creating new browser instance...
Could not parse sitemap: https://seoanalyze.se/sitemap.txt
Could not parse sitemap: https://seoanalyze.se/sitemaps.xml
Could not parse sitemap: https://seoanalyze.se/sitemap-index.xml
Could not parse sitemap: https://seoanalyze.se/wp-sitemap.xml
Could not parse sitemap: https://seoanalyze.se/page-sitemap.xml
Found 6 URLs in sitemap - using sitemap-first strategy
Crawling (1/100): https://seoanalyze.se
Robots.txt blocks: https://seoanalyzer.se/
Robots.txt blocks: https://seoanalyzer.se/seo-analys
Robots.txt blocks: https://seoanalyzer.se/lighthouse-analys
Robots.txt blocks: https://seoanalyzer.se/crawl-analys
Robots.txt blocks: https://seoanalyzer.se/integritetspolicy
Robots.txt blocks: https://seoanalyzer.se/anvandarvillkor
ðŸ“Š PROGRESS UPDATE [Crawl 1029]: 1 pages crawled
Lighthouse categories: performance, accessibility, seo, best-practices
Browser instance created
Browser acquired from pool (1 in pool, 0 available)
Crawling (2/100): https://seoanalyze.se/
ðŸ“Š PROGRESS UPDATE [Crawl 1029]: 2 pages crawled
Crawling (3/100): https://seoanalyze.se/ai-analys
ðŸ“Š PROGRESS UPDATE [Crawl 1029]: 3 pages crawled
Crawling (4/100): https://seoanalyze.se/integritetspolicy
ðŸ“Š PROGRESS UPDATE [Crawl 1029]: 4 pages crawled
ðŸ§  Running Rule Engine for crawl analysis cmglg94yu0004r20omxt318c0
âœ… Added 0 rule-based recommendations
ðŸ“Š Added RUM data with 0 samples
ðŸ” Running Change Detection for crawl https://seoanalyze.se
ðŸ“¸ Created snapshot 358a5a95-d06c-4bfd-ad7b-ca7b941308d3 for https://seoanalyze.se
ðŸ“Š PROGRESS UPDATE [Crawl 1029]: 100 pages crawled
Crawl job 1029 completed in 4092ms
ðŸ’¾ Updating Crawl analysis cmglg94yu0004r20omxt318c0 in database
ðŸ’¾ DB results uppdaterade fÃ¶r crawl cmglg94yu0004r20omxt318c0
ðŸ“ Updated analysis cmglg94yu0004r20omxt318c0 status to completed
[SAVE] Saved artifact locally: analyses/2025-10-10/cmglg94yu0004r20omxt318c0/crawl-results.json
âœ… Crawl analysis cmglg94yu0004r20omxt318c0 updated in database and artifacts
ðŸ“Š METRICS [Crawl]: domain=seoanalyze.se, score=100, issuesCount=0, durationMs=4131, pagesCount=4
ðŸ”„ STATE TRANSITION [Crawl 1029]: active â†’ completed (resultId: cmglg94yu0004r20omxt318c0)
[SAVE] Saved artifact locally: analyses/2025-10-10/cmglg94y20003r20o0vbttckq/screenshots/desktop.png
[SCREENSHOT] desktop OK key=analyses/2025-10-10/cmglg94y20003r20o0vbttckq/screenshots/desktop.png
[SAVE] Saved artifact locally: analyses/2025-10-10/cmglg94y20003r20o0vbttckq/screenshots/mobile.png
[SCREENSHOT] mobile OK key=analyses/2025-10-10/cmglg94y20003r20o0vbttckq/screenshots/mobile.png
Browser operation completed in 5192ms
Browser released to pool
[SAVE] Saved artifact locally: analyses/2025-10-10/cmglg94y20003r20o0vbttckq/seo-results.json
ðŸ“ Updated analysis cmglg94y20003r20o0vbttckq status to completed
ðŸ’¾ Saved SEO analysis cmglg94y20003r20o0vbttckq to database and artifacts
ðŸ“¸ Created snapshot b9897fe8-91f0-4edc-acb5-b3d9f044e502 for https://seoanalyze.se
ðŸ“Š PROGRESS UPDATE [SEO 5316]: 100%
SEO job 5316 completed in 7056ms
ðŸ“Š METRICS [SEO]: domain=seoanalyze.se, score=98, issuesCount=0, durationMs=7056
ðŸ”„ STATE TRANSITION [SEO 5316]: active â†’ completed (resultId: cmglg94y20003r20o0vbttckq)
Chrome process 6516 killed successfully
Cleaned up temp directory: /tmp/lighthouse-1760137217434-igrik7tx-1320
ðŸ“Š PROGRESS UPDATE [Lighthouse 506]: 90%
ðŸ§  Running Rule Engine for analysis cmglg94z70005r20ojs781nvm
âœ… Added 0 rule-based recommendations
ðŸ“Š Added RUM data with 0 samples
ðŸ” Running Change Detection for https://seoanalyze.se
ðŸ“¸ Created snapshot 2cbfcbe8-7288-4c08-b291-5b1c9ea0cbeb for https://seoanalyze.se
ðŸ“Š PROGRESS UPDATE [Lighthouse 506]: 100%
Lighthouse job 506 completed in 14390ms
ðŸ’¾ Updating Lighthouse analysis cmglg94z70005r20ojs781nvm in database
ðŸ’¾ DB results uppdaterade fÃ¶r cmglg94z70005r20ojs781nvm
ðŸ“ Updated analysis cmglg94z70005r20ojs781nvm status to completed
[SAVE] Saved artifact locally: analyses/2025-10-10/cmglg94z70005r20ojs781nvm/lighthouse-results.json
âœ… Lighthouse analysis cmglg94z70005r20ojs781nvm updated in database and artifacts
ðŸ“Š METRICS [Lighthouse]: domain=seoanalyze.se, score=87, issuesCount=2, durationMs=14406
ðŸ”„ STATE TRANSITION [Lighthouse 506]: active â†’ completed (resultId: cmglg94z70005r20ojs781nvm)
ðŸ¤– SEO, Crawl, and Lighthouse jobs completed successfully
ðŸ¤– Fetched full data from DB - SEO has summary: true, Crawl has summary: true, Lighthouse has summary: true
ðŸ¤– Step 2: Using 0 user-provided competitors: []
ðŸ¤– Step 3: Crawling 0 competitors
ðŸ¤– Step 4: Generating AI report with DeepSeek
ðŸ¤– Step 5: Saving AI report
ðŸ¤– AI Analysis job 75 completed in 16572ms
ðŸ”„ STATE TRANSITION [AI Analysis 75]: waiting â†’ completed
ðŸ“Š Memory [queue-workers-0]: RSS 345MB, Heap 119MB
Destroying browser instance...
Browser instance destroyed
ðŸ“Š Memory [queue-workers-0]: RSS 246MB, Heap 107MB
ðŸ“Š Memory [queue-workers-0]: RSS 245MB, Heap 107MB
ðŸ“Š Memory [queue-workers-0]: RSS 246MB, Heap 107MB
ðŸ“Š Memory [queue-workers-0]: RSS 245MB, Heap 107MB
ðŸ“Š Memory [queue-workers-0]: RSS 245MB, Heap 107MB
ðŸ“Š Memory [queue-workers-0]: RSS 246MB, Heap 108MB
ðŸ¤– Processing AI Analysis job 76 for https://nobina.se
ðŸ¤– Step 1: Analyzing user's website https://nobina.se
ðŸ”„ STATE TRANSITION [AI Analysis 76]: waiting â†’ active (worker picked up job)
ðŸ¤– Created SEO analysis: cmglgdntx0006r20o2fd9gbak, Crawl analysis: cmglgdnu40007r20ouxpfq8x1, Lighthouse analysis: cmglgdnu80008r20orgkx0wih
Added SEO job 5317 for https://nobina.se
Processing SEO job 5317 for https://nobina.se
ðŸ”„ STATE TRANSITION [SEO 5317]: waiting â†’ active (worker picked up job)
Added Crawl job 1030 for https://nobina.se
Processing Crawl job 1030 for https://nobina.se
ðŸ“Š PROGRESS UPDATE [SEO 5317]: 10%
ðŸ”„ STATE TRANSITION [Crawl 1030]: waiting â†’ active (worker picked up job)
Added Lighthouse job 507 for https://nobina.se
Processing Lighthouse job 507 for https://nobina.se
ðŸ¤– Waiting for user SEO (5317), Crawl (1030), and Lighthouse (507)
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 10 pages crawled
ðŸ”„ STATE TRANSITION [Lighthouse 507]: waiting â†’ active (worker picked up job)
ðŸ“Š PROGRESS UPDATE [Lighthouse 507]: 10%
Loading ES modules...
Using Chrome path: /usr/bin/chromium
Chrome flags: 14 flags configured
Loaded robots.txt
ðŸ“Š PROGRESS UPDATE [SEO 5317]: 30%
DEBUG: HTML retrieved for https://nobina.se, HTML sample=<!doctype html> <html lang="sv"> <head> <meta charset="utf-8"> <meta http-equiv="X-UA-Compatible" content="IE=edge" /> <meta name="viewport" content="width=device-width, initial-scale
DEBUG: performSeoAnalysis creating new Cheerio instance for https://nobina.se
DEBUG: Cheerio version: 1.1.2
DEBUG: URL=https://nobina.se, Cheerio found 0 scripts, 0 JSON-LD
Schema detection: found 0 scripts, hasSchema: false, types: 
Lighthouse categories: performance, accessibility, seo, best-practices
robots.txt check: true
sitemap.xml check: true
ðŸ“Š PROGRESS UPDATE [SEO 5317]: 90%
[SCREENSHOT] start id=cmglgdntx0006r20o2fd9gbak url=https://nobina.se
Creating new browser instance...
Could not parse sitemap: https://nobina.se/sitemap_index.xml
Browser instance created
Browser acquired from pool (1 in pool, 0 available)
Could not parse sitemap: https://nobina.se/sitemap.txt
Could not parse sitemap: https://nobina.se/sitemaps.xml
Could not parse sitemap: https://nobina.se/sitemap-index.xml
Could not parse sitemap: https://nobina.se/wp-sitemap.xml
Could not parse sitemap: https://nobina.se/page-sitemap.xml
Found 320 URLs in sitemap - using sitemap-first strategy
Crawling (1/100): https://nobina.se
Robots.txt blocks: https://www.nobina.se/vara-losningar/hyr-buss/sweden-rock/sweden-rock-english/
Robots.txt blocks: https://www.nobina.se/vara-losningar/hyr-buss/sweden-rock/sa-funkar-nobina-biljetten/
Robots.txt blocks: https://www.nobina.se/vara-losningar/hyr-buss/sweden-rock/nobina-ticket-faq-english/
Robots.txt blocks: https://www.nobina.se/vara-losningar/hyr-buss/sweden-rock/nobina-yksittaisen-lipun-ukk/
Robots.txt blocks: https://www.nobina.se/jobba-hos-oss/nobina-som-arbetsgivare/vart-arbete-med-mangfald-och-inkludering/lingio/
Robots.txt blocks: https://www.nobina.se/jobba-hos-oss/nobina-som-arbetsgivare/vart-arbete-med-mangfald-och-inkludering/mitt-liv-mentorprogram/
Robots.txt blocks: https://www.nobina.se/jobba-hos-oss/nobina-som-arbetsgivare/vart-arbete-med-mangfald-och-inkludering/korta-vagen/
Robots.txt blocks: https://www.nobina.se/vara-losningar/hyr-buss/referenser-hyra-buss-hos-nobina/angsjo-lyftet-jarfalla/
Robots.txt blocks: https://www.nobina.se/vara-losningar/hyr-buss/referenser-hyra-buss-hos-nobina/stockholm-mean-machines/
Robots.txt blocks: https://www.nobina.se/vara-losningar/hyr-buss/nobina-eventtrafik/fragor-och-svar-nobina-eventtrafik/
Robots.txt blocks: https://www.nobina.se/vara-losningar/hyr-buss/nobina-hyrbuss/fragor-och-svar-nobina-hyrbuss/
Robots.txt blocks: https://www.nobina.se/vara-losningar/hyr-buss/referenser-nobina-eventtrafik/sweden-rock-festival/
Robots.txt blocks: https://www.nobina.se/vara-losningar/hyr-buss/referenser-nobina-eventtrafik/o-ringen/
Robots.txt blocks: https://www.nobina.se/om-oss/dataskydd-och-integritet/personuppgiftsbehandling/cookies/
Robots.txt blocks: https://www.nobina.se/jobba-hos-oss/nobina-som-arbetsgivare/en-trygg-resa-borjar-i-verkstaden/mot-vara-mekaniker/
Robots.txt blocks: https://www.nobina.se/jobba-hos-oss/nobina-som-arbetsgivare/en-trygg-resa-borjar-i-verkstaden/fordonsvard/
Robots.txt blocks: https://www.nobina.se/uppstart-nv/nacka-varmdo/om-oss/resenarsloftet/
Robots.txt blocks: https://www.nobina.se/uppstart-nv/nacka-varmdo/lokal-information/infobrev/
Robots.txt blocks: https://www.nobina.se/uppstart-karlstad/karlstad/om-oss/nobinas-resenarslofte/
Robots.txt blocks: https://www.nobina.se/uppstart-karlstad/karlstad/om-oss/vara-varderingar/
Robots.txt blocks: https://www.nobina.se/uppstart-karlstad/karlstad/om-oss/till-nobina.se/
Robots.txt blocks: https://www.nobina.se/uppstart-karlstad/karlstad/lokal-information/utbildning/
Robots.txt blocks: https://www.nobina.se/uppstart-stenungsund/stenungsund/om-oss/vara-varderingar/
Robots.txt blocks: https://www.nobina.se/uppstart-stenungsund/stenungsund/om-oss/till-nobina.se/
Robots.txt blocks: https://www.nobina.se/uppstart-stenungsund/stenungsund/om-oss/nobinas-uniform/
Robots.txt blocks: https://www.nobina.se/uppstart-umea/umea/lokal-information/vara-arbetssatt/
Robots.txt blocks: https://www.nobina.se/uppstart-stenungsund/stenungsund/lokal-information/
Robots.txt blocks: https://www.nobina.se/uppstart-stenungsund/stenungsund/fragor-och-svar/
Robots.txt blocks: https://www.nobina.se/uppstart-stenungsund/stenungsund/kontakt/
Robots.txt blocks: https://www.nobina.se/vara-losningar/nobina-forum/webinar-om-flexibel-on-demand-trafik/
Robots.txt blocks: https://www.nobina.se/nyheter/2025/nobina-och-vr-skriver-nobina-skriver-10-arigt-avtal-om-ersattningstrafik-for-norrtag/
Robots.txt blocks: https://www.nobina.se/nyheter/2025/nu-ar-vi-igang/
Robots.txt blocks: https://www.nobina.se/nyheter/2025/it-storningar-hos-nobina--nu-ar-systemen-igang/
Robots.txt blocks: https://www.nobina.se/nyheter/2025/just-nu-inget-trafikavtal-for-sodertorn-e45-efter-19-juni-2025/
Robots.txt blocks: https://www.nobina.se/nyheter/2025/farre-an-1-av-10-bussresenarer-anvander-balte-i-kollektivtrafiken/
Robots.txt blocks: https://www.nobina.se/nyheter/2025/forarnas-arbetsdag/
Robots.txt blocks: https://www.nobina.se/nyheter/2025/nobina-uppmarksammar-bussforarens-dag/
Robots.txt blocks: https://www.nobina.se/nyheter/2025/tack-alla-bussforare/
Robots.txt blocks: https://www.nobina.se/nyheter/2025/den-grona-resan--hallbarhet-i-varje-resa/
Robots.txt blocks: https://www.nobina.se/nyheter/2025/paxi---hallands-forsta-on-demand-buss/
Robots.txt blocks: https://www.nobina.se/nyheter/2025/utokat-fortroende-i-skane---tva-nya-avtal/
Robots.txt blocks: https://www.nobina.se/nyheter/2025/boras-hockey/
Robots.txt blocks: https://www.nobina.se/nyheter/2025/smart-laddning-av-elbussar/
Robots.txt blocks: https://www.nobina.se/nyheter/2025/framkomlighet-och-korbanebredd/
Robots.txt blocks: https://www.nobina.se/nyheter/2025/festivaltrafik-med-feeling-pa-sweden-rock/
Robots.txt blocks: https://www.nobina.se/nyheter/2025/gruppen-som-skapar-basta-forarmiljon/
Robots.txt blocks: https://www.nobina.se/nyheter/2025/nobina-kor-busstrafiken-i-karlstad-stad-fran-1-juli/
Robots.txt blocks: https://www.nobina.se/nyheter/2025/over-100-000-resenarer-pa-x-linjen/
Robots.txt blocks: https://www.nobina.se/nyheter/2025/nya-depan-i-timboholm/
Robots.txt blocks: https://www.nobina.se/nyheter/2025/trafikstart-pa-sodertorn/
Robots.txt blocks: https://www.nobina.se/nyheter/2025/nobinaforaren-josefin-kihlberg-vinner-bussforar-sm-2025/
Robots.txt blocks: https://www.nobina.se/nyheter/2025/nobinamekanikern-abbe-sveriges-represetant-i-euroskills/
Robots.txt blocks: https://www.nobina.se/nyheter/2025/nobina-vinner-fornyat-kontrakt-i-varmland/
Robots.txt blocks: https://www.nobina.se/uppstart-karlstad/karlstad/lokal-information/
Robots.txt blocks: https://www.nobina.se/jobba-hos-oss/bussforare/mot-vara-bussforare/
Robots.txt blocks: https://www.nobina.se/jobba-hos-oss/bussforare/bussforare-jobb/
Robots.txt blocks: https://www.nobina.se/jobba-hos-oss/mekaniker/lediga-jobb-verkstad-och-underhall/
Robots.txt blocks: https://www.nobina.se/varmland/jobba-hos-nobina-varmland/jobba-som-bussforare-i-varmland/
Robots.txt blocks: https://www.nobina.se/ostergotland/jobba-hos-nobina-ostergotland/jobba-som-bussforare-i-ostergotland/
Robots.txt blocks: https://www.nobina.se/ostergotland/jobba-hos-nobina-ostergotland/jobba-som-fordonsvardare-i-linkoping/
Robots.txt blocks: https://www.nobina.se/ostergotland/jobba-hos-nobina-ostergotland/jobba-som-fordonsvardsledare-i-linkoping/
Robots.txt blocks: https://www.nobina.se/ostergotland/jobba-hos-nobina-ostergotland/jobba-som-mekaniker-i-linkoping/
Robots.txt blocks: https://www.nobina.se/testcontainer/start/standard/
Robots.txt blocks: https://www.nobina.se/seminarier/tack/framkomlighetsrapporten-2023/
Robots.txt blocks: https://www.nobina.se/nyheter/2024/for-sakerhets-skull---anvand-balte/
Robots.txt blocks: https://www.nobina.se/nyheter/2024/lat-bilen-vila-och-ta-bussen---provakare-sokes-i-pitea/
Robots.txt blocks: https://www.nobina.se/nyheter/2024/x-linjen-tar-resenarerna-dit-de-vill/
Robots.txt blocks: https://www.nobina.se/nyheter/2024/framtidens-kollektivtrafik-i-sunne/
Robots.txt blocks: https://www.nobina.se/nyheter/2024/en-stor-andel-tjejer-och-yngre-nar-malmo-rekryterar-till-forarutbilning/
Robots.txt blocks: https://www.nobina.se/nyheter/2024/bussforaren-dag-for-tionde-aret/
Robots.txt blocks: https://www.nobina.se/nyheter/2024/10-arsjubileum-for-firandet-av-bussforarens-dag/
Robots.txt blocks: https://www.nobina.se/nyheter/2024/tack-alla-bussforare/
Robots.txt blocks: https://www.nobina.se/nyheter/2024/nobina-far-fornyat-fortroende-av-region-stockholm/
Robots.txt blocks: https://www.nobina.se/nyheter/2024/resandet-okar-med-buss-pa-bestallning-pa-morko/
Robots.txt blocks: https://www.nobina.se/nyheter/2024/narvarande-gruppchef-hjalper-forarna-att-gora-sitt-basta/
Robots.txt blocks: https://www.nobina.se/nyheter/2024/stort-soktryck-pa-nobinas-forarutbildningar-runtom-i-landet/
Robots.txt blocks: https://www.nobina.se/nyheter/2024/nobinas-forsta-eldrivna-regionbussar-rullar-i-skane/
Robots.txt blocks: https://www.nobina.se/nyheter/2024/nobina-lanserar-storningswebb-for-tagtrafiken/
Robots.txt blocks: https://www.nobina.se/nyheter/2024/nobina-busspartner-till-stockholm-pride-for-nionde-gangen/
Robots.txt blocks: https://www.nobina.se/nyheter/2024/fran-forare-till-mekaniker---mumin-hittade-hem-i-verkstaden/
Robots.txt blocks: https://www.nobina.se/nyheter/2024/nu-hejar-vi-pa-vara-finalister-pa-bussforar-sm/
Robots.txt blocks: https://www.nobina.se/nyheter/2024/nobinaforare-vann-titeln-sveriges-basta-bussforare/
Robots.txt blocks: https://www.nobina.se/nyheter/2024/on-demand-i-svalov---flexibel-kollektivtrafik-med-skaneflex/
Robots.txt blocks: https://www.nobina.se/nyheter/2024/Har-atervinns-80-av-tvattvattnet/
Robots.txt blocks: https://www.nobina.se/nyheter/2024/livekameror-okar-tryggheten-pa-malmos-bussar/
Robots.txt blocks: https://www.nobina.se/nyheter/2024/sjalvkorande-bussar-till-centralsjukhuset-i-karlstad/
Robots.txt blocks: https://www.nobina.se/nyheter/2024/flexibel-on-demand-trafik-brt-innovationer-och-ai-ger-fler-och-nya-resenarer/
Robots.txt blocks: https://www.nobina.se/nyheter/2024/nobina-tar-over-trafiken-i-umea-i-juni-2026/
Robots.txt blocks: https://www.nobina.se/nyheter/2024/nobina-forst-ut-med-realtidsdata-om-ersattningstrafik/
Robots.txt blocks: https://www.nobina.se/nyheter/2024/nobina-vinner-anbud-for-linje-321/
Robots.txt blocks: https://www.nobina.se/nyheter/2024/fornyat-fortroende-for-nobina-for-busstrafiken-boden--lulea/
Robots.txt blocks: https://www.nobina.se/nyheter/2024/nobina-vinner-omfattande-avtal-for-ersattningstrafik-for-tag-i-skane/
Robots.txt blocks: https://www.nobina.se/nyheter/2024/nobina-far-fornyat-fortroende-for-busstrafiken-i-malmo-stad/
Robots.txt blocks: https://www.nobina.se/nyheter/2024/100-procent-el-i-umea-stadstrafik-2026/
Robots.txt blocks: https://www.nobina.se/uppstart-hbs/huddinge-botkyrka-soderort/om-oss/
Robots.txt blocks: https://www.nobina.se/om-oss/vi-engagerar-oss/samarbetet-med-nobina-ar-vardefullt-och-viktigt/
Robots.txt blocks: https://www.nobina.se/om-oss/vi-engagerar-oss/stor-dag-fylld-med-ridning-och-gladje/
Robots.txt blocks: https://www.nobina.se/om-oss/vi-engagerar-oss/onskan-om-att-aka-buss-blev-sann/
Robots.txt blocks: https://www.nobina.se/om-oss/vi-engagerar-oss/nobina-ar-huvudpartner-till-min-stora-dag/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 1 pages crawled
[SAVE] Saved artifact locally: analyses/2025-10-10/cmglgdntx0006r20o2fd9gbak/screenshots/desktop.png
[SCREENSHOT] desktop OK key=analyses/2025-10-10/cmglgdntx0006r20o2fd9gbak/screenshots/desktop.png
[SAVE] Saved artifact locally: analyses/2025-10-10/cmglgdntx0006r20o2fd9gbak/screenshots/mobile.png
[SCREENSHOT] mobile OK key=analyses/2025-10-10/cmglgdntx0006r20o2fd9gbak/screenshots/mobile.png
Browser operation completed in 7787ms
Browser released to pool
[SAVE] Saved artifact locally: analyses/2025-10-10/cmglgdntx0006r20o2fd9gbak/seo-results.json
ðŸ“ Updated analysis cmglgdntx0006r20o2fd9gbak status to completed
ðŸ’¾ Saved SEO analysis cmglgdntx0006r20o2fd9gbak to database and artifacts
ðŸ“¸ Created snapshot f3ef59be-dbb5-4aac-a889-420b8742962d for https://nobina.se
ðŸ“Š PROGRESS UPDATE [SEO 5317]: 100%
SEO job 5317 completed in 10911ms
ðŸ“Š METRICS [SEO]: domain=nobina.se, score=91, issuesCount=0, durationMs=10911
ðŸ”„ STATE TRANSITION [SEO 5317]: active â†’ completed (resultId: cmglgdntx0006r20o2fd9gbak)
Crawling (2/100): https://nobina.se/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 2 pages crawled
ðŸ“Š Memory [queue-workers-0]: RSS 379MB, Heap 149MB
Chrome process 8893 killed successfully
Cleaned up temp directory: /tmp/lighthouse-1760137428514-3wy395mg-1320
ðŸ“Š PROGRESS UPDATE [Lighthouse 507]: 90%
ðŸ§  Running Rule Engine for analysis cmglgdnu80008r20orgkx0wih
âœ… Added 0 rule-based recommendations
ðŸ“Š Added RUM data with 0 samples
ðŸ” Running Change Detection for https://nobina.se
ðŸ“¸ Created snapshot d7c963a4-064a-4297-855e-4c7bfd2a7074 for https://nobina.se
ðŸ“Š PROGRESS UPDATE [Lighthouse 507]: 100%
Lighthouse job 507 completed in 24383ms
ðŸ’¾ Updating Lighthouse analysis cmglgdnu80008r20orgkx0wih in database
ðŸ’¾ DB results uppdaterade fÃ¶r cmglgdnu80008r20orgkx0wih
ðŸ“ Updated analysis cmglgdnu80008r20orgkx0wih status to completed
[SAVE] Saved artifact locally: analyses/2025-10-10/cmglgdnu80008r20orgkx0wih/lighthouse-results.json
âœ… Lighthouse analysis cmglgdnu80008r20orgkx0wih updated in database and artifacts
ðŸ“Š METRICS [Lighthouse]: domain=nobina.se, score=45, issuesCount=7, durationMs=24405
ðŸ”„ STATE TRANSITION [Lighthouse 507]: active â†’ completed (resultId: cmglgdnu80008r20orgkx0wih)
Crawling (3/100): https://nobina.se/om-oss/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 3 pages crawled
Crawling (4/100): https://nobina.se/om-oss/tillsammans-forflyttar-vi-samhallet/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 4 pages crawled
Crawling (5/100): https://nobina.se/om-oss/vara-varderingar/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 5 pages crawled
Crawling (6/100): https://nobina.se/om-oss/var-vision/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 6 pages crawled
Crawling (7/100): https://nobina.se/om-oss/vart-resenarslofte/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 7 pages crawled
Crawling (8/100): https://nobina.se/om-oss/vart-ledarlofte/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 8 pages crawled
Crawling (9/100): https://nobina.se/om-oss/sakerheten-gar-alltid-forst/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 9 pages crawled
Destroying browser instance...
Browser instance destroyed
Crawling (10/100): https://nobina.se/link/753d69a6ed934133b48638633e39958b.aspx
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 10 pages crawled
ðŸ“Š Memory [queue-workers-0]: RSS 406MB, Heap 199MB
Crawling (11/100): https://nobina.se/om-oss/vi-engagerar-oss/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 11 pages crawled
Crawling (12/100): https://nobina.se/om-oss/vi-engagerar-oss/samarbetet-med-nobina-ar-vardefullt-och-viktigt/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 12 pages crawled
Crawling (13/100): https://nobina.se/om-oss/vi-engagerar-oss/stor-dag-fylld-med-ridning-och-gladje/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 13 pages crawled
Crawling (14/100): https://nobina.se/om-oss/vi-engagerar-oss/onskan-om-att-aka-buss-blev-sann/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 14 pages crawled
Crawling (15/100): https://nobina.se/om-oss/visselblasarfunktion/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 15 pages crawled
Crawling (16/100): https://nobina.se/om-oss/dataskydd-och-integritet/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 16 pages crawled
Crawling (17/100): https://nobina.se/om-oss/dataskydd-och-integritet/personuppgiftsbehandling/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 17 pages crawled
Crawling (18/100): https://nobina.se/om-oss/dataskydd-och-integritet/informationssakerhet/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 18 pages crawled
Crawling (19/100): https://nobina.se/vara-losningar/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 19 pages crawled
ðŸ“Š Memory [queue-workers-0]: RSS 304MB, Heap 145MB
Crawling (20/100): https://nobina.se/vara-losningar/samhallets-utmaningar/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 20 pages crawled
Crawling (21/100): https://nobina.se/vara-losningar/samhallets-utmaningar/klimat-och-hallbarhet/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 21 pages crawled
Crawling (22/100): https://nobina.se/vara-losningar/samhallets-utmaningar/trangsel-och-framkomlighet/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 22 pages crawled
Crawling (23/100): https://nobina.se/vara-losningar/samhallets-utmaningar/stadsutveckling-och-bostadsbyggande/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 23 pages crawled
Crawling (24/100): https://nobina.se/vara-losningar/busslosningar/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 24 pages crawled
Crawling (25/100): https://nobina.se/vara-losningar/busslosningar/hur-fungerar-kollektivtrafiken/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 25 pages crawled
Crawling (26/100): https://nobina.se/vara-losningar/busslosningar/stad-och-region/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 26 pages crawled
Crawling (27/100): https://nobina.se/vara-losningar/busslosningar/brt-bus-rapid-transit/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 27 pages crawled
Crawling (28/100): https://nobina.se/vara-losningar/busslosningar/flexibel-on-demand-trafik/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 28 pages crawled
ðŸ“Š Memory [queue-workers-0]: RSS 311MB, Heap 131MB
Crawling (29/100): https://nobina.se/vara-losningar/busslosningar/ersattningstrafik-tag/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 29 pages crawled
Crawling (30/100): https://nobina.se/vara-losningar/teknikutveckling/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 30 pages crawled
Crawling (31/100): https://nobina.se/vara-losningar/teknikutveckling/nobina-electrical-solutions/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 31 pages crawled
Crawling (32/100): https://nobina.se/vara-losningar/teknikutveckling/automatisering/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 32 pages crawled
Crawling (33/100): https://nobina.se/vara-losningar/teknikutveckling/digitalisering/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 33 pages crawled
Crawling (34/100): https://nobina.se/vara-losningar/vara-losningar-i-verkligheten/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 34 pages crawled
Crawling (35/100): https://nobina.se/vara-losningar/vara-losningar-i-verkligheten/elbussar-i-landskrona/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 35 pages crawled
Crawling (36/100): https://nobina.se/vara-losningar/vara-losningar-i-verkligheten/bus-rapid-transit-malmoexpressen/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 36 pages crawled
Crawling (37/100): https://nobina.se/vara-losningar/vara-losningar-i-verkligheten/bus-rapid-transit-barkarby/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 37 pages crawled
Crawling (38/100): https://nobina.se/vara-losningar/vara-losningar-i-verkligheten/barkarbystaden/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 38 pages crawled
âœ… Using Prisma singleton for database connection
Queue worker using Chrome at: /usr/bin/chromium
PM2 Instance: 0, Running Lighthouse: true
ðŸ•·ï¸ Creating Crawl worker (enabled=true, isMainInstance=true)
ðŸ”’ Memory guard started for queue-workers-0 (limit: 1100MB)
[STORAGE] Local artifact storage initialized at /home/reda/seo-analyzer-nextjs/artifacts
âœ… Connected to Redis
ðŸ¤– Processing AI Analysis job 77 for https://www.google.com
ðŸ¤– Step 1: Analyzing user's website https://www.google.com
ðŸ”„ STATE TRANSITION [AI Analysis 77]: waiting â†’ active (worker picked up job)
ðŸ¤– Created SEO analysis: cmglggmks0000r28re19ielm4, Crawl analysis: cmglggmky0001r28r527suh10, Lighthouse analysis: cmglggml20002r28rbu5ovqyg
Added SEO job 5318 for https://www.google.com
Processing SEO job 5318 for https://www.google.com
ðŸ”„ STATE TRANSITION [SEO 5318]: waiting â†’ active (worker picked up job)
Added Crawl job 1031 for https://www.google.com
Processing Crawl job 1031 for https://www.google.com
ðŸ“Š PROGRESS UPDATE [SEO 5318]: 10%
ðŸ”„ STATE TRANSITION [Crawl 1031]: waiting â†’ active (worker picked up job)
Added Lighthouse job 508 for https://www.google.com
Processing Lighthouse job 508 for https://www.google.com
ðŸ¤– Waiting for user SEO (5318), Crawl (1031), and Lighthouse (508)
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 10 pages crawled
ðŸ”„ STATE TRANSITION [Lighthouse 508]: waiting â†’ active (worker picked up job)
ðŸ“Š PROGRESS UPDATE [Lighthouse 508]: 10%
Loading ES modules...
Loaded robots.txt
Using Chrome path: /usr/bin/chromium
Chrome flags: 14 flags configured
ðŸ“Š PROGRESS UPDATE [SEO 5318]: 30%
DEBUG: HTML retrieved for https://www.google.com, HTML sample=<!doctype html><html itemscope="" itemtype="http://schema.org/WebPage" lang="sv-NL"><head><meta content="text/html; charset=UTF-8" http-equiv="Content-Type"><meta content="/images/branding/googleg/1x/
DEBUG: performSeoAnalysis creating new Cheerio instance for https://www.google.com
DEBUG: Cheerio version: 1.1.2
DEBUG: URL=https://www.google.com, Cheerio found 0 scripts, 0 JSON-LD
Schema detection: found 0 scripts, hasSchema: false, types: 
robots.txt check: true
sitemap.xml check: true
ðŸ“Š PROGRESS UPDATE [SEO 5318]: 90%
[SCREENSHOT] start id=cmglggmks0000r28re19ielm4 url=https://www.google.com
Creating new browser instance...
Lighthouse categories: performance, accessibility, seo, best-practices
Could not parse sitemap: https://www.google.com/slides/sitemaps.xml
Could not parse sitemap: https://www.google.com/sheets/sitemaps.xml
Browser instance created
Browser acquired from pool (1 in pool, 0 available)
Could not parse sitemap: https://www.google.com/search/about/sitemap.xml
Could not parse sitemap: https://www.google.com/calendar/about/sitemap.xml
[SAVE] Saved artifact locally: analyses/2025-10-10/cmglggmks0000r28re19ielm4/screenshots/desktop.png
[SCREENSHOT] desktop OK key=analyses/2025-10-10/cmglggmks0000r28re19ielm4/screenshots/desktop.png
Could not parse sitemap: https://www.google.com/sitemap_index.xml
Could not parse sitemap: https://www.google.com/sitemap.txt
Could not parse sitemap: https://www.google.com/sitemaps.xml
Could not parse sitemap: https://www.google.com/sitemap-index.xml
Could not parse sitemap: https://www.google.com/wp-sitemap.xml
Could not parse sitemap: https://www.google.com/page-sitemap.xml
Found 44255 URLs in sitemap - using sitemap-first strategy
Crawling (1/100): https://www.google.com
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 1 pages crawled
Crawling (2/100): https://www.google.com/intl/am/gmail/about/
Crawling (3/100): https://www.google.com/intl/am/gmail/about/policy/
Crawling (4/100): https://www.google.com/intl/am/gmail/about/for-work/
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 2 pages crawled
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 3 pages crawled
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 4 pages crawled
Crawling (5/100): https://www.google.com/intl/ar/gmail/about/
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 5 pages crawled
[SAVE] Saved artifact locally: analyses/2025-10-10/cmglggmks0000r28re19ielm4/screenshots/mobile.png
[SCREENSHOT] mobile OK key=analyses/2025-10-10/cmglggmks0000r28re19ielm4/screenshots/mobile.png
Browser operation completed in 6068ms
Browser released to pool
[SAVE] Saved artifact locally: analyses/2025-10-10/cmglggmks0000r28re19ielm4/seo-results.json
ðŸ“ Updated analysis cmglggmks0000r28re19ielm4 status to completed
ðŸ’¾ Saved SEO analysis cmglggmks0000r28re19ielm4 to database and artifacts
Crawling (6/100): https://www.google.com/intl/ar/gmail/about/for-work/
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 6 pages crawled
Crawling (7/100): https://www.google.com/intl/ar/gmail/about/policy/
ðŸ“¸ Created snapshot d20b5568-48ca-4a58-a3ca-a114c9941d90 for https://www.google.com
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 7 pages crawled
ðŸ“Š PROGRESS UPDATE [SEO 5318]: 100%
SEO job 5318 completed in 11034ms
ðŸ“Š METRICS [SEO]: domain=www.google.com, score=25, issuesCount=0, durationMs=11034
ðŸ”„ STATE TRANSITION [SEO 5318]: active â†’ completed (resultId: cmglggmks0000r28re19ielm4)
Crawling (8/100): https://www.google.com/intl/bg/gmail/about/
Crawling (9/100): https://www.google.com/intl/bg/gmail/about/for-work/
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 8 pages crawled
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 9 pages crawled
Crawling (10/100): https://www.google.com/intl/bg/gmail/about/policy/
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 10 pages crawled
Crawling (11/100): https://www.google.com/intl/bn/gmail/about/
Crawling (12/100): https://www.google.com/intl/bn/gmail/about/for-work/
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 11 pages crawled
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 12 pages crawled
Crawling (13/100): https://www.google.com/intl/bn/gmail/about/policy/
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 13 pages crawled
Crawling (14/100): https://www.google.com/intl/cs/gmail/about/
Crawling (15/100): https://www.google.com/intl/cs/gmail/about/for-work/
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 14 pages crawled
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 15 pages crawled
Crawling (16/100): https://www.google.com/intl/cs/gmail/about/policy/
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 16 pages crawled
Crawling (17/100): https://www.google.com/intl/da/gmail/about/
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 17 pages crawled
âœ… Using Prisma singleton for database connection
Queue worker using Chrome at: /usr/bin/chromium
PM2 Instance: 0, Running Lighthouse: true
ðŸ•·ï¸ Creating Crawl worker (enabled=true, isMainInstance=true)
ðŸ”’ Memory guard started for queue-workers-0 (limit: 1100MB)
[STORAGE] Local artifact storage initialized at /home/reda/seo-analyzer-nextjs/artifacts
âœ… Connected to Redis
ðŸ“Š Memory [queue-workers-0]: RSS 116MB, Heap 31MB
ðŸ¤– Processing AI Analysis job 78 for https://seoanalyze.se
ðŸ¤– Step 1: Analyzing user's website https://seoanalyze.se
ðŸ”„ STATE TRANSITION [AI Analysis 78]: waiting â†’ active (worker picked up job)
ðŸ¤– Created SEO analysis: cmglgha210000r2lorthl7v3s, Crawl analysis: cmglgha260001r2lo0sufotwt, Lighthouse analysis: cmglgha290002r2lojhhe417p
Added SEO job 5319 for https://seoanalyze.se
Processing SEO job 5319 for https://seoanalyze.se
Added Crawl job 1032 for https://seoanalyze.se
ðŸ”„ STATE TRANSITION [SEO 5319]: waiting â†’ active (worker picked up job)
Processing Crawl job 1032 for https://seoanalyze.se
ðŸ”„ STATE TRANSITION [Crawl 1032]: waiting â†’ active (worker picked up job)
ðŸ“Š PROGRESS UPDATE [SEO 5319]: 10%
Added Lighthouse job 509 for https://seoanalyze.se
Processing Lighthouse job 509 for https://seoanalyze.se
ðŸ¤– Waiting for user SEO (5319), Crawl (1032), and Lighthouse (509)
ðŸ“Š PROGRESS UPDATE [Crawl 1032]: 10 pages crawled
ðŸ”„ STATE TRANSITION [Lighthouse 509]: waiting â†’ active (worker picked up job)
ðŸ“Š PROGRESS UPDATE [Lighthouse 509]: 10%
Loading ES modules...
Loaded robots.txt
Could not parse sitemap: https://seoanalyzer.se/sitemap.xml
ðŸ“Š PROGRESS UPDATE [SEO 5319]: 30%
DEBUG: HTML retrieved for https://seoanalyze.se, HTML sample=<!DOCTYPE html><!--9cgQzoniMRb1BVtM0dP4u--><html lang="sv"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" as="image" imageSrcSet=
DEBUG: performSeoAnalysis creating new Cheerio instance for https://seoanalyze.se
DEBUG: Cheerio version: 1.1.2
DEBUG: URL=https://seoanalyze.se, Cheerio found 0 scripts, 0 JSON-LD
DEBUG: Using regex fallback for JSON-LD extraction
Found JSON-LD via regex: {"@context":"https://schema.org","@graph":[{"@type":"Organization","@id":"https://seoanalyze.se/#org...
Schema detection: found 1 scripts, hasSchema: true, types: Organization,WebSite,SoftwareApplication,BreadcrumbList
robots.txt check: true
sitemap.xml check: true
Could not parse sitemap: https://seoanalyze.se/sitemap_index.xml
ðŸ“Š PROGRESS UPDATE [SEO 5319]: 90%
[SCREENSHOT] start id=cmglgha210000r2lorthl7v3s url=https://seoanalyze.se
Creating new browser instance...
Could not parse sitemap: https://seoanalyze.se/sitemap.txt
Could not parse sitemap: https://seoanalyze.se/sitemaps.xml
Could not parse sitemap: https://seoanalyze.se/sitemap-index.xml
Browser instance created
Browser acquired from pool (1 in pool, 0 available)
Could not parse sitemap: https://seoanalyze.se/wp-sitemap.xml
Using Chrome path: /usr/bin/chromium
Chrome flags: 14 flags configured
Could not parse sitemap: https://seoanalyze.se/page-sitemap.xml
Found 6 URLs in sitemap - using sitemap-first strategy
Crawling (1/100): https://seoanalyze.se
Robots.txt blocks: https://seoanalyzer.se/
Robots.txt blocks: https://seoanalyzer.se/seo-analys
Robots.txt blocks: https://seoanalyzer.se/lighthouse-analys
Robots.txt blocks: https://seoanalyzer.se/crawl-analys
Robots.txt blocks: https://seoanalyzer.se/integritetspolicy
Robots.txt blocks: https://seoanalyzer.se/anvandarvillkor
ðŸ“Š PROGRESS UPDATE [Crawl 1032]: 1 pages crawled
Lighthouse categories: performance, accessibility, seo, best-practices
Crawling (2/100): https://seoanalyze.se/
ðŸ“Š PROGRESS UPDATE [Crawl 1032]: 2 pages crawled
Crawling (3/100): https://seoanalyze.se/ai-analys
ðŸ“Š PROGRESS UPDATE [Crawl 1032]: 3 pages crawled
Crawling (4/100): https://seoanalyze.se/integritetspolicy
ðŸ“Š PROGRESS UPDATE [Crawl 1032]: 4 pages crawled
ðŸ§  Running Rule Engine for crawl analysis cmglgha260001r2lo0sufotwt
âœ… Added 0 rule-based recommendations
ðŸ“Š Added RUM data with 0 samples
ðŸ” Running Change Detection for crawl https://seoanalyze.se
ðŸ“¸ Created snapshot ca15253b-e2f8-44f4-a183-35a4ed2058d5 for https://seoanalyze.se
ðŸ“Š PROGRESS UPDATE [Crawl 1032]: 100 pages crawled
Crawl job 1032 completed in 6128ms
ðŸ’¾ Updating Crawl analysis cmglgha260001r2lo0sufotwt in database
[SAVE] Saved artifact locally: analyses/2025-10-10/cmglgha210000r2lorthl7v3s/screenshots/desktop.png
[SCREENSHOT] desktop OK key=analyses/2025-10-10/cmglgha210000r2lorthl7v3s/screenshots/desktop.png
ðŸ’¾ DB results uppdaterade fÃ¶r crawl cmglgha260001r2lo0sufotwt
ðŸ“ Updated analysis cmglgha260001r2lo0sufotwt status to completed
[SAVE] Saved artifact locally: analyses/2025-10-10/cmglgha260001r2lo0sufotwt/crawl-results.json
âœ… Crawl analysis cmglgha260001r2lo0sufotwt updated in database and artifacts
ðŸ“Š METRICS [Crawl]: domain=seoanalyze.se, score=100, issuesCount=0, durationMs=6573, pagesCount=4
ðŸ”„ STATE TRANSITION [Crawl 1032]: active â†’ completed (resultId: cmglgha260001r2lo0sufotwt)
[SAVE] Saved artifact locally: analyses/2025-10-10/cmglgha210000r2lorthl7v3s/screenshots/mobile.png
[SCREENSHOT] mobile OK key=analyses/2025-10-10/cmglgha210000r2lorthl7v3s/screenshots/mobile.png
Browser operation completed in 7004ms
Browser released to pool
[SAVE] Saved artifact locally: analyses/2025-10-10/cmglgha210000r2lorthl7v3s/seo-results.json
ðŸ“ Updated analysis cmglgha210000r2lorthl7v3s status to completed
ðŸ’¾ Saved SEO analysis cmglgha210000r2lorthl7v3s to database and artifacts
ðŸ“¸ Created snapshot c71784d2-bb88-4dec-ac2d-1d0815cbcd13 for https://seoanalyze.se
ðŸ“Š PROGRESS UPDATE [SEO 5319]: 100%
SEO job 5319 completed in 9172ms
ðŸ“Š METRICS [SEO]: domain=seoanalyze.se, score=98, issuesCount=0, durationMs=9172
ðŸ”„ STATE TRANSITION [SEO 5319]: active â†’ completed (resultId: cmglgha210000r2lorthl7v3s)
Processing Crawl job 1030 for https://nobina.se
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 10 pages crawled
Loaded robots.txt
Could not parse sitemap: https://nobina.se/sitemap_index.xml
Could not parse sitemap: https://nobina.se/sitemap.txt
Could not parse sitemap: https://nobina.se/sitemaps.xml
Could not parse sitemap: https://nobina.se/sitemap-index.xml
Could not parse sitemap: https://nobina.se/wp-sitemap.xml
Could not parse sitemap: https://nobina.se/page-sitemap.xml
Found 320 URLs in sitemap - using sitemap-first strategy
Crawling (1/100): https://nobina.se
Robots.txt blocks: https://www.nobina.se/vara-losningar/hyr-buss/sweden-rock/sweden-rock-english/
Robots.txt blocks: https://www.nobina.se/vara-losningar/hyr-buss/sweden-rock/sa-funkar-nobina-biljetten/
Robots.txt blocks: https://www.nobina.se/vara-losningar/hyr-buss/sweden-rock/nobina-ticket-faq-english/
Robots.txt blocks: https://www.nobina.se/vara-losningar/hyr-buss/sweden-rock/nobina-yksittaisen-lipun-ukk/
Robots.txt blocks: https://www.nobina.se/jobba-hos-oss/nobina-som-arbetsgivare/vart-arbete-med-mangfald-och-inkludering/lingio/
Robots.txt blocks: https://www.nobina.se/jobba-hos-oss/nobina-som-arbetsgivare/vart-arbete-med-mangfald-och-inkludering/mitt-liv-mentorprogram/
Robots.txt blocks: https://www.nobina.se/jobba-hos-oss/nobina-som-arbetsgivare/vart-arbete-med-mangfald-och-inkludering/korta-vagen/
Robots.txt blocks: https://www.nobina.se/vara-losningar/hyr-buss/referenser-hyra-buss-hos-nobina/angsjo-lyftet-jarfalla/
Robots.txt blocks: https://www.nobina.se/vara-losningar/hyr-buss/referenser-hyra-buss-hos-nobina/stockholm-mean-machines/
Robots.txt blocks: https://www.nobina.se/vara-losningar/hyr-buss/nobina-eventtrafik/fragor-och-svar-nobina-eventtrafik/
Robots.txt blocks: https://www.nobina.se/vara-losningar/hyr-buss/nobina-hyrbuss/fragor-och-svar-nobina-hyrbuss/
Robots.txt blocks: https://www.nobina.se/vara-losningar/hyr-buss/referenser-nobina-eventtrafik/sweden-rock-festival/
Robots.txt blocks: https://www.nobina.se/vara-losningar/hyr-buss/referenser-nobina-eventtrafik/o-ringen/
Robots.txt blocks: https://www.nobina.se/om-oss/dataskydd-och-integritet/personuppgiftsbehandling/cookies/
Robots.txt blocks: https://www.nobina.se/jobba-hos-oss/nobina-som-arbetsgivare/en-trygg-resa-borjar-i-verkstaden/mot-vara-mekaniker/
Robots.txt blocks: https://www.nobina.se/jobba-hos-oss/nobina-som-arbetsgivare/en-trygg-resa-borjar-i-verkstaden/fordonsvard/
Robots.txt blocks: https://www.nobina.se/uppstart-nv/nacka-varmdo/om-oss/resenarsloftet/
Robots.txt blocks: https://www.nobina.se/uppstart-nv/nacka-varmdo/lokal-information/infobrev/
Robots.txt blocks: https://www.nobina.se/uppstart-karlstad/karlstad/om-oss/nobinas-resenarslofte/
Robots.txt blocks: https://www.nobina.se/uppstart-karlstad/karlstad/om-oss/vara-varderingar/
Robots.txt blocks: https://www.nobina.se/uppstart-karlstad/karlstad/om-oss/till-nobina.se/
Robots.txt blocks: https://www.nobina.se/uppstart-karlstad/karlstad/lokal-information/utbildning/
Robots.txt blocks: https://www.nobina.se/uppstart-stenungsund/stenungsund/om-oss/vara-varderingar/
Robots.txt blocks: https://www.nobina.se/uppstart-stenungsund/stenungsund/om-oss/till-nobina.se/
Robots.txt blocks: https://www.nobina.se/uppstart-stenungsund/stenungsund/om-oss/nobinas-uniform/
Robots.txt blocks: https://www.nobina.se/uppstart-umea/umea/lokal-information/vara-arbetssatt/
Robots.txt blocks: https://www.nobina.se/uppstart-stenungsund/stenungsund/lokal-information/
Robots.txt blocks: https://www.nobina.se/uppstart-stenungsund/stenungsund/fragor-och-svar/
Robots.txt blocks: https://www.nobina.se/uppstart-stenungsund/stenungsund/kontakt/
Robots.txt blocks: https://www.nobina.se/vara-losningar/nobina-forum/webinar-om-flexibel-on-demand-trafik/
Robots.txt blocks: https://www.nobina.se/nyheter/2025/nobina-och-vr-skriver-nobina-skriver-10-arigt-avtal-om-ersattningstrafik-for-norrtag/
Robots.txt blocks: https://www.nobina.se/nyheter/2025/nu-ar-vi-igang/
Robots.txt blocks: https://www.nobina.se/nyheter/2025/it-storningar-hos-nobina--nu-ar-systemen-igang/
Robots.txt blocks: https://www.nobina.se/nyheter/2025/just-nu-inget-trafikavtal-for-sodertorn-e45-efter-19-juni-2025/
Robots.txt blocks: https://www.nobina.se/nyheter/2025/farre-an-1-av-10-bussresenarer-anvander-balte-i-kollektivtrafiken/
Robots.txt blocks: https://www.nobina.se/nyheter/2025/forarnas-arbetsdag/
Robots.txt blocks: https://www.nobina.se/nyheter/2025/nobina-uppmarksammar-bussforarens-dag/
Robots.txt blocks: https://www.nobina.se/nyheter/2025/tack-alla-bussforare/
Robots.txt blocks: https://www.nobina.se/nyheter/2025/den-grona-resan--hallbarhet-i-varje-resa/
Robots.txt blocks: https://www.nobina.se/nyheter/2025/paxi---hallands-forsta-on-demand-buss/
Robots.txt blocks: https://www.nobina.se/nyheter/2025/utokat-fortroende-i-skane---tva-nya-avtal/
Robots.txt blocks: https://www.nobina.se/nyheter/2025/boras-hockey/
Robots.txt blocks: https://www.nobina.se/nyheter/2025/smart-laddning-av-elbussar/
Robots.txt blocks: https://www.nobina.se/nyheter/2025/framkomlighet-och-korbanebredd/
Robots.txt blocks: https://www.nobina.se/nyheter/2025/festivaltrafik-med-feeling-pa-sweden-rock/
Robots.txt blocks: https://www.nobina.se/nyheter/2025/gruppen-som-skapar-basta-forarmiljon/
Robots.txt blocks: https://www.nobina.se/nyheter/2025/nobina-kor-busstrafiken-i-karlstad-stad-fran-1-juli/
Robots.txt blocks: https://www.nobina.se/nyheter/2025/over-100-000-resenarer-pa-x-linjen/
Robots.txt blocks: https://www.nobina.se/nyheter/2025/nya-depan-i-timboholm/
Robots.txt blocks: https://www.nobina.se/nyheter/2025/trafikstart-pa-sodertorn/
Robots.txt blocks: https://www.nobina.se/nyheter/2025/nobinaforaren-josefin-kihlberg-vinner-bussforar-sm-2025/
Robots.txt blocks: https://www.nobina.se/nyheter/2025/nobinamekanikern-abbe-sveriges-represetant-i-euroskills/
Robots.txt blocks: https://www.nobina.se/nyheter/2025/nobina-vinner-fornyat-kontrakt-i-varmland/
Robots.txt blocks: https://www.nobina.se/uppstart-karlstad/karlstad/lokal-information/
Robots.txt blocks: https://www.nobina.se/jobba-hos-oss/bussforare/mot-vara-bussforare/
Robots.txt blocks: https://www.nobina.se/jobba-hos-oss/bussforare/bussforare-jobb/
Robots.txt blocks: https://www.nobina.se/jobba-hos-oss/mekaniker/lediga-jobb-verkstad-och-underhall/
Robots.txt blocks: https://www.nobina.se/varmland/jobba-hos-nobina-varmland/jobba-som-bussforare-i-varmland/
Robots.txt blocks: https://www.nobina.se/ostergotland/jobba-hos-nobina-ostergotland/jobba-som-bussforare-i-ostergotland/
Robots.txt blocks: https://www.nobina.se/ostergotland/jobba-hos-nobina-ostergotland/jobba-som-fordonsvardare-i-linkoping/
Robots.txt blocks: https://www.nobina.se/ostergotland/jobba-hos-nobina-ostergotland/jobba-som-fordonsvardsledare-i-linkoping/
Robots.txt blocks: https://www.nobina.se/ostergotland/jobba-hos-nobina-ostergotland/jobba-som-mekaniker-i-linkoping/
Robots.txt blocks: https://www.nobina.se/testcontainer/start/standard/
Robots.txt blocks: https://www.nobina.se/seminarier/tack/framkomlighetsrapporten-2023/
Robots.txt blocks: https://www.nobina.se/nyheter/2024/for-sakerhets-skull---anvand-balte/
Robots.txt blocks: https://www.nobina.se/nyheter/2024/lat-bilen-vila-och-ta-bussen---provakare-sokes-i-pitea/
Robots.txt blocks: https://www.nobina.se/nyheter/2024/x-linjen-tar-resenarerna-dit-de-vill/
Robots.txt blocks: https://www.nobina.se/nyheter/2024/framtidens-kollektivtrafik-i-sunne/
Robots.txt blocks: https://www.nobina.se/nyheter/2024/en-stor-andel-tjejer-och-yngre-nar-malmo-rekryterar-till-forarutbilning/
Robots.txt blocks: https://www.nobina.se/nyheter/2024/bussforaren-dag-for-tionde-aret/
Robots.txt blocks: https://www.nobina.se/nyheter/2024/10-arsjubileum-for-firandet-av-bussforarens-dag/
Robots.txt blocks: https://www.nobina.se/nyheter/2024/tack-alla-bussforare/
Robots.txt blocks: https://www.nobina.se/nyheter/2024/nobina-far-fornyat-fortroende-av-region-stockholm/
Robots.txt blocks: https://www.nobina.se/nyheter/2024/resandet-okar-med-buss-pa-bestallning-pa-morko/
Robots.txt blocks: https://www.nobina.se/nyheter/2024/narvarande-gruppchef-hjalper-forarna-att-gora-sitt-basta/
Robots.txt blocks: https://www.nobina.se/nyheter/2024/stort-soktryck-pa-nobinas-forarutbildningar-runtom-i-landet/
Robots.txt blocks: https://www.nobina.se/nyheter/2024/nobinas-forsta-eldrivna-regionbussar-rullar-i-skane/
Robots.txt blocks: https://www.nobina.se/nyheter/2024/nobina-lanserar-storningswebb-for-tagtrafiken/
Robots.txt blocks: https://www.nobina.se/nyheter/2024/nobina-busspartner-till-stockholm-pride-for-nionde-gangen/
Robots.txt blocks: https://www.nobina.se/nyheter/2024/fran-forare-till-mekaniker---mumin-hittade-hem-i-verkstaden/
Robots.txt blocks: https://www.nobina.se/nyheter/2024/nu-hejar-vi-pa-vara-finalister-pa-bussforar-sm/
Robots.txt blocks: https://www.nobina.se/nyheter/2024/nobinaforare-vann-titeln-sveriges-basta-bussforare/
Robots.txt blocks: https://www.nobina.se/nyheter/2024/on-demand-i-svalov---flexibel-kollektivtrafik-med-skaneflex/
Robots.txt blocks: https://www.nobina.se/nyheter/2024/Har-atervinns-80-av-tvattvattnet/
Robots.txt blocks: https://www.nobina.se/nyheter/2024/livekameror-okar-tryggheten-pa-malmos-bussar/
Robots.txt blocks: https://www.nobina.se/nyheter/2024/sjalvkorande-bussar-till-centralsjukhuset-i-karlstad/
Robots.txt blocks: https://www.nobina.se/nyheter/2024/flexibel-on-demand-trafik-brt-innovationer-och-ai-ger-fler-och-nya-resenarer/
Robots.txt blocks: https://www.nobina.se/nyheter/2024/nobina-tar-over-trafiken-i-umea-i-juni-2026/
Robots.txt blocks: https://www.nobina.se/nyheter/2024/nobina-forst-ut-med-realtidsdata-om-ersattningstrafik/
Robots.txt blocks: https://www.nobina.se/nyheter/2024/nobina-vinner-anbud-for-linje-321/
Robots.txt blocks: https://www.nobina.se/nyheter/2024/fornyat-fortroende-for-nobina-for-busstrafiken-boden--lulea/
Robots.txt blocks: https://www.nobina.se/nyheter/2024/nobina-vinner-omfattande-avtal-for-ersattningstrafik-for-tag-i-skane/
Robots.txt blocks: https://www.nobina.se/nyheter/2024/nobina-far-fornyat-fortroende-for-busstrafiken-i-malmo-stad/
Robots.txt blocks: https://www.nobina.se/nyheter/2024/100-procent-el-i-umea-stadstrafik-2026/
Robots.txt blocks: https://www.nobina.se/uppstart-hbs/huddinge-botkyrka-soderort/om-oss/
Robots.txt blocks: https://www.nobina.se/om-oss/vi-engagerar-oss/samarbetet-med-nobina-ar-vardefullt-och-viktigt/
Robots.txt blocks: https://www.nobina.se/om-oss/vi-engagerar-oss/stor-dag-fylld-med-ridning-och-gladje/
Robots.txt blocks: https://www.nobina.se/om-oss/vi-engagerar-oss/onskan-om-att-aka-buss-blev-sann/
Robots.txt blocks: https://www.nobina.se/om-oss/vi-engagerar-oss/nobina-ar-huvudpartner-till-min-stora-dag/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 1 pages crawled
Chrome process 11506 killed successfully
Cleaned up temp directory: /tmp/lighthouse-1760137599462-lf66ho1l-11148
ðŸ“Š PROGRESS UPDATE [Lighthouse 509]: 90%
ðŸ§  Running Rule Engine for analysis cmglgha290002r2lojhhe417p
âœ… Added 0 rule-based recommendations
ðŸ“Š Added RUM data with 0 samples
ðŸ” Running Change Detection for https://seoanalyze.se
ðŸ“¸ Created snapshot da1e703e-522b-43cf-828d-dd55de498f70 for https://seoanalyze.se
ðŸ“Š PROGRESS UPDATE [Lighthouse 509]: 100%
Lighthouse job 509 completed in 19401ms
ðŸ’¾ Updating Lighthouse analysis cmglgha290002r2lojhhe417p in database
ðŸ’¾ DB results uppdaterade fÃ¶r cmglgha290002r2lojhhe417p
ðŸ“ Updated analysis cmglgha290002r2lojhhe417p status to completed
[SAVE] Saved artifact locally: analyses/2025-10-10/cmglgha290002r2lojhhe417p/lighthouse-results.json
âœ… Lighthouse analysis cmglgha290002r2lojhhe417p updated in database and artifacts
ðŸ“Š METRICS [Lighthouse]: domain=seoanalyze.se, score=78, issuesCount=2, durationMs=19414
ðŸ”„ STATE TRANSITION [Lighthouse 509]: active â†’ completed (resultId: cmglgha290002r2lojhhe417p)
ðŸ¤– SEO, Crawl, and Lighthouse jobs completed successfully
ðŸ¤– Fetched full data from DB - SEO has summary: true, Crawl has summary: true, Lighthouse has summary: true
ðŸ¤– Step 2: Using 0 user-provided competitors: []
ðŸ¤– Step 3: Crawling 0 competitors
ðŸ¤– Step 4: Generating AI report with DeepSeek
ðŸ” DEBUG seoAnalysisData: {
  "hasSummary": true,
  "hasResults": true,
  "summaryScore": 98,
  "resultsTitle": "SEO Analyze | Gratis SEO-analys fÃ¶r din webbplats",
  "resultsWordCount": 439,
  "resultsHttps": true,
  "resultsRobots": true
}
ðŸ” DEBUG seoDetails extracted: {
  "title": "SEO Analyze | Gratis SEO-analys fÃ¶r din webbplats",
  "titleLength": 49,
  "wordCount": 439,
  "robotsFound": true,
  "sitemapFound": true,
  "httpsEnabled": true
}
ðŸ¤– Sending request to DeepSeek AI...
Crawling (2/100): https://nobina.se/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 2 pages crawled
ðŸ“Š Memory [queue-workers-0]: RSS 358MB, Heap 162MB
Crawling (3/100): https://nobina.se/om-oss/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 3 pages crawled
Crawling (4/100): https://nobina.se/om-oss/tillsammans-forflyttar-vi-samhallet/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 4 pages crawled
Destroying browser instance...
Browser instance destroyed
Processing Lighthouse job 508 for https://www.google.com
ðŸ“Š PROGRESS UPDATE [Lighthouse 508]: 10%
Loading ES modules...
Using Chrome path: /usr/bin/chromium
Chrome flags: 14 flags configured
Lighthouse categories: performance, accessibility, seo, best-practices
Crawling (5/100): https://nobina.se/om-oss/vara-varderingar/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 5 pages crawled
Crawling (6/100): https://nobina.se/om-oss/var-vision/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 6 pages crawled
Crawling (7/100): https://nobina.se/om-oss/vart-resenarslofte/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 7 pages crawled
Crawling (8/100): https://nobina.se/om-oss/vart-ledarlofte/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 8 pages crawled
Crawling (9/100): https://nobina.se/om-oss/sakerheten-gar-alltid-forst/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 9 pages crawled
Chrome process 12179 killed successfully
Cleaned up temp directory: /tmp/lighthouse-1760137641709-l6ayxxet-11148
ðŸ“Š PROGRESS UPDATE [Lighthouse 508]: 90%
ðŸ§  Running Rule Engine for analysis cmglggml20002r28rbu5ovqyg
âœ… Added 0 rule-based recommendations
ðŸ“Š Added RUM data with 0 samples
ðŸ” Running Change Detection for https://www.google.com
ðŸ“¸ Created snapshot 4c687cc1-a023-4185-a40a-3443cda9d438 for https://www.google.com
ðŸ“Š PROGRESS UPDATE [Lighthouse 508]: 100%
Lighthouse job 508 completed in 11857ms
ðŸ’¾ Updating Lighthouse analysis cmglggml20002r28rbu5ovqyg in database
ðŸ’¾ DB results uppdaterade fÃ¶r cmglggml20002r28rbu5ovqyg
ðŸ“ Updated analysis cmglggml20002r28rbu5ovqyg status to completed
[SAVE] Saved artifact locally: analyses/2025-10-10/cmglggml20002r28rbu5ovqyg/lighthouse-results.json
âœ… Lighthouse analysis cmglggml20002r28rbu5ovqyg updated in database and artifacts
ðŸ“Š METRICS [Lighthouse]: domain=www.google.com, score=90, issuesCount=2, durationMs=11875
ðŸ”„ STATE TRANSITION [Lighthouse 508]: active â†’ completed (resultId: cmglggml20002r28rbu5ovqyg)
Processing Lighthouse job 510 for https://seoanalyze.se/
ðŸ”„ STATE TRANSITION [Lighthouse 510]: waiting â†’ active (worker picked up job)
ðŸ“Š PROGRESS UPDATE [Lighthouse 510]: 10%
Loading ES modules...
Using Chrome path: /usr/bin/chromium
Chrome flags: 14 flags configured
Lighthouse categories: performance, accessibility, seo, best-practices
ðŸ“Š Memory [queue-workers-0]: RSS 356MB, Heap 138MB
Crawling (10/100): https://nobina.se/link/753d69a6ed934133b48638633e39958b.aspx
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 10 pages crawled
Crawling (11/100): https://nobina.se/om-oss/vi-engagerar-oss/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 11 pages crawled
Crawling (12/100): https://nobina.se/om-oss/vi-engagerar-oss/samarbetet-med-nobina-ar-vardefullt-och-viktigt/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 12 pages crawled
Chrome process 12442 killed successfully
Cleaned up temp directory: /tmp/lighthouse-1760137655898-nt9piie2-11148
ðŸ“Š PROGRESS UPDATE [Lighthouse 510]: 90%
ðŸ§  Running Rule Engine for analysis 01K7862DJGFY9BB27PM8CK89J5
âœ… Added 0 rule-based recommendations
ðŸ“Š Added RUM data with 128 samples
ðŸ” Running Change Detection for https://seoanalyze.se/
ðŸ“¸ Created snapshot d424c19d-1516-489c-8dc4-3f4c5cba7b30 for https://seoanalyze.se/
ðŸ“Š PROGRESS UPDATE [Lighthouse 510]: 100%
Lighthouse job 510 completed in 14223ms
ðŸ’¾ Updating Lighthouse analysis 01K7862DJGFY9BB27PM8CK89J5 in database
ðŸ’¾ DB results uppdaterade fÃ¶r 01K7862DJGFY9BB27PM8CK89J5
ðŸ“ Updated analysis 01K7862DJGFY9BB27PM8CK89J5 status to completed
[SAVE] Saved artifact locally: analyses/2025-10-10/01K7862DJGFY9BB27PM8CK89J5/lighthouse-results.json
âœ… Lighthouse analysis 01K7862DJGFY9BB27PM8CK89J5 updated in database and artifacts
ðŸ“Š METRICS [Lighthouse]: domain=seoanalyze.se, score=91, issuesCount=2, durationMs=14242
ðŸ”„ STATE TRANSITION [Lighthouse 510]: active â†’ completed (resultId: 01K7862DJGFY9BB27PM8CK89J5)
Crawling (13/100): https://nobina.se/om-oss/vi-engagerar-oss/stor-dag-fylld-med-ridning-och-gladje/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 13 pages crawled
Crawling (14/100): https://nobina.se/om-oss/vi-engagerar-oss/onskan-om-att-aka-buss-blev-sann/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 14 pages crawled
Crawling (15/100): https://nobina.se/om-oss/visselblasarfunktion/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 15 pages crawled
Crawling (16/100): https://nobina.se/om-oss/dataskydd-och-integritet/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 16 pages crawled
Crawling (17/100): https://nobina.se/om-oss/dataskydd-och-integritet/personuppgiftsbehandling/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 17 pages crawled
Crawling (18/100): https://nobina.se/om-oss/dataskydd-och-integritet/informationssakerhet/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 18 pages crawled
ðŸ¤– DeepSeek AI response received
ðŸ¤– Step 5: Saving AI report
ðŸ¤– AI Analysis job 78 completed in 85739ms
ðŸ¤– Processing AI Analysis job 77 for https://www.google.com
ðŸ¤– Step 1: Analyzing user's website https://www.google.com
ðŸ”„ STATE TRANSITION [AI Analysis 77]: waiting â†’ active (worker picked up job)
ðŸ”„ STATE TRANSITION [AI Analysis 78]: waiting â†’ completed
ðŸ¤– Created SEO analysis: cmglgj48y0003r2lo612rxuht, Crawl analysis: cmglgj4920004r2lopvloi4sr, Lighthouse analysis: cmglgj4960005r2logtmk9h92
Added SEO job 5320 for https://www.google.com
Processing SEO job 5320 for https://www.google.com
ðŸ”„ STATE TRANSITION [SEO 5320]: waiting â†’ active (worker picked up job)
Added Crawl job 1033 for https://www.google.com
ðŸ“Š PROGRESS UPDATE [SEO 5320]: 10%
Added Lighthouse job 511 for https://www.google.com
Processing Lighthouse job 511 for https://www.google.com
ðŸ¤– Waiting for user SEO (5320), Crawl (1033), and Lighthouse (511)
ðŸ”„ STATE TRANSITION [Lighthouse 511]: waiting â†’ active (worker picked up job)
ðŸ“Š PROGRESS UPDATE [Lighthouse 511]: 10%
Loading ES modules...
Using Chrome path: /usr/bin/chromium
Chrome flags: 14 flags configured
ðŸ“Š PROGRESS UPDATE [SEO 5320]: 30%
DEBUG: HTML retrieved for https://www.google.com, HTML sample=<!doctype html><html itemscope="" itemtype="http://schema.org/WebPage" lang="sv-NL"><head><meta content="text/html; charset=UTF-8" http-equiv="Content-Type"><meta content="/images/branding/googleg/1x/
DEBUG: performSeoAnalysis creating new Cheerio instance for https://www.google.com
DEBUG: Cheerio version: 1.1.2
DEBUG: URL=https://www.google.com, Cheerio found 0 scripts, 0 JSON-LD
Schema detection: found 0 scripts, hasSchema: false, types: 
robots.txt check: true
sitemap.xml check: true
ðŸ“Š PROGRESS UPDATE [SEO 5320]: 90%
[SCREENSHOT] start id=cmglgj48y0003r2lo612rxuht url=https://www.google.com
Creating new browser instance...
Lighthouse categories: performance, accessibility, seo, best-practices
Browser instance created
Browser acquired from pool (1 in pool, 0 available)
Crawling (19/100): https://nobina.se/vara-losningar/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 19 pages crawled
ðŸ“Š Memory [queue-workers-0]: RSS 348MB, Heap 142MB
[SAVE] Saved artifact locally: analyses/2025-10-10/cmglgj48y0003r2lo612rxuht/screenshots/desktop.png
[SCREENSHOT] desktop OK key=analyses/2025-10-10/cmglgj48y0003r2lo612rxuht/screenshots/desktop.png
[SAVE] Saved artifact locally: analyses/2025-10-10/cmglgj48y0003r2lo612rxuht/screenshots/mobile.png
[SCREENSHOT] mobile OK key=analyses/2025-10-10/cmglgj48y0003r2lo612rxuht/screenshots/mobile.png
Browser operation completed in 5097ms
Browser released to pool
[SAVE] Saved artifact locally: analyses/2025-10-10/cmglgj48y0003r2lo612rxuht/seo-results.json
ðŸ“ Updated analysis cmglgj48y0003r2lo612rxuht status to completed
ðŸ’¾ Saved SEO analysis cmglgj48y0003r2lo612rxuht to database and artifacts
ðŸ“¸ Created snapshot 8127a3a1-2a77-479c-9af0-c1c173a6339d for https://www.google.com
ðŸ“Š PROGRESS UPDATE [SEO 5320]: 100%
SEO job 5320 completed in 6664ms
ðŸ“Š METRICS [SEO]: domain=www.google.com, score=25, issuesCount=0, durationMs=6664
ðŸ”„ STATE TRANSITION [SEO 5320]: active â†’ completed (resultId: cmglgj48y0003r2lo612rxuht)
Crawling (20/100): https://nobina.se/vara-losningar/samhallets-utmaningar/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 20 pages crawled
Chrome process 12892 killed successfully
Cleaned up temp directory: /tmp/lighthouse-1760137683044-002mdm38-11148
ðŸ“Š PROGRESS UPDATE [Lighthouse 511]: 90%
ðŸ§  Running Rule Engine for analysis cmglgj4960005r2logtmk9h92
âœ… Added 0 rule-based recommendations
ðŸ“Š Added RUM data with 0 samples
ðŸ” Running Change Detection for https://www.google.com
ðŸ“¸ Created snapshot 3de2d8f2-93d8-4be5-8522-204bf7d0f5a3 for https://www.google.com
ðŸ“Š PROGRESS UPDATE [Lighthouse 511]: 100%
Lighthouse job 511 completed in 12743ms
ðŸ’¾ Updating Lighthouse analysis cmglgj4960005r2logtmk9h92 in database
ðŸ’¾ DB results uppdaterade fÃ¶r cmglgj4960005r2logtmk9h92
ðŸ“ Updated analysis cmglgj4960005r2logtmk9h92 status to completed
[SAVE] Saved artifact locally: analyses/2025-10-10/cmglgj4960005r2logtmk9h92/lighthouse-results.json
âœ… Lighthouse analysis cmglgj4960005r2logtmk9h92 updated in database and artifacts
ðŸ“Š METRICS [Lighthouse]: domain=www.google.com, score=89, issuesCount=2, durationMs=12762
ðŸ”„ STATE TRANSITION [Lighthouse 511]: active â†’ completed (resultId: cmglgj4960005r2logtmk9h92)
Crawling (21/100): https://nobina.se/vara-losningar/samhallets-utmaningar/klimat-och-hallbarhet/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 21 pages crawled
Crawling (22/100): https://nobina.se/vara-losningar/samhallets-utmaningar/trangsel-och-framkomlighet/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 22 pages crawled
Crawling (23/100): https://nobina.se/vara-losningar/samhallets-utmaningar/stadsutveckling-och-bostadsbyggande/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 23 pages crawled
Crawling (24/100): https://nobina.se/vara-losningar/busslosningar/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 24 pages crawled
Crawling (25/100): https://nobina.se/vara-losningar/busslosningar/hur-fungerar-kollektivtrafiken/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 25 pages crawled
Crawling (26/100): https://nobina.se/vara-losningar/busslosningar/stad-och-region/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 26 pages crawled
Crawling (27/100): https://nobina.se/vara-losningar/busslosningar/brt-bus-rapid-transit/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 27 pages crawled
Crawling (28/100): https://nobina.se/vara-losningar/busslosningar/flexibel-on-demand-trafik/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 28 pages crawled
ðŸ“Š Memory [queue-workers-0]: RSS 368MB, Heap 158MB
Destroying browser instance...
Browser instance destroyed
Crawling (29/100): https://nobina.se/vara-losningar/busslosningar/ersattningstrafik-tag/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 29 pages crawled
Crawling (30/100): https://nobina.se/vara-losningar/teknikutveckling/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 30 pages crawled
Crawling (31/100): https://nobina.se/vara-losningar/teknikutveckling/nobina-electrical-solutions/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 31 pages crawled
Crawling (32/100): https://nobina.se/vara-losningar/teknikutveckling/automatisering/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 32 pages crawled
Crawling (33/100): https://nobina.se/vara-losningar/teknikutveckling/digitalisering/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 33 pages crawled
Crawling (34/100): https://nobina.se/vara-losningar/vara-losningar-i-verkligheten/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 34 pages crawled
Crawling (35/100): https://nobina.se/vara-losningar/vara-losningar-i-verkligheten/elbussar-i-landskrona/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 35 pages crawled
Crawling (36/100): https://nobina.se/vara-losningar/vara-losningar-i-verkligheten/bus-rapid-transit-malmoexpressen/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 36 pages crawled
Crawling (37/100): https://nobina.se/vara-losningar/vara-losningar-i-verkligheten/bus-rapid-transit-barkarby/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 37 pages crawled
Crawling (38/100): https://nobina.se/vara-losningar/vara-losningar-i-verkligheten/barkarbystaden/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 38 pages crawled
ðŸ“Š Memory [queue-workers-0]: RSS 302MB, Heap 146MB
Crawling (39/100): https://nobina.se/vara-losningar/vara-losningar-i-verkligheten/trygghetskamera---live-i-malmo/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 39 pages crawled
Crawling (40/100): https://nobina.se/vara-losningar/nobina-forum/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 40 pages crawled
Crawling (41/100): https://nobina.se/vara-losningar/nobina-forum/webinar-om-flexibel-on-demand-trafik/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 41 pages crawled
Crawling (42/100): https://nobina.se/vara-losningar/hyr-buss/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 42 pages crawled
Crawling (43/100): https://nobina.se/vara-losningar/hyr-buss/nobina-hyrbuss/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 43 pages crawled
Crawling (44/100): https://nobina.se/vara-losningar/forfragan-hyrbuss/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 44 pages crawled
Crawling (45/100): https://nobina.se/nyheter/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 45 pages crawled
Crawling (46/100): https://nobina.se/jobba-hos-oss/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 46 pages crawled
ðŸ“Š Memory [queue-workers-0]: RSS 319MB, Heap 148MB
Crawling (47/100): https://nobina.se/jobba-hos-oss/lediga-jobb/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 47 pages crawled
Crawling (48/100): https://nobina.se/jobba-hos-oss/bussforare/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 48 pages crawled
Crawling (49/100): https://nobina.se/jobba-hos-oss/bussforare/mot-vara-bussforare/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 49 pages crawled
Crawling (50/100): https://nobina.se/jobba-hos-oss/bussforare/bussforare-jobb/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 50 pages crawled
ðŸ“Š Memory [queue-workers-0]: RSS 279MB, Heap 133MB
Crawling (51/100): https://nobina.se/jobba-hos-oss/mekaniker/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 51 pages crawled
Crawling (52/100): https://nobina.se/jobba-hos-oss/mekaniker/lediga-jobb-verkstad-och-underhall/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 52 pages crawled
Crawling (53/100): https://nobina.se/jobba-hos-oss/karriar-pa-nobina/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 53 pages crawled
Crawling (54/100): https://nobina.se/jobba-hos-oss/karriar-pa-nobina/trafikledning---stod-och-information/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 54 pages crawled
Crawling (55/100): https://nobina.se/jobba-hos-oss/karriar-pa-nobina/yttre-trafikledare-far-trafiken-att-flyta-pa/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 55 pages crawled
Crawling (56/100): https://nobina.se/jobba-hos-oss/karriar-pa-nobina/business-academy/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 56 pages crawled
Crawling (57/100): https://nobina.se/jobba-hos-oss/nobina-som-arbetsgivare/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 57 pages crawled
Crawling (58/100): https://nobina.se/jobba-hos-oss/nobina-som-arbetsgivare/arbetsomraden/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 58 pages crawled
ðŸ“Š Memory [queue-workers-0]: RSS 313MB, Heap 142MB
Crawling (59/100): https://nobina.se/jobba-hos-oss/nobina-som-arbetsgivare/vart-arbete-med-mangfald-och-inkludering/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 59 pages crawled
Crawling (60/100): https://nobina.se/jobba-hos-oss/nobina-som-arbetsgivare/en-trygg-resa-borjar-i-verkstaden/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 60 pages crawled
Crawling (61/100): https://nobina.se/jobba-hos-oss/nobina-som-arbetsgivare/kamratstodjare/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 61 pages crawled
Crawling (62/100): https://nobina.se/jobba-hos-oss/bussforarutbildning/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 62 pages crawled
Crawling (63/100): https://nobina.se/jobba-hos-oss/bussforarutbildning/vara-utbildningar/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 63 pages crawled
Crawling (64/100): https://nobina.se/jobba-hos-oss/bussforarutbildning/fragor-och-svar-om-bussforarutbildning/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 64 pages crawled
Crawling (65/100): https://nobina.se/jobba-hos-oss/bussforarutbildning/nobinas-trafikskola/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 65 pages crawled
Crawling (66/100): https://nobina.se/transportlosningar/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 66 pages crawled
ðŸ“Š Memory [queue-workers-0]: RSS 319MB, Heap 149MB
Crawling (67/100): https://nobina.se/transportlosningar/kommersiella-transportlosningar/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 67 pages crawled
Crawling (68/100): https://nobina.se/transportlosningar/musik--och-kulturfestivaler/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 68 pages crawled
ðŸ¤– Processing AI Analysis job 76 for https://nobina.se
ðŸ¤– Step 1: Analyzing user's website https://nobina.se
ðŸ”„ STATE TRANSITION [AI Analysis 76]: waiting â†’ active (worker picked up job)
ðŸ”„ STATE TRANSITION [AI Analysis 77]: waiting â†’ failed (error: Job 1033 timed out after 180000ms)
ðŸ¤– Created SEO analysis: cmglgn64y0006r2looevdbmsr, Crawl analysis: cmglgn6530007r2loccqh4s03, Lighthouse analysis: cmglgn6550008r2lowcrpjssz
Added SEO job 5321 for https://nobina.se
Processing SEO job 5321 for https://nobina.se
ðŸ”„ STATE TRANSITION [SEO 5321]: waiting â†’ active (worker picked up job)
Added Crawl job 1034 for https://nobina.se
ðŸ“Š PROGRESS UPDATE [SEO 5321]: 10%
Added Lighthouse job 512 for https://nobina.se
ðŸ¤– Waiting for user SEO (5321), Crawl (1034), and Lighthouse (512)
Processing Lighthouse job 512 for https://nobina.se
ðŸ”„ STATE TRANSITION [Lighthouse 512]: waiting â†’ active (worker picked up job)
ðŸ“Š PROGRESS UPDATE [Lighthouse 512]: 10%
Loading ES modules...
Using Chrome path: /usr/bin/chromium
Chrome flags: 14 flags configured
ðŸ“Š PROGRESS UPDATE [SEO 5321]: 30%
DEBUG: HTML retrieved for https://nobina.se, HTML sample=<!doctype html> <html lang="sv"> <head> <meta charset="utf-8"> <meta http-equiv="X-UA-Compatible" content="IE=edge" /> <meta name="viewport" content="width=device-width, initial-scale
DEBUG: performSeoAnalysis creating new Cheerio instance for https://nobina.se
DEBUG: Cheerio version: 1.1.2
DEBUG: URL=https://nobina.se, Cheerio found 0 scripts, 0 JSON-LD
Schema detection: found 0 scripts, hasSchema: false, types: 
Lighthouse categories: performance, accessibility, seo, best-practices
robots.txt check: true
sitemap.xml check: true
ðŸ“Š PROGRESS UPDATE [SEO 5321]: 90%
[SCREENSHOT] start id=cmglgn64y0006r2looevdbmsr url=https://nobina.se
Creating new browser instance...
Browser instance created
Browser acquired from pool (1 in pool, 0 available)
Crawling (69/100): https://nobina.se/transportlosningar/sportevenemang/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 69 pages crawled
[SAVE] Saved artifact locally: analyses/2025-10-10/cmglgn64y0006r2looevdbmsr/screenshots/desktop.png
[SCREENSHOT] desktop OK key=analyses/2025-10-10/cmglgn64y0006r2looevdbmsr/screenshots/desktop.png
Crawling (70/100): https://nobina.se/transportlosningar/foretagsevent/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 70 pages crawled
Crawling (71/100): https://nobina.se/transportlosningar/arbetsplatser/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 71 pages crawled
[SAVE] Saved artifact locally: analyses/2025-10-10/cmglgn64y0006r2looevdbmsr/screenshots/mobile.png
[SCREENSHOT] mobile OK key=analyses/2025-10-10/cmglgn64y0006r2looevdbmsr/screenshots/mobile.png
Browser operation completed in 7260ms
Browser released to pool
[SAVE] Saved artifact locally: analyses/2025-10-10/cmglgn64y0006r2looevdbmsr/seo-results.json
ðŸ“ Updated analysis cmglgn64y0006r2looevdbmsr status to completed
ðŸ’¾ Saved SEO analysis cmglgn64y0006r2looevdbmsr to database and artifacts
ðŸ“¸ Created snapshot ce07eff4-8c9b-4b6a-94bb-69c2892970a7 for https://nobina.se
ðŸ“Š PROGRESS UPDATE [SEO 5321]: 100%
SEO job 5321 completed in 9519ms
ðŸ“Š METRICS [SEO]: domain=nobina.se, score=91, issuesCount=0, durationMs=9519
ðŸ”„ STATE TRANSITION [SEO 5321]: active â†’ completed (resultId: cmglgn64y0006r2looevdbmsr)
Crawling (72/100): https://nobina.se/transportlosningar/digitala-losningar-for-modern-bestallningstrafik/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 72 pages crawled
Crawling (73/100): https://nobina.se/transportlosningar/destinationer/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 73 pages crawled
Crawling (74/100): https://nobina.se/transportlosningar/transportlosningar-for-researrangorer-och-partners/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 74 pages crawled
Chrome process 14884 killed successfully
Cleaned up temp directory: /tmp/lighthouse-1760137872112-z75n2x45-11148
ðŸ“Š PROGRESS UPDATE [Lighthouse 512]: 90%
ðŸ§  Running Rule Engine for analysis cmglgn6550008r2lowcrpjssz
âœ… Added 0 rule-based recommendations
ðŸ“Š Added RUM data with 0 samples
ðŸ” Running Change Detection for https://nobina.se
ðŸ“¸ Created snapshot 8dc5f555-c57c-4fda-b3e2-900521c542a3 for https://nobina.se
ðŸ“Š PROGRESS UPDATE [Lighthouse 512]: 100%
Lighthouse job 512 completed in 22298ms
ðŸ’¾ Updating Lighthouse analysis cmglgn6550008r2lowcrpjssz in database
ðŸ’¾ DB results uppdaterade fÃ¶r cmglgn6550008r2lowcrpjssz
ðŸ“ Updated analysis cmglgn6550008r2lowcrpjssz status to completed
[SAVE] Saved artifact locally: analyses/2025-10-10/cmglgn6550008r2lowcrpjssz/lighthouse-results.json
âœ… Lighthouse analysis cmglgn6550008r2lowcrpjssz updated in database and artifacts
ðŸ“Š METRICS [Lighthouse]: domain=nobina.se, score=42, issuesCount=10, durationMs=22333
ðŸ”„ STATE TRANSITION [Lighthouse 512]: active â†’ completed (resultId: cmglgn6550008r2lowcrpjssz)
Crawling (75/100): https://nobina.se/transportlosningar/hyr-en-buss/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 75 pages crawled
Crawling (76/100): https://nobina.se/kontakt/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 76 pages crawled
ðŸ“Š Memory [queue-workers-0]: RSS 388MB, Heap 160MB
Crawling (77/100): https://nobina.se/kontakt/har-finns-vi/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 77 pages crawled
Crawling (78/100): https://nobina.se/kontakt/synpunkter/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 78 pages crawled
Crawling (79/100): https://nobina.se/kontakt/Media/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 79 pages crawled
Crawling (80/100): https://nobina.se/kontakt/faktureringsinformation/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 80 pages crawled
Crawling (81/100): https://nobina.se/nyheter/2025/nobina-vinner-fornyat-kontrakt-i-varmland/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 81 pages crawled
Crawling (82/100): https://nobina.se/nyheter/2025/nobinaforaren-josefin-kihlberg-vinner-bussforar-sm-2025/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 82 pages crawled
Crawling (83/100): https://nobina.se/nyheter/2025/trafikstart-pa-sodertorn/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 83 pages crawled
Destroying browser instance...
Browser instance destroyed
Crawling (84/100): https://nobina.se/nyheter/2025/utokat-fortroende-i-skane---tva-nya-avtal/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 84 pages crawled
Crawling (85/100): https://nobina.se/nyheter/2025/den-grona-resan--hallbarhet-i-varje-resa/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 85 pages crawled
Crawling (86/100): https://nobina.se/nyheter/2025/farre-an-1-av-10-bussresenarer-anvander-balte-i-kollektivtrafiken/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 86 pages crawled
ðŸ“Š Memory [queue-workers-0]: RSS 307MB, Heap 153MB
Crawling (87/100): https://nobina.se/nyheter/2025/nobinamekanikern-abbe-sveriges-represetant-i-euroskills/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 87 pages crawled
Crawling (88/100): https://nobina.se/nyheter/2025/nya-depan-i-timboholm/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 88 pages crawled
Crawling (89/100): https://nobina.se/nyheter/2025/over-100-000-resenarer-pa-x-linjen/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 89 pages crawled
Crawling (90/100): https://nobina.se/om-oss/dataskydd-och-integritet/personuppgiftsbehandling/cookies/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 90 pages crawled
Crawling (91/100): https://nobina.se/sv/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 91 pages crawled
Page has noindex directive, skipping: https://nobina.se/sv/
Crawling (92/100): https://nobina.se/sv/om-oss/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 92 pages crawled
Page has noindex directive, skipping: https://nobina.se/sv/om-oss/
Crawling (93/100): https://nobina.se/sv/om-oss/tillsammans-forflyttar-vi-samhallet/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 93 pages crawled
Page has noindex directive, skipping: https://nobina.se/sv/om-oss/tillsammans-forflyttar-vi-samhallet/
Crawling (94/100): https://nobina.se/sv/om-oss/vara-varderingar/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 94 pages crawled
Page has noindex directive, skipping: https://nobina.se/sv/om-oss/vara-varderingar/
Crawling (95/100): https://nobina.se/sv/om-oss/var-vision/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 95 pages crawled
Page has noindex directive, skipping: https://nobina.se/sv/om-oss/var-vision/
Crawling (96/100): https://nobina.se/sv/om-oss/sakerheten-gar-alltid-forst/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 96 pages crawled
Page has noindex directive, skipping: https://nobina.se/sv/om-oss/sakerheten-gar-alltid-forst/
Crawling (97/100): https://nobina.se/sv/om-oss/var-resa/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 97 pages crawled
Page has noindex directive, skipping: https://nobina.se/sv/om-oss/var-resa/
Crawling (98/100): https://nobina.se/sv/om-oss/vart-strategiska-ramverk/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 98 pages crawled
Page has noindex directive, skipping: https://nobina.se/sv/om-oss/vart-strategiska-ramverk/
Crawling (99/100): https://nobina.se/sv/om-oss/loften-till-vara-resenarer/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 99 pages crawled
Page has noindex directive, skipping: https://nobina.se/sv/om-oss/loften-till-vara-resenarer/
Crawling (100/100): https://nobina.se/sv/om-oss/var-koncernledning/
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 100 pages crawled
Page has noindex directive, skipping: https://nobina.se/sv/om-oss/var-koncernledning/
ðŸ§  Running Rule Engine for crawl analysis cmglgdnu40007r20ouxpfq8x1
âœ… Added 0 rule-based recommendations
ðŸ“Š Added RUM data with 0 samples
ðŸ” Running Change Detection for crawl https://nobina.se
ðŸ“¸ Created snapshot aa63ccce-7c8d-4da5-8ee5-a5089d0f0dfb for https://nobina.se
ðŸ“Š PROGRESS UPDATE [Crawl 1030]: 100 pages crawled
Crawl job 1030 completed in 333053ms
ðŸ’¾ Updating Crawl analysis cmglgdnu40007r20ouxpfq8x1 in database
ðŸ’¾ DB results uppdaterade fÃ¶r crawl cmglgdnu40007r20ouxpfq8x1
ðŸ“ Updated analysis cmglgdnu40007r20ouxpfq8x1 status to completed
[SAVE] Saved artifact locally: analyses/2025-10-10/cmglgdnu40007r20ouxpfq8x1/crawl-results.json
âœ… Crawl analysis cmglgdnu40007r20ouxpfq8x1 updated in database and artifacts
ðŸ“Š METRICS [Crawl]: domain=nobina.se, score=0, issuesCount=267, durationMs=339771, pagesCount=90
Processing Crawl job 1031 for https://www.google.com
ðŸ”„ STATE TRANSITION [Crawl 1030]: active â†’ completed (resultId: cmglgdnu40007r20ouxpfq8x1)
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 10 pages crawled
Loaded robots.txt
Could not parse sitemap: https://www.google.com/slides/sitemaps.xml
Could not parse sitemap: https://www.google.com/sheets/sitemaps.xml
Could not parse sitemap: https://www.google.com/search/about/sitemap.xml
Could not parse sitemap: https://www.google.com/calendar/about/sitemap.xml
Could not parse sitemap: https://www.google.com/sitemap_index.xml
Could not parse sitemap: https://www.google.com/sitemap.txt
Could not parse sitemap: https://www.google.com/sitemaps.xml
Could not parse sitemap: https://www.google.com/sitemap-index.xml
Could not parse sitemap: https://www.google.com/wp-sitemap.xml
Could not parse sitemap: https://www.google.com/page-sitemap.xml
Found 44255 URLs in sitemap - using sitemap-first strategy
Crawling (1/100): https://www.google.com
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 1 pages crawled
Crawling (2/100): https://www.google.com/intl/am/gmail/about/policy/
Crawling (3/100): https://www.google.com/intl/am/gmail/about/
Crawling (4/100): https://www.google.com/intl/am/gmail/about/for-work/
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 2 pages crawled
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 3 pages crawled
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 4 pages crawled
Crawling (5/100): https://www.google.com/intl/ar/gmail/about/
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 5 pages crawled
Crawling (6/100): https://www.google.com/intl/ar/gmail/about/for-work/
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 6 pages crawled
Crawling (7/100): https://www.google.com/intl/ar/gmail/about/policy/
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 7 pages crawled
ðŸ“Š Memory [queue-workers-0]: RSS 1006MB, Heap 270MB
Crawling (8/100): https://www.google.com/intl/bg/gmail/about/for-work/
Crawling (9/100): https://www.google.com/intl/bg/gmail/about/policy/
Crawling (10/100): https://www.google.com/intl/bg/gmail/about/
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 8 pages crawled
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 9 pages crawled
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 10 pages crawled
Crawling (11/100): https://www.google.com/intl/bn/gmail/about/
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 11 pages crawled
Crawling (12/100): https://www.google.com/intl/bn/gmail/about/for-work/
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 12 pages crawled
Crawling (13/100): https://www.google.com/intl/bn/gmail/about/policy/
Crawling (14/100): https://www.google.com/intl/cs/gmail/about/
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 13 pages crawled
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 14 pages crawled
Crawling (15/100): https://www.google.com/intl/cs/gmail/about/for-work/
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 15 pages crawled
Crawling (16/100): https://www.google.com/intl/cs/gmail/about/policy/
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 16 pages crawled
Crawling (17/100): https://www.google.com/intl/da/gmail/about/policy/
Crawling (18/100): https://www.google.com/intl/da/gmail/about/
Crawling (19/100): https://www.google.com/intl/da/gmail/about/for-work/
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 17 pages crawled
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 18 pages crawled
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 19 pages crawled
Crawling (20/100): https://www.google.com/intl/de/gmail/about/
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 20 pages crawled
Crawling (21/100): https://www.google.com/intl/de/gmail/about/for-work/
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 21 pages crawled
Crawling (22/100): https://www.google.com/intl/el/gmail/about/
Crawling (23/100): https://www.google.com/intl/de/gmail/about/policy/
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 22 pages crawled
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 23 pages crawled
Crawling (24/100): https://www.google.com/intl/el/gmail/about/policy/
Crawling (25/100): https://www.google.com/intl/el/gmail/about/for-work/
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 24 pages crawled
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 25 pages crawled
Crawling (26/100): https://www.google.com/intl/en_in/gmail/about/for-work/
Crawling (27/100): https://www.google.com/intl/en_in/gmail/about/
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 26 pages crawled
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 27 pages crawled
Crawling (28/100): https://www.google.com/intl/en_in/gmail/about/policy/
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 28 pages crawled
Crawling (29/100): https://www.google.com/intl/en_uk/gmail/about/
Crawling (30/100): https://www.google.com/intl/en_uk/gmail/about/for-work/
Crawling (31/100): https://www.google.com/intl/en_uk/gmail/about/policy/
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 29 pages crawled
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 30 pages crawled
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 31 pages crawled
Crawling (32/100): https://www.google.com/intl/es-419/gmail/about/
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 32 pages crawled
Crawling (33/100): https://www.google.com/intl/es-419/gmail/about/for-work/
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 33 pages crawled
Crawling (34/100): https://www.google.com/intl/es-419/gmail/about/policy/
Crawling (35/100): https://www.google.com/intl/es/gmail/about/
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 34 pages crawled
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 35 pages crawled
Crawling (36/100): https://www.google.com/intl/es/gmail/about/for-work/
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 36 pages crawled
Crawling (37/100): https://www.google.com/intl/es/gmail/about/policy/
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 37 pages crawled
Crawling (38/100): https://www.google.com/intl/et/gmail/about/
Crawling (39/100): https://www.google.com/intl/et/gmail/about/for-work/
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 38 pages crawled
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 39 pages crawled
Crawling (40/100): https://www.google.com/intl/et/gmail/about/policy/
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 40 pages crawled
Crawling (41/100): https://www.google.com/intl/eu_es/gmail/about/
Crawling (42/100): https://www.google.com/intl/eu_es/gmail/about/for-work/
Crawling (43/100): https://www.google.com/intl/eu_es/gmail/about/policy/
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 41 pages crawled
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 42 pages crawled
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 43 pages crawled
Crawling (44/100): https://www.google.com/intl/fa/gmail/about/
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 44 pages crawled
Crawling (45/100): https://www.google.com/intl/fa/gmail/about/for-work/
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 45 pages crawled
Crawling (46/100): https://www.google.com/intl/fa/gmail/about/policy/
Crawling (47/100): https://www.google.com/intl/fi/gmail/about/
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 46 pages crawled
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 47 pages crawled
Crawling (48/100): https://www.google.com/intl/fi/gmail/about/for-work/
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 48 pages crawled
Crawling (49/100): https://www.google.com/intl/fil/gmail/about/
Crawling (50/100): https://www.google.com/intl/fi/gmail/about/policy/
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 49 pages crawled
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 50 pages crawled
Crawling (51/100): https://www.google.com/intl/fil/gmail/about/for-work/
Crawling (52/100): https://www.google.com/intl/fil/gmail/about/policy/
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 51 pages crawled
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 52 pages crawled
Crawling (53/100): https://www.google.com/intl/fr/gmail/about/
Crawling (54/100): https://www.google.com/intl/fr/gmail/about/for-work/
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 53 pages crawled
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 54 pages crawled
Crawling (55/100): https://www.google.com/intl/fr/gmail/about/policy/
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 55 pages crawled
Crawling (56/100): https://www.google.com/intl/gl_es/gmail/about/for-work/
Crawling (57/100): https://www.google.com/intl/gl_es/gmail/about/
Crawling (58/100): https://www.google.com/intl/gl_es/gmail/about/policy/
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 56 pages crawled
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 57 pages crawled
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 58 pages crawled
Crawling (59/100): https://www.google.com/intl/gu_in/gmail/about/
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 59 pages crawled
Crawling (60/100): https://www.google.com/intl/gu_in/gmail/about/for-work/
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 60 pages crawled
Crawling (61/100): https://www.google.com/intl/gu_in/gmail/about/policy/
Crawling (62/100): https://www.google.com/intl/hi/gmail/about/
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 61 pages crawled
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 62 pages crawled
Crawling (63/100): https://www.google.com/intl/hi/gmail/about/policy/
Crawling (64/100): https://www.google.com/intl/hi/gmail/about/for-work/
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 63 pages crawled
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 64 pages crawled
Crawling (65/100): https://www.google.com/intl/hr/gmail/about/
Crawling (66/100): https://www.google.com/intl/hr/gmail/about/for-work/
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 65 pages crawled
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 66 pages crawled
Crawling (67/100): https://www.google.com/intl/hr/gmail/about/policy/
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 67 pages crawled
Crawling (68/100): https://www.google.com/intl/hu/gmail/about/
Crawling (69/100): https://www.google.com/intl/hu/gmail/about/for-work/
Crawling (70/100): https://www.google.com/intl/hu/gmail/about/policy/
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 68 pages crawled
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 69 pages crawled
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 70 pages crawled
Crawling (71/100): https://www.google.com/intl/id/gmail/about/
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 71 pages crawled
Crawling (72/100): https://www.google.com/intl/id/gmail/about/for-work/
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 72 pages crawled
Crawling (73/100): https://www.google.com/intl/id/gmail/about/policy/
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 73 pages crawled
Crawling (74/100): https://www.google.com/intl/is/gmail/about/
Crawling (75/100): https://www.google.com/intl/is/gmail/about/for-work/
Crawling (76/100): https://www.google.com/intl/is/gmail/about/policy/
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 74 pages crawled
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 75 pages crawled
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 76 pages crawled
Crawling (77/100): https://www.google.com/intl/it/gmail/about/
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 77 pages crawled
Crawling (78/100): https://www.google.com/intl/it/gmail/about/for-work/
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 78 pages crawled
Crawling (79/100): https://www.google.com/intl/it/gmail/about/policy/
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 79 pages crawled
Crawling (80/100): https://www.google.com/intl/he/gmail/about/
Crawling (81/100): https://www.google.com/intl/he/gmail/about/for-work/
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 80 pages crawled
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 81 pages crawled
Crawling (82/100): https://www.google.com/intl/he/gmail/about/policy/
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 82 pages crawled
Crawling (83/100): https://www.google.com/intl/ja/gmail/about/
Crawling (84/100): https://www.google.com/intl/ja/gmail/about/for-work/
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 83 pages crawled
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 84 pages crawled
Crawling (85/100): https://www.google.com/intl/ja/gmail/about/policy/
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 85 pages crawled
Crawling (86/100): https://www.google.com/intl/kn_in/gmail/about/
Crawling (87/100): https://www.google.com/intl/kn_in/gmail/about/for-work/
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 86 pages crawled
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 87 pages crawled
Crawling (88/100): https://www.google.com/intl/kn_in/gmail/about/policy/
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 88 pages crawled
Crawling (89/100): https://www.google.com/intl/ko/gmail/about/
Crawling (90/100): https://www.google.com/intl/ko/gmail/about/for-work/
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 89 pages crawled
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 90 pages crawled
Crawling (91/100): https://www.google.com/intl/ko/gmail/about/policy/
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 91 pages crawled
Crawling (92/100): https://www.google.com/intl/lt/gmail/about/
Crawling (93/100): https://www.google.com/intl/lt/gmail/about/for-work/
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 92 pages crawled
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 93 pages crawled
Crawling (94/100): https://www.google.com/intl/lt/gmail/about/policy/
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 94 pages crawled
Crawling (95/100): https://www.google.com/intl/lv/gmail/about/for-work/
Crawling (96/100): https://www.google.com/intl/lv/gmail/about/
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 95 pages crawled
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 96 pages crawled
Crawling (97/100): https://www.google.com/intl/lv/gmail/about/policy/
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 97 pages crawled
Crawling (98/100): https://www.google.com/intl/ml_in/gmail/about/for-work/
Crawling (99/100): https://www.google.com/intl/ml_in/gmail/about/
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 98 pages crawled
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 99 pages crawled
Crawling (100/100): https://www.google.com/intl/ml_in/gmail/about/policy/
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 100 pages crawled
ðŸ§  Running Rule Engine for crawl analysis cmglggmky0001r28r527suh10
âœ… Added 0 rule-based recommendations
ðŸ“Š Added RUM data with 0 samples
ðŸ” Running Change Detection for crawl https://www.google.com
ðŸ“¸ Created snapshot 2f1f169a-ffc1-4865-87ff-55613f990225 for https://www.google.com
ðŸ“Š PROGRESS UPDATE [Crawl 1031]: 100 pages crawled
Crawl job 1031 completed in 19274ms
ðŸ’¾ Updating Crawl analysis cmglggmky0001r28r527suh10 in database
âœ… Using Prisma singleton for database connection
Queue worker using Chrome at: /usr/bin/chromium
PM2 Instance: 0, Running Lighthouse: true
ðŸ•·ï¸ Creating Crawl worker (enabled=true, isMainInstance=true)
ðŸ”’ Memory guard started for queue-workers-0 (limit: 1100MB)
[STORAGE] Local artifact storage initialized at /home/reda/seo-analyzer-nextjs/artifacts
âœ… Connected to Redis
Processing Crawl job 1033 for https://www.google.com
ðŸ¤– Processing AI Analysis job 79 for https://seoanalyze.se/
ðŸ¤– Step 1: Analyzing user's website https://seoanalyze.se/
ðŸ”„ STATE TRANSITION [Crawl 1033]: waiting â†’ active (worker picked up job)
ðŸ”„ STATE TRANSITION [AI Analysis 79]: waiting â†’ active (worker picked up job)
ðŸ“Š PROGRESS UPDATE [Crawl 1033]: 10 pages crawled
Loaded robots.txt
ðŸ¤– Created SEO analysis: cmglgpewi0000r2lrlg4r3f3y, Crawl analysis: cmglgpewq0001r2lr2haqvooz, Lighthouse analysis: cmglgpews0002r2lrjlyyxl2z
Added SEO job 5322 for https://seoanalyze.se/
Processing SEO job 5322 for https://seoanalyze.se/
ðŸ”„ STATE TRANSITION [SEO 5322]: waiting â†’ active (worker picked up job)
Could not parse sitemap: https://www.google.com/slides/sitemaps.xml
Added Crawl job 1035 for https://seoanalyze.se/
ðŸ“Š PROGRESS UPDATE [SEO 5322]: 10%
Could not parse sitemap: https://www.google.com/sheets/sitemaps.xml
Added Lighthouse job 513 for https://seoanalyze.se/
Processing Lighthouse job 513 for https://seoanalyze.se/
ðŸ¤– Waiting for user SEO (5322), Crawl (1035), and Lighthouse (513)
ðŸ”„ STATE TRANSITION [Lighthouse 513]: waiting â†’ active (worker picked up job)
ðŸ“Š PROGRESS UPDATE [Lighthouse 513]: 10%
Loading ES modules...
ðŸ“Š PROGRESS UPDATE [SEO 5322]: 30%
DEBUG: HTML retrieved for https://seoanalyze.se/, HTML sample=<!DOCTYPE html><!--9cgQzoniMRb1BVtM0dP4u--><html lang="sv"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" as="image" imageSrcSet=
DEBUG: performSeoAnalysis creating new Cheerio instance for https://seoanalyze.se/
DEBUG: Cheerio version: 1.1.2
DEBUG: URL=https://seoanalyze.se/, Cheerio found 0 scripts, 0 JSON-LD
DEBUG: Using regex fallback for JSON-LD extraction
Found JSON-LD via regex: {"@context":"https://schema.org","@graph":[{"@type":"Organization","@id":"https://seoanalyze.se/#org...
Schema detection: found 1 scripts, hasSchema: true, types: Organization,WebSite,SoftwareApplication,BreadcrumbList
robots.txt check: true
sitemap.xml check: true
ðŸ“Š PROGRESS UPDATE [SEO 5322]: 90%
[SCREENSHOT] start id=cmglgpewi0000r2lrlg4r3f3y url=https://seoanalyze.se/
Creating new browser instance...
Browser instance created
Browser acquired from pool (1 in pool, 0 available)
Using Chrome path: /usr/bin/chromium
Chrome flags: 14 flags configured
Lighthouse categories: performance, accessibility, seo, best-practices
Could not parse sitemap: https://www.google.com/search/about/sitemap.xml
[SAVE] Saved artifact locally: analyses/2025-10-10/cmglgpewi0000r2lrlg4r3f3y/screenshots/desktop.png
[SCREENSHOT] desktop OK key=analyses/2025-10-10/cmglgpewi0000r2lrlg4r3f3y/screenshots/desktop.png
Could not parse sitemap: https://www.google.com/calendar/about/sitemap.xml
Could not parse sitemap: https://www.google.com/sitemap_index.xml
Could not parse sitemap: https://www.google.com/sitemap.txt
[SAVE] Saved artifact locally: analyses/2025-10-10/cmglgpewi0000r2lrlg4r3f3y/screenshots/mobile.png
[SCREENSHOT] mobile OK key=analyses/2025-10-10/cmglgpewi0000r2lrlg4r3f3y/screenshots/mobile.png
Browser operation completed in 7388ms
Browser released to pool
[SAVE] Saved artifact locally: analyses/2025-10-10/cmglgpewi0000r2lrlg4r3f3y/seo-results.json
Could not parse sitemap: https://www.google.com/sitemaps.xml
Could not parse sitemap: https://www.google.com/sitemap-index.xml
ðŸ“ Updated analysis cmglgpewi0000r2lrlg4r3f3y status to completed
ðŸ’¾ Saved SEO analysis cmglgpewi0000r2lrlg4r3f3y to database and artifacts
Could not parse sitemap: https://www.google.com/wp-sitemap.xml
Could not parse sitemap: https://www.google.com/page-sitemap.xml
Found 44255 URLs in sitemap - using sitemap-first strategy
Crawling (1/100): https://www.google.com
ðŸ“¸ Created snapshot e9c4ac82-52a4-4868-a153-b09f03e9496b for https://seoanalyze.se/
ðŸ“Š PROGRESS UPDATE [Crawl 1033]: 1 pages crawled
ðŸ“Š PROGRESS UPDATE [SEO 5322]: 100%
SEO job 5322 completed in 9627ms
ðŸ“Š METRICS [SEO]: domain=seoanalyze.se, score=98, issuesCount=0, durationMs=9627
ðŸ”„ STATE TRANSITION [SEO 5322]: active â†’ completed (resultId: cmglgpewi0000r2lrlg4r3f3y)
Crawling (2/100): https://www.google.com/intl/am/gmail/about/
Crawling (3/100): https://www.google.com/intl/am/gmail/about/for-work/
Crawling (4/100): https://www.google.com/intl/am/gmail/about/policy/
ðŸ“Š PROGRESS UPDATE [Crawl 1033]: 2 pages crawled
ðŸ“Š PROGRESS UPDATE [Crawl 1033]: 3 pages crawled
ðŸ“Š PROGRESS UPDATE [Crawl 1033]: 4 pages crawled
Crawling (5/100): https://www.google.com/intl/ar/gmail/about/
ðŸ“Š PROGRESS UPDATE [Crawl 1033]: 5 pages crawled
Crawling (6/100): https://www.google.com/intl/ar/gmail/about/for-work/
ðŸ“Š PROGRESS UPDATE [Crawl 1033]: 6 pages crawled
Crawling (7/100): https://www.google.com/intl/ar/gmail/about/policy/
ðŸ“Š PROGRESS UPDATE [Crawl 1033]: 7 pages crawled
Crawling (8/100): https://www.google.com/intl/bg/gmail/about/
Crawling (9/100): https://www.google.com/intl/bg/gmail/about/for-work/
ðŸ“Š PROGRESS UPDATE [Crawl 1033]: 8 pages crawled
ðŸ“Š PROGRESS UPDATE [Crawl 1033]: 9 pages crawled
Crawling (10/100): https://www.google.com/intl/bg/gmail/about/policy/
ðŸ“Š PROGRESS UPDATE [Crawl 1033]: 10 pages crawled
Crawling (11/100): https://www.google.com/intl/bn/gmail/about/
ðŸ“Š PROGRESS UPDATE [Crawl 1033]: 11 pages crawled
Crawling (12/100): https://www.google.com/intl/bn/gmail/about/for-work/
ðŸ“Š PROGRESS UPDATE [Crawl 1033]: 12 pages crawled
Crawling (13/100): https://www.google.com/intl/bn/gmail/about/policy/
ðŸ“Š PROGRESS UPDATE [Crawl 1033]: 13 pages crawled
Crawling (14/100): https://www.google.com/intl/cs/gmail/about/
Crawling (15/100): https://www.google.com/intl/cs/gmail/about/for-work/
ðŸ“Š PROGRESS UPDATE [Crawl 1033]: 14 pages crawled
ðŸ“Š PROGRESS UPDATE [Crawl 1033]: 15 pages crawled
Crawling (16/100): https://www.google.com/intl/cs/gmail/about/policy/
ðŸ“Š PROGRESS UPDATE [Crawl 1033]: 16 pages crawled
Crawling (17/100): https://www.google.com/intl/da/gmail/about/
ðŸ“Š PROGRESS UPDATE [Crawl 1033]: 17 pages crawled
Crawling (18/100): https://www.google.com/intl/da/gmail/about/for-work/
Crawling (19/100): https://www.google.com/intl/da/gmail/about/policy/
ðŸ“Š PROGRESS UPDATE [Crawl 1033]: 18 pages crawled
ðŸ“Š PROGRESS UPDATE [Crawl 1033]: 19 pages crawled
Crawling (20/100): https://www.google.com/intl/de/gmail/about/
ðŸ“Š PROGRESS UPDATE [Crawl 1033]: 20 pages crawled
Crawling (21/100): https://www.google.com/intl/de/gmail/about/for-work/
ðŸ“Š PROGRESS UPDATE [Crawl 1033]: 21 pages crawled
Crawling (22/100): https://www.google.com/intl/de/gmail/about/policy/
ðŸ“Š PROGRESS UPDATE [Crawl 1033]: 22 pages crawled
Crawling (23/100): https://www.google.com/intl/el/gmail/about/
Crawling (24/100): https://www.google.com/intl/el/gmail/about/for-work/
ðŸ“Š PROGRESS UPDATE [Crawl 1033]: 23 pages crawled
ðŸ“Š PROGRESS UPDATE [Crawl 1033]: 24 pages crawled
Crawling (25/100): https://www.google.com/intl/el/gmail/about/policy/
ðŸ“Š Memory [queue-workers-0]: RSS 369MB, Heap 194MB
ðŸ“Š PROGRESS UPDATE [Crawl 1033]: 25 pages crawled
Crawling (26/100): https://www.google.com/intl/en_in/gmail/about/
Crawling (27/100): https://www.google.com/intl/en_in/gmail/about/for-work/
ðŸ“Š PROGRESS UPDATE [Crawl 1033]: 26 pages crawled
ðŸ“Š PROGRESS UPDATE [Crawl 1033]: 27 pages crawled
Crawling (28/100): https://www.google.com/intl/en_in/gmail/about/policy/
ðŸ“Š PROGRESS UPDATE [Crawl 1033]: 28 pages crawled
Crawling (29/100): https://www.google.com/intl/en_uk/gmail/about/
Crawling (30/100): https://www.google.com/intl/en_uk/gmail/about/for-work/
Crawling (31/100): https://www.google.com/intl/en_uk/gmail/about/policy/
ðŸ“Š PROGRESS UPDATE [Crawl 1033]: 29 pages crawled
ðŸ“Š PROGRESS UPDATE [Crawl 1033]: 30 pages crawled
ðŸ“Š PROGRESS UPDATE [Crawl 1033]: 31 pages crawled
Crawling (32/100): https://www.google.com/intl/es-419/gmail/about/
ðŸ“Š PROGRESS UPDATE [Crawl 1033]: 32 pages crawled
Crawling (33/100): https://www.google.com/intl/es-419/gmail/about/for-work/
ðŸ“Š PROGRESS UPDATE [Crawl 1033]: 33 pages crawled
Crawling (34/100): https://www.google.com/intl/es-419/gmail/about/policy/
ðŸ“Š PROGRESS UPDATE [Crawl 1033]: 34 pages crawled
Crawling (35/100): https://www.google.com/intl/es/gmail/about/
Crawling (36/100): https://www.google.com/intl/es/gmail/about/policy/
Crawling (37/100): https://www.google.com/intl/es/gmail/about/for-work/
ðŸ“Š PROGRESS UPDATE [Crawl 1033]: 35 pages crawled
ðŸ“Š PROGRESS UPDATE [Crawl 1033]: 36 pages crawled
ðŸ“Š PROGRESS UPDATE [Crawl 1033]: 37 pages crawled
Crawling (38/100): https://www.google.com/intl/et/gmail/about/
ðŸ“Š PROGRESS UPDATE [Crawl 1033]: 38 pages crawled
Crawling (39/100): https://www.google.com/intl/et/gmail/about/for-work/
ðŸ“Š PROGRESS UPDATE [Crawl 1033]: 39 pages crawled
Crawling (40/100): https://www.google.com/intl/et/gmail/about/policy/
Crawling (41/100): https://www.google.com/intl/eu_es/gmail/about/
ðŸ“Š PROGRESS UPDATE [Crawl 1033]: 40 pages crawled
ðŸ“Š PROGRESS UPDATE [Crawl 1033]: 41 pages crawled
Crawling (42/100): https://www.google.com/intl/eu_es/gmail/about/for-work/
ðŸ“Š PROGRESS UPDATE [Crawl 1033]: 42 pages crawled
Crawling (43/100): https://www.google.com/intl/eu_es/gmail/about/policy/
Crawling (44/100): https://www.google.com/intl/fa/gmail/about/
ðŸ“Š PROGRESS UPDATE [Crawl 1033]: 43 pages crawled
ðŸ“Š PROGRESS UPDATE [Crawl 1033]: 44 pages crawled
Crawling (45/100): https://www.google.com/intl/fa/gmail/about/for-work/
ðŸ“Š PROGRESS UPDATE [Crawl 1033]: 45 pages crawled
Crawling (46/100): https://www.google.com/intl/fa/gmail/about/policy/
ðŸ“Š PROGRESS UPDATE [Crawl 1033]: 46 pages crawled
Chrome process 16509 killed successfully
Crawling (47/100): https://www.google.com/intl/fi/gmail/about/
ðŸ“Š PROGRESS UPDATE [Crawl 1033]: 47 pages crawled
Cleaned up temp directory: /tmp/lighthouse-1760137978644-7ww8bl91-16335
ðŸ“Š PROGRESS UPDATE [Lighthouse 513]: 90%
ðŸ§  Running Rule Engine for analysis cmglgpews0002r2lrjlyyxl2z
âœ… Added 0 rule-based recommendations
ðŸ“Š Added RUM data with 128 samples
ðŸ” Running Change Detection for https://seoanalyze.se/
ðŸ“¸ Created snapshot a92f08e8-1be5-4d25-9f51-6f0e16787291 for https://seoanalyze.se/
ðŸ“Š PROGRESS UPDATE [Lighthouse 513]: 100%
Lighthouse job 513 completed in 21221ms
ðŸ’¾ Updating Lighthouse analysis cmglgpews0002r2lrjlyyxl2z in database
ðŸ’¾ DB results uppdaterade fÃ¶r cmglgpews0002r2lrjlyyxl2z
ðŸ“ Updated analysis cmglgpews0002r2lrjlyyxl2z status to completed
[SAVE] Saved artifact locally: analyses/2025-10-10/cmglgpews0002r2lrjlyyxl2z/lighthouse-results.json
âœ… Lighthouse analysis cmglgpews0002r2lrjlyyxl2z updated in database and artifacts
ðŸ“Š METRICS [Lighthouse]: domain=seoanalyze.se, score=89, issuesCount=2, durationMs=21239
ðŸ”„ STATE TRANSITION [Lighthouse 513]: active â†’ completed (resultId: cmglgpews0002r2lrjlyyxl2z)
Crawling (48/100): https://www.google.com/intl/fi/gmail/about/for-work/
ðŸ“Š PROGRESS UPDATE [Crawl 1033]: 48 pages crawled
Crawling (49/100): https://www.google.com/intl/fi/gmail/about/policy/
ðŸ“Š PROGRESS UPDATE [Crawl 1033]: 49 pages crawled
Crawling (50/100): https://www.google.com/intl/fil/gmail/about/
Crawling (51/100): https://www.google.com/intl/fil/gmail/about/for-work/
Crawling (52/100): https://www.google.com/intl/fil/gmail/about/policy/
ðŸ“Š PROGRESS UPDATE [Crawl 1033]: 50 pages crawled
ðŸ“Š PROGRESS UPDATE [Crawl 1033]: 51 pages crawled
ðŸ“Š PROGRESS UPDATE [Crawl 1033]: 52 pages crawled
Crawling (53/100): https://www.google.com/intl/fr/gmail/about/
ðŸ“Š PROGRESS UPDATE [Crawl 1033]: 53 pages crawled
Crawling (54/100): https://www.google.com/intl/fr/gmail/about/for-work/
ðŸ“Š PROGRESS UPDATE [Crawl 1033]: 54 pages crawled
Crawling (55/100): https://www.google.com/intl/fr/gmail/about/policy/
ðŸ“Š PROGRESS UPDATE [Crawl 1033]: 55 pages crawled
Crawling (56/100): https://www.google.com/intl/gl_es/gmail/about/policy/
Crawling (57/100): https://www.google.com/intl/gl_es/gmail/about/
Crawling (58/100): https://www.google.com/intl/gl_es/gmail/about/for-work/
ðŸ“Š PROGRESS UPDATE [Crawl 1033]: 56 pages crawled
ðŸ“Š PROGRESS UPDATE [Crawl 1033]: 57 pages crawled
ðŸ“Š PROGRESS UPDATE [Crawl 1033]: 58 pages crawled
Crawling (59/100): https://www.google.com/intl/gu_in/gmail/about/
ðŸ“Š PROGRESS UPDATE [Crawl 1033]: 59 pages crawled
Crawling (60/100): https://www.google.com/intl/gu_in/gmail/about/for-work/
ðŸ“Š PROGRESS UPDATE [Crawl 1033]: 60 pages crawled
Crawling (61/100): https://www.google.com/intl/hi/gmail/about/
Crawling (62/100): https://www.google.com/intl/gu_in/gmail/about/policy/
ðŸ“Š PROGRESS UPDATE [Crawl 1033]: 61 pages crawled
ðŸ“Š PROGRESS UPDATE [Crawl 1033]: 62 pages crawled
Crawling (63/100): https://www.google.com/intl/hi/gmail/about/for-work/
ðŸ“Š PROGRESS UPDATE [Crawl 1033]: 63 pages crawled
Crawling (64/100): https://www.google.com/intl/hi/gmail/about/policy/
Crawling (65/100): https://www.google.com/intl/hr/gmail/about/
ðŸ“Š PROGRESS UPDATE [Crawl 1033]: 64 pages crawled
ðŸ“Š PROGRESS UPDATE [Crawl 1033]: 65 pages crawled
Crawling (66/100): https://www.google.com/intl/hr/gmail/about/for-work/
ðŸ“Š PROGRESS UPDATE [Crawl 1033]: 66 pages crawled
Crawling (67/100): https://www.google.com/intl/hr/gmail/about/policy/
Crawling (68/100): https://www.google.com/intl/hu/gmail/about/
ðŸ“Š PROGRESS UPDATE [Crawl 1033]: 67 pages crawled
ðŸ“Š PROGRESS UPDATE [Crawl 1033]: 68 pages crawled
Crawling (69/100): https://www.google.com/intl/hu/gmail/about/for-work/
ðŸ“Š PROGRESS UPDATE [Crawl 1033]: 69 pages crawled
Crawling (70/100): https://www.google.com/intl/hu/gmail/about/policy/
ðŸ“Š PROGRESS UPDATE [Crawl 1033]: 70 pages crawled
Crawling (71/100): https://www.google.com/intl/id/gmail/about/
Crawling (72/100): https://www.google.com/intl/id/gmail/about/for-work/
ðŸ“Š PROGRESS UPDATE [Crawl 1033]: 71 pages crawled
ðŸ“Š PROGRESS UPDATE [Crawl 1033]: 72 pages crawled
Crawling (73/100): https://www.google.com/intl/id/gmail/about/policy/
ðŸ“Š PROGRESS UPDATE [Crawl 1033]: 73 pages crawled
Crawling (74/100): https://www.google.com/intl/is/gmail/about/
Crawling (75/100): https://www.google.com/intl/is/gmail/about/for-work/
ðŸ“Š PROGRESS UPDATE [Crawl 1033]: 74 pages crawled
ðŸ“Š PROGRESS UPDATE [Crawl 1033]: 75 pages crawled
Crawling (76/100): https://www.google.com/intl/is/gmail/about/policy/
ðŸ“Š PROGRESS UPDATE [Crawl 1033]: 76 pages crawled
Crawling (77/100): https://www.google.com/intl/it/gmail/about/
Crawling (78/100): https://www.google.com/intl/it/gmail/about/for-work/
ðŸ“Š PROGRESS UPDATE [Crawl 1033]: 77 pages crawled
ðŸ“Š PROGRESS UPDATE [Crawl 1033]: 78 pages crawled
Crawling (79/100): https://www.google.com/intl/it/gmail/about/policy/
ðŸ“Š PROGRESS UPDATE [Crawl 1033]: 79 pages crawled
Crawling (80/100): https://www.google.com/intl/he/gmail/about/
Crawling (81/100): https://www.google.com/intl/he/gmail/about/for-work/
Crawling (82/100): https://www.google.com/intl/he/gmail/about/policy/
ðŸ“Š PROGRESS UPDATE [Crawl 1033]: 80 pages crawled
ðŸ“Š PROGRESS UPDATE [Crawl 1033]: 81 pages crawled
ðŸ“Š PROGRESS UPDATE [Crawl 1033]: 82 pages crawled
Crawling (83/100): https://www.google.com/intl/ja/gmail/about/
ðŸ“Š PROGRESS UPDATE [Crawl 1033]: 83 pages crawled
Crawling (84/100): https://www.google.com/intl/ja/gmail/about/for-work/
ðŸ“Š PROGRESS UPDATE [Crawl 1033]: 84 pages crawled
Crawling (85/100): https://www.google.com/intl/ja/gmail/about/policy/
ðŸ“Š PROGRESS UPDATE [Crawl 1033]: 85 pages crawled
Crawling (86/100): https://www.google.com/intl/kn_in/gmail/about/
Crawling (87/100): https://www.google.com/intl/kn_in/gmail/about/for-work/
Crawling (88/100): https://www.google.com/intl/kn_in/gmail/about/policy/
ðŸ“Š PROGRESS UPDATE [Crawl 1033]: 86 pages crawled
ðŸ“Š PROGRESS UPDATE [Crawl 1033]: 87 pages crawled
ðŸ“Š PROGRESS UPDATE [Crawl 1033]: 88 pages crawled
Crawling (89/100): https://www.google.com/intl/ko/gmail/about/
ðŸ“Š PROGRESS UPDATE [Crawl 1033]: 89 pages crawled
Crawling (90/100): https://www.google.com/intl/ko/gmail/about/for-work/
ðŸ“Š PROGRESS UPDATE [Crawl 1033]: 90 pages crawled
Crawling (91/100): https://www.google.com/intl/ko/gmail/about/policy/
ðŸ“Š PROGRESS UPDATE [Crawl 1033]: 91 pages crawled
Crawling (92/100): https://www.google.com/intl/lt/gmail/about/
Crawling (93/100): https://www.google.com/intl/lt/gmail/about/for-work/
Crawling (94/100): https://www.google.com/intl/lt/gmail/about/policy/
ðŸ“Š PROGRESS UPDATE [Crawl 1033]: 92 pages crawled
ðŸ“Š PROGRESS UPDATE [Crawl 1033]: 93 pages crawled
ðŸ“Š PROGRESS UPDATE [Crawl 1033]: 94 pages crawled
Crawling (95/100): https://www.google.com/intl/lv/gmail/about/
ðŸ“Š PROGRESS UPDATE [Crawl 1033]: 95 pages crawled
Crawling (96/100): https://www.google.com/intl/lv/gmail/about/for-work/
ðŸ“Š PROGRESS UPDATE [Crawl 1033]: 96 pages crawled
Crawling (97/100): https://www.google.com/intl/ml_in/gmail/about/
Crawling (98/100): https://www.google.com/intl/lv/gmail/about/policy/
ðŸ“Š PROGRESS UPDATE [Crawl 1033]: 97 pages crawled
ðŸ“Š PROGRESS UPDATE [Crawl 1033]: 98 pages crawled
Crawling (99/100): https://www.google.com/intl/ml_in/gmail/about/for-work/
Crawling (100/100): https://www.google.com/intl/ml_in/gmail/about/policy/
ðŸ“Š PROGRESS UPDATE [Crawl 1033]: 99 pages crawled
ðŸ“Š PROGRESS UPDATE [Crawl 1033]: 100 pages crawled
ðŸ§  Running Rule Engine for crawl analysis cmglgj4920004r2lopvloi4sr
âœ… Added 0 rule-based recommendations
ðŸ“Š Added RUM data with 0 samples
ðŸ” Running Change Detection for crawl https://www.google.com
ðŸ“¸ Created snapshot f008ba21-eae7-4c56-9299-d056c11ec1c9 for https://www.google.com
ðŸ“Š PROGRESS UPDATE [Crawl 1033]: 100 pages crawled
Crawl job 1033 completed in 29514ms
ðŸ’¾ Updating Crawl analysis cmglgj4920004r2lopvloi4sr in database
ðŸ’¾ DB results uppdaterade fÃ¶r crawl cmglgj4920004r2lopvloi4sr
Destroying browser instance...
ðŸ“ Updated analysis cmglgj4920004r2lopvloi4sr status to completed
Browser instance destroyed
[SAVE] Saved artifact locally: analyses/2025-10-10/cmglgj4920004r2lopvloi4sr/crawl-results.json
âœ… Crawl analysis cmglgj4920004r2lopvloi4sr updated in database and artifacts
ðŸ“Š METRICS [Crawl]: domain=www.google.com, score=0, issuesCount=2569, durationMs=42044, pagesCount=100
Processing Crawl job 1034 for https://nobina.se
ðŸ”„ STATE TRANSITION [Crawl 1033]: active â†’ completed (resultId: cmglgj4920004r2lopvloi4sr)
ðŸ”„ STATE TRANSITION [Crawl 1034]: waiting â†’ active (worker picked up job)
ðŸ”„ STATE TRANSITION [Crawl 1031]: active â†’ failed (error: job stalled more than allowable limit)
ðŸ“Š PROGRESS UPDATE [Crawl 1034]: 10 pages crawled
Loaded robots.txt
Could not parse sitemap: https://nobina.se/sitemap_index.xml
Could not parse sitemap: https://nobina.se/sitemap.txt
Could not parse sitemap: https://nobina.se/sitemaps.xml
Could not parse sitemap: https://nobina.se/sitemap-index.xml
Could not parse sitemap: https://nobina.se/wp-sitemap.xml
Could not parse sitemap: https://nobina.se/page-sitemap.xml
Found 320 URLs in sitemap - using sitemap-first strategy
Crawling (1/100): https://nobina.se
Robots.txt blocks: https://www.nobina.se/vara-losningar/hyr-buss/sweden-rock/sweden-rock-english/
Robots.txt blocks: https://www.nobina.se/vara-losningar/hyr-buss/sweden-rock/sa-funkar-nobina-biljetten/
Robots.txt blocks: https://www.nobina.se/vara-losningar/hyr-buss/sweden-rock/nobina-ticket-faq-english/
Robots.txt blocks: https://www.nobina.se/vara-losningar/hyr-buss/sweden-rock/nobina-yksittaisen-lipun-ukk/
Robots.txt blocks: https://www.nobina.se/jobba-hos-oss/nobina-som-arbetsgivare/vart-arbete-med-mangfald-och-inkludering/lingio/
Robots.txt blocks: https://www.nobina.se/jobba-hos-oss/nobina-som-arbetsgivare/vart-arbete-med-mangfald-och-inkludering/mitt-liv-mentorprogram/
Robots.txt blocks: https://www.nobina.se/jobba-hos-oss/nobina-som-arbetsgivare/vart-arbete-med-mangfald-och-inkludering/korta-vagen/
Robots.txt blocks: https://www.nobina.se/vara-losningar/hyr-buss/referenser-hyra-buss-hos-nobina/angsjo-lyftet-jarfalla/
Robots.txt blocks: https://www.nobina.se/vara-losningar/hyr-buss/referenser-hyra-buss-hos-nobina/stockholm-mean-machines/
Robots.txt blocks: https://www.nobina.se/vara-losningar/hyr-buss/nobina-eventtrafik/fragor-och-svar-nobina-eventtrafik/
Robots.txt blocks: https://www.nobina.se/vara-losningar/hyr-buss/nobina-hyrbuss/fragor-och-svar-nobina-hyrbuss/
Robots.txt blocks: https://www.nobina.se/vara-losningar/hyr-buss/referenser-nobina-eventtrafik/sweden-rock-festival/
Robots.txt blocks: https://www.nobina.se/vara-losningar/hyr-buss/referenser-nobina-eventtrafik/o-ringen/
Robots.txt blocks: https://www.nobina.se/om-oss/dataskydd-och-integritet/personuppgiftsbehandling/cookies/
Robots.txt blocks: https://www.nobina.se/jobba-hos-oss/nobina-som-arbetsgivare/en-trygg-resa-borjar-i-verkstaden/mot-vara-mekaniker/
Robots.txt blocks: https://www.nobina.se/jobba-hos-oss/nobina-som-arbetsgivare/en-trygg-resa-borjar-i-verkstaden/fordonsvard/
Robots.txt blocks: https://www.nobina.se/uppstart-nv/nacka-varmdo/om-oss/resenarsloftet/
Robots.txt blocks: https://www.nobina.se/uppstart-nv/nacka-varmdo/lokal-information/infobrev/
Robots.txt blocks: https://www.nobina.se/uppstart-karlstad/karlstad/om-oss/nobinas-resenarslofte/
Robots.txt blocks: https://www.nobina.se/uppstart-karlstad/karlstad/om-oss/vara-varderingar/
Robots.txt blocks: https://www.nobina.se/uppstart-karlstad/karlstad/om-oss/till-nobina.se/
Robots.txt blocks: https://www.nobina.se/uppstart-karlstad/karlstad/lokal-information/utbildning/
Robots.txt blocks: https://www.nobina.se/uppstart-stenungsund/stenungsund/om-oss/vara-varderingar/
Robots.txt blocks: https://www.nobina.se/uppstart-stenungsund/stenungsund/om-oss/till-nobina.se/
Robots.txt blocks: https://www.nobina.se/uppstart-stenungsund/stenungsund/om-oss/nobinas-uniform/
Robots.txt blocks: https://www.nobina.se/uppstart-umea/umea/lokal-information/vara-arbetssatt/
Robots.txt blocks: https://www.nobina.se/uppstart-stenungsund/stenungsund/lokal-information/
Robots.txt blocks: https://www.nobina.se/uppstart-stenungsund/stenungsund/fragor-och-svar/
Robots.txt blocks: https://www.nobina.se/uppstart-stenungsund/stenungsund/kontakt/
Robots.txt blocks: https://www.nobina.se/vara-losningar/nobina-forum/webinar-om-flexibel-on-demand-trafik/
Robots.txt blocks: https://www.nobina.se/nyheter/2025/nobina-och-vr-skriver-nobina-skriver-10-arigt-avtal-om-ersattningstrafik-for-norrtag/
Robots.txt blocks: https://www.nobina.se/nyheter/2025/nu-ar-vi-igang/
Robots.txt blocks: https://www.nobina.se/nyheter/2025/it-storningar-hos-nobina--nu-ar-systemen-igang/
Robots.txt blocks: https://www.nobina.se/nyheter/2025/just-nu-inget-trafikavtal-for-sodertorn-e45-efter-19-juni-2025/
Robots.txt blocks: https://www.nobina.se/nyheter/2025/farre-an-1-av-10-bussresenarer-anvander-balte-i-kollektivtrafiken/
Robots.txt blocks: https://www.nobina.se/nyheter/2025/forarnas-arbetsdag/
Robots.txt blocks: https://www.nobina.se/nyheter/2025/nobina-uppmarksammar-bussforarens-dag/
Robots.txt blocks: https://www.nobina.se/nyheter/2025/tack-alla-bussforare/
Robots.txt blocks: https://www.nobina.se/nyheter/2025/den-grona-resan--hallbarhet-i-varje-resa/
Robots.txt blocks: https://www.nobina.se/nyheter/2025/paxi---hallands-forsta-on-demand-buss/
Robots.txt blocks: https://www.nobina.se/nyheter/2025/utokat-fortroende-i-skane---tva-nya-avtal/
Robots.txt blocks: https://www.nobina.se/nyheter/2025/boras-hockey/
Robots.txt blocks: https://www.nobina.se/nyheter/2025/smart-laddning-av-elbussar/
Robots.txt blocks: https://www.nobina.se/nyheter/2025/framkomlighet-och-korbanebredd/
Robots.txt blocks: https://www.nobina.se/nyheter/2025/festivaltrafik-med-feeling-pa-sweden-rock/
Robots.txt blocks: https://www.nobina.se/nyheter/2025/gruppen-som-skapar-basta-forarmiljon/
Robots.txt blocks: https://www.nobina.se/nyheter/2025/nobina-kor-busstrafiken-i-karlstad-stad-fran-1-juli/
Robots.txt blocks: https://www.nobina.se/nyheter/2025/over-100-000-resenarer-pa-x-linjen/
Robots.txt blocks: https://www.nobina.se/nyheter/2025/nya-depan-i-timboholm/
Robots.txt blocks: https://www.nobina.se/nyheter/2025/trafikstart-pa-sodertorn/
Robots.txt blocks: https://www.nobina.se/nyheter/2025/nobinaforaren-josefin-kihlberg-vinner-bussforar-sm-2025/
Robots.txt blocks: https://www.nobina.se/nyheter/2025/nobinamekanikern-abbe-sveriges-represetant-i-euroskills/
Robots.txt blocks: https://www.nobina.se/nyheter/2025/nobina-vinner-fornyat-kontrakt-i-varmland/
Robots.txt blocks: https://www.nobina.se/uppstart-karlstad/karlstad/lokal-information/
Robots.txt blocks: https://www.nobina.se/jobba-hos-oss/bussforare/mot-vara-bussforare/
Robots.txt blocks: https://www.nobina.se/jobba-hos-oss/bussforare/bussforare-jobb/
Robots.txt blocks: https://www.nobina.se/jobba-hos-oss/mekaniker/lediga-jobb-verkstad-och-underhall/
Robots.txt blocks: https://www.nobina.se/varmland/jobba-hos-nobina-varmland/jobba-som-bussforare-i-varmland/
Robots.txt blocks: https://www.nobina.se/ostergotland/jobba-hos-nobina-ostergotland/jobba-som-bussforare-i-ostergotland/
Robots.txt blocks: https://www.nobina.se/ostergotland/jobba-hos-nobina-ostergotland/jobba-som-fordonsvardare-i-linkoping/
Robots.txt blocks: https://www.nobina.se/ostergotland/jobba-hos-nobina-ostergotland/jobba-som-fordonsvardsledare-i-linkoping/
Robots.txt blocks: https://www.nobina.se/ostergotland/jobba-hos-nobina-ostergotland/jobba-som-mekaniker-i-linkoping/
Robots.txt blocks: https://www.nobina.se/testcontainer/start/standard/
Robots.txt blocks: https://www.nobina.se/seminarier/tack/framkomlighetsrapporten-2023/
Robots.txt blocks: https://www.nobina.se/nyheter/2024/for-sakerhets-skull---anvand-balte/
Robots.txt blocks: https://www.nobina.se/nyheter/2024/lat-bilen-vila-och-ta-bussen---provakare-sokes-i-pitea/
Robots.txt blocks: https://www.nobina.se/nyheter/2024/x-linjen-tar-resenarerna-dit-de-vill/
Robots.txt blocks: https://www.nobina.se/nyheter/2024/framtidens-kollektivtrafik-i-sunne/
Robots.txt blocks: https://www.nobina.se/nyheter/2024/en-stor-andel-tjejer-och-yngre-nar-malmo-rekryterar-till-forarutbilning/
Robots.txt blocks: https://www.nobina.se/nyheter/2024/bussforaren-dag-for-tionde-aret/
Robots.txt blocks: https://www.nobina.se/nyheter/2024/10-arsjubileum-for-firandet-av-bussforarens-dag/
Robots.txt blocks: https://www.nobina.se/nyheter/2024/tack-alla-bussforare/
Robots.txt blocks: https://www.nobina.se/nyheter/2024/nobina-far-fornyat-fortroende-av-region-stockholm/
Robots.txt blocks: https://www.nobina.se/nyheter/2024/resandet-okar-med-buss-pa-bestallning-pa-morko/
Robots.txt blocks: https://www.nobina.se/nyheter/2024/narvarande-gruppchef-hjalper-forarna-att-gora-sitt-basta/
Robots.txt blocks: https://www.nobina.se/nyheter/2024/stort-soktryck-pa-nobinas-forarutbildningar-runtom-i-landet/
Robots.txt blocks: https://www.nobina.se/nyheter/2024/nobinas-forsta-eldrivna-regionbussar-rullar-i-skane/
Robots.txt blocks: https://www.nobina.se/nyheter/2024/nobina-lanserar-storningswebb-for-tagtrafiken/
Robots.txt blocks: https://www.nobina.se/nyheter/2024/nobina-busspartner-till-stockholm-pride-for-nionde-gangen/
Robots.txt blocks: https://www.nobina.se/nyheter/2024/fran-forare-till-mekaniker---mumin-hittade-hem-i-verkstaden/
Robots.txt blocks: https://www.nobina.se/nyheter/2024/nu-hejar-vi-pa-vara-finalister-pa-bussforar-sm/
Robots.txt blocks: https://www.nobina.se/nyheter/2024/nobinaforare-vann-titeln-sveriges-basta-bussforare/
Robots.txt blocks: https://www.nobina.se/nyheter/2024/on-demand-i-svalov---flexibel-kollektivtrafik-med-skaneflex/
Robots.txt blocks: https://www.nobina.se/nyheter/2024/Har-atervinns-80-av-tvattvattnet/
Robots.txt blocks: https://www.nobina.se/nyheter/2024/livekameror-okar-tryggheten-pa-malmos-bussar/
Robots.txt blocks: https://www.nobina.se/nyheter/2024/sjalvkorande-bussar-till-centralsjukhuset-i-karlstad/
Robots.txt blocks: https://www.nobina.se/nyheter/2024/flexibel-on-demand-trafik-brt-innovationer-och-ai-ger-fler-och-nya-resenarer/
Robots.txt blocks: https://www.nobina.se/nyheter/2024/nobina-tar-over-trafiken-i-umea-i-juni-2026/
Robots.txt blocks: https://www.nobina.se/nyheter/2024/nobina-forst-ut-med-realtidsdata-om-ersattningstrafik/
Robots.txt blocks: https://www.nobina.se/nyheter/2024/nobina-vinner-anbud-for-linje-321/
Robots.txt blocks: https://www.nobina.se/nyheter/2024/fornyat-fortroende-for-nobina-for-busstrafiken-boden--lulea/
Robots.txt blocks: https://www.nobina.se/nyheter/2024/nobina-vinner-omfattande-avtal-for-ersattningstrafik-for-tag-i-skane/
Robots.txt blocks: https://www.nobina.se/nyheter/2024/nobina-far-fornyat-fortroende-for-busstrafiken-i-malmo-stad/
Robots.txt blocks: https://www.nobina.se/nyheter/2024/100-procent-el-i-umea-stadstrafik-2026/
Robots.txt blocks: https://www.nobina.se/uppstart-hbs/huddinge-botkyrka-soderort/om-oss/
Robots.txt blocks: https://www.nobina.se/om-oss/vi-engagerar-oss/samarbetet-med-nobina-ar-vardefullt-och-viktigt/
Robots.txt blocks: https://www.nobina.se/om-oss/vi-engagerar-oss/stor-dag-fylld-med-ridning-och-gladje/
Robots.txt blocks: https://www.nobina.se/om-oss/vi-engagerar-oss/onskan-om-att-aka-buss-blev-sann/
Robots.txt blocks: https://www.nobina.se/om-oss/vi-engagerar-oss/nobina-ar-huvudpartner-till-min-stora-dag/
ðŸ“Š PROGRESS UPDATE [Crawl 1034]: 1 pages crawled
ðŸ“Š Memory [queue-workers-0]: RSS 1518MB, Heap 414MB
âœ… Using Prisma singleton for database connection
Queue worker using Chrome at: /usr/bin/chromium
PM2 Instance: 0, Running Lighthouse: true
ðŸ•·ï¸ Creating Crawl worker (enabled=true, isMainInstance=true)
ðŸ”’ Memory guard started for queue-workers-0 (limit: 1100MB)
[STORAGE] Local artifact storage initialized at /home/reda/seo-analyzer-nextjs/artifacts
âœ… Connected to Redis
Processing Crawl job 1035 for https://seoanalyze.se/
ðŸ”„ STATE TRANSITION [Crawl 1035]: waiting â†’ active (worker picked up job)
ðŸ”„ STATE TRANSITION [AI Analysis 76]: waiting â†’ active (worker picked up job)
ðŸ“Š PROGRESS UPDATE [Crawl 1035]: 10 pages crawled
ðŸ¤– Processing AI Analysis job 80 for https://seoanalyze.se/
ðŸ¤– Step 1: Analyzing user's website https://seoanalyze.se/
ðŸ”„ STATE TRANSITION [AI Analysis 80]: waiting â†’ active (worker picked up job)
ðŸ”„ STATE TRANSITION [AI Analysis 76]: waiting â†’ failed (error: job stalled more than allowable limit)
Loaded robots.txt
Could not parse sitemap: https://seoanalyzer.se/sitemap.xml
Could not parse sitemap: https://seoanalyze.se/sitemap_index.xml
Could not parse sitemap: https://seoanalyze.se/sitemap.txt
Could not parse sitemap: https://seoanalyze.se/sitemaps.xml
Could not parse sitemap: https://seoanalyze.se/sitemap-index.xml
Could not parse sitemap: https://seoanalyze.se/wp-sitemap.xml
Could not parse sitemap: https://seoanalyze.se/page-sitemap.xml
Found 6 URLs in sitemap - using sitemap-first strategy
Crawling (1/100): https://seoanalyze.se/
Robots.txt blocks: https://seoanalyzer.se/
Robots.txt blocks: https://seoanalyzer.se/seo-analys
Robots.txt blocks: https://seoanalyzer.se/lighthouse-analys
Robots.txt blocks: https://seoanalyzer.se/crawl-analys
Robots.txt blocks: https://seoanalyzer.se/integritetspolicy
Robots.txt blocks: https://seoanalyzer.se/anvandarvillkor
ðŸ“Š PROGRESS UPDATE [Crawl 1035]: 1 pages crawled
ðŸ¤– Created SEO analysis: cmglgqhif0000r26dl92ehdmq, Crawl analysis: cmglgqhim0001r26dl1dyz7i9, Lighthouse analysis: cmglgqhip0002r26d3uxlb3me
Added SEO job 5323 for https://seoanalyze.se/
Processing SEO job 5323 for https://seoanalyze.se/
Added Crawl job 1036 for https://seoanalyze.se/
ðŸ”„ STATE TRANSITION [SEO 5323]: waiting â†’ active (worker picked up job)
ðŸ“Š PROGRESS UPDATE [SEO 5323]: 10%
Added Lighthouse job 514 for https://seoanalyze.se/
Processing Lighthouse job 514 for https://seoanalyze.se/
ðŸ¤– Waiting for user SEO (5323), Crawl (1036), and Lighthouse (514)
ðŸ”„ STATE TRANSITION [Lighthouse 514]: waiting â†’ active (worker picked up job)
ðŸ“Š PROGRESS UPDATE [Lighthouse 514]: 10%
Loading ES modules...
ðŸ“Š PROGRESS UPDATE [SEO 5323]: 30%
DEBUG: HTML retrieved for https://seoanalyze.se/, HTML sample=<!DOCTYPE html><!--9cgQzoniMRb1BVtM0dP4u--><html lang="sv"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" as="image" imageSrcSet=
DEBUG: performSeoAnalysis creating new Cheerio instance for https://seoanalyze.se/
DEBUG: Cheerio version: 1.1.2
DEBUG: URL=https://seoanalyze.se/, Cheerio found 0 scripts, 0 JSON-LD
DEBUG: Using regex fallback for JSON-LD extraction
Found JSON-LD via regex: {"@context":"https://schema.org","@graph":[{"@type":"Organization","@id":"https://seoanalyze.se/#org...
Schema detection: found 1 scripts, hasSchema: true, types: Organization,WebSite,SoftwareApplication,BreadcrumbList
robots.txt check: true
sitemap.xml check: true
ðŸ“Š PROGRESS UPDATE [SEO 5323]: 90%
[SCREENSHOT] start id=cmglgqhif0000r26dl92ehdmq url=https://seoanalyze.se/
Creating new browser instance...
Crawling (2/100): https://seoanalyze.se/ai-analys
ðŸ“Š PROGRESS UPDATE [Crawl 1035]: 2 pages crawled
Browser instance created
Browser acquired from pool (1 in pool, 0 available)
Using Chrome path: /usr/bin/chromium
Chrome flags: 14 flags configured
Crawling (3/100): https://seoanalyze.se/integritetspolicy
ðŸ“Š PROGRESS UPDATE [Crawl 1035]: 3 pages crawled
ðŸ§  Running Rule Engine for crawl analysis cmglgpewq0001r2lr2haqvooz
âœ… Added 0 rule-based recommendations
Lighthouse categories: performance, accessibility, seo, best-practices
ðŸ“Š Added RUM data with 128 samples
ðŸ” Running Change Detection for crawl https://seoanalyze.se/
ðŸ“¸ Created snapshot 98d947a2-06e0-4590-8924-261f1148c889 for https://seoanalyze.se/
ðŸ“Š PROGRESS UPDATE [Crawl 1035]: 100 pages crawled
Crawl job 1035 completed in 2984ms
ðŸ’¾ Updating Crawl analysis cmglgpewq0001r2lr2haqvooz in database
ðŸ’¾ DB results uppdaterade fÃ¶r crawl cmglgpewq0001r2lr2haqvooz
ðŸ“ Updated analysis cmglgpewq0001r2lr2haqvooz status to completed
Chrome process 17188 killed successfully
